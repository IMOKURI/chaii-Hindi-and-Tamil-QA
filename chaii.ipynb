{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "chaii.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM5ekfa0Bas/j8ZSivKcoRC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7c93ed481db94b38967637fea4ae35fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ff2fcb75a8524e9f84f4607f3c3b4ad3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8555a716f5f4489d80c2fc2983c2babe",
              "IPY_MODEL_6caacf2867d6421abc45322156e1c967",
              "IPY_MODEL_625b70b578c24d6da65c0ff1df39ec99"
            ]
          }
        },
        "ff2fcb75a8524e9f84f4607f3c3b4ad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8555a716f5f4489d80c2fc2983c2babe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_62243f0c5b2144c4b07f7a79254a321a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f840d81fcf2648fbb21c9bcc3c7e6641"
          }
        },
        "6caacf2867d6421abc45322156e1c967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_547ea405337345fb861dcf1ac9e3bbae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 179,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 179,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4092e571264c4e38b8570d0f21110c10"
          }
        },
        "625b70b578c24d6da65c0ff1df39ec99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dfe88ad423d8464ba86b256442b26b15",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 179/179 [00:00&lt;00:00, 7.73kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_641efef8a3ae4beaa4683156ad575a93"
          }
        },
        "62243f0c5b2144c4b07f7a79254a321a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f840d81fcf2648fbb21c9bcc3c7e6641": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "547ea405337345fb861dcf1ac9e3bbae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4092e571264c4e38b8570d0f21110c10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dfe88ad423d8464ba86b256442b26b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "641efef8a3ae4beaa4683156ad575a93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "544e8ba722e04a27add8bb2ede6edab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4ef60073c0304d968a5ee469a98e5e6d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a19e6cf1390749f4999be35fd7bd1eea",
              "IPY_MODEL_a36c5a42f87b48eeb02159106cedb528",
              "IPY_MODEL_68f2a71832f442049d6bc5e6bcee97b1"
            ]
          }
        },
        "4ef60073c0304d968a5ee469a98e5e6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a19e6cf1390749f4999be35fd7bd1eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2496bf863649484a900d6c93dd65bf7a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dcfb3d9660d54480bdc4b153a36a99b5"
          }
        },
        "a36c5a42f87b48eeb02159106cedb528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2edad0c78c254a1b993d787350f1fada",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 606,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 606,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_632b78a74dcd47fcb258e77f69a7a609"
          }
        },
        "68f2a71832f442049d6bc5e6bcee97b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d56e39f166394fc7ae6103e3954c00ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 606/606 [00:00&lt;00:00, 26.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9019d0604974d39b4da30d78155a222"
          }
        },
        "2496bf863649484a900d6c93dd65bf7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dcfb3d9660d54480bdc4b153a36a99b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2edad0c78c254a1b993d787350f1fada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "632b78a74dcd47fcb258e77f69a7a609": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d56e39f166394fc7ae6103e3954c00ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9019d0604974d39b4da30d78155a222": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55a1db1d104d4a2e868e617cd36095a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_add8e8135925455781c3a1b7231f1d88",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_43b348c785574c01a8a7810694669ba5",
              "IPY_MODEL_9956d355bdbc491f976bf9d1f8663b37",
              "IPY_MODEL_95bfbbce3cfe4128a5c99095fa3794b3"
            ]
          }
        },
        "add8e8135925455781c3a1b7231f1d88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43b348c785574c01a8a7810694669ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4b69088fba33446fa3004807c475d257",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9544741b6ae144c5b103eeba9eaf290e"
          }
        },
        "9956d355bdbc491f976bf9d1f8663b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c41801cb6a7f44a191b29292b8bce784",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57c7a5492ad64010b2a546f6e8170a74"
          }
        },
        "95bfbbce3cfe4128a5c99095fa3794b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8e614a4f021a40aeac65b434d654a454",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.07M/5.07M [00:01&lt;00:00, 4.92MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9d03d242945484983ecb860750fe265"
          }
        },
        "4b69088fba33446fa3004807c475d257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9544741b6ae144c5b103eeba9eaf290e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c41801cb6a7f44a191b29292b8bce784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57c7a5492ad64010b2a546f6e8170a74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e614a4f021a40aeac65b434d654a454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9d03d242945484983ecb860750fe265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d5864e15378740d4a6d70da6c2102a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d0b9234fa7e14a8d999f36bcf6fec876",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d935556582854f6eba5591d3e6d20c04",
              "IPY_MODEL_c6b5944e16574ee7ae24f021a6cdcd3f",
              "IPY_MODEL_872ba6e4cc42464ca1667a5f657db5af"
            ]
          }
        },
        "d0b9234fa7e14a8d999f36bcf6fec876": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d935556582854f6eba5591d3e6d20c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a783f6aa32fd4a649937be8358d80a6e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cea95718a11a49fb87b72f2f4bddc5b8"
          }
        },
        "c6b5944e16574ee7ae24f021a6cdcd3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_51acacaee52a44e6abf2e4218c52d402",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 150,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 150,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd4ca6c2ec3f437991b9376e8cc2bd1e"
          }
        },
        "872ba6e4cc42464ca1667a5f657db5af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_281eac8bec124df9bdbf607a1242eb84",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 150/150 [00:00&lt;00:00, 6.10kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd0e1792b62d42d18ee0cb5b5c0fae8b"
          }
        },
        "a783f6aa32fd4a649937be8358d80a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cea95718a11a49fb87b72f2f4bddc5b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51acacaee52a44e6abf2e4218c52d402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd4ca6c2ec3f437991b9376e8cc2bd1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "281eac8bec124df9bdbf607a1242eb84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd0e1792b62d42d18ee0cb5b5c0fae8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36e4738a65474c2480db43003c0e36f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a3b118b28c694bc3a44344ddea1e90b5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_272caf9759de4a1a89b63e4e1fffa1b8",
              "IPY_MODEL_4c19719da3504573a0e947d5c162a5b0",
              "IPY_MODEL_bb3a405e64c84de3958e46ab593a1dcf"
            ]
          }
        },
        "a3b118b28c694bc3a44344ddea1e90b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "272caf9759de4a1a89b63e4e1fffa1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8d189f9004384e899e229a2b4136650c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e6f2d21fad6452ab577f17fc2624c93"
          }
        },
        "4c19719da3504573a0e947d5c162a5b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cf301d6bd6bb41b9aa62cc6638502c5c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2239666418,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2239666418,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f55655a29b94410ba8b5071cdceffa5"
          }
        },
        "bb3a405e64c84de3958e46ab593a1dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0d345378098c4d3bbb8e20bfdf480f4c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.24G/2.24G [00:36&lt;00:00, 65.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c37d4f02973b4b6e95041d68c8043f29"
          }
        },
        "8d189f9004384e899e229a2b4136650c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e6f2d21fad6452ab577f17fc2624c93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf301d6bd6bb41b9aa62cc6638502c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f55655a29b94410ba8b5071cdceffa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d345378098c4d3bbb8e20bfdf480f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c37d4f02973b4b6e95041d68c8043f29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IMOKURI/chaii-Hindi-and-Tamil-QA/blob/main/chaii.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p8HABKC9jNl"
      },
      "source": [
        "# 📔 About this notebook ...\n",
        "\n",
        "[chaii - Hindi and Tamil Question Answering](https://www.kaggle.com/c/chaii-hindi-and-tamil-question-answering/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U4_rc_e9rOY"
      },
      "source": [
        "# Memo\n",
        "\n",
        "\n",
        "\n",
        "## ToDo\n",
        "\n",
        "- [ ] [ラベルノイズ補正](https://www.kaggle.com/c/chaii-hindi-and-tamil-question-answering/discussion/264395)\n",
        "    - [ ] [これもかな](https://www.kaggle.com/c/chaii-hindi-and-tamil-question-answering/discussion/266109)\n",
        "- [x] [Post process でスコアアップ](https://www.kaggle.com/nbroad/chaii-qa-torch-5-fold-with-post-processing-765)\n",
        "- モデル\n",
        "    - [ ] [monsoon-nlp/hindi-tpu-electra](https://huggingface.co/monsoon-nlp/hindi-tpu-electra)\n",
        "    - [ ] [RemBERT](https://www.kaggle.com/c/chaii-hindi-and-tamil-question-answering/discussion/267827)\n",
        "    - [ ] [google/muril-base-cased](https://huggingface.co/google/muril-base-cased)\n",
        "    - その他 [multilingual & QA models](https://huggingface.co/models?filter=multilingual&pipeline_tag=question-answering)\n",
        "- [x] モデルクラスで  `AutoModelForQuestionAnswering` クラス を使ってみる\n",
        "\n",
        "## Done\n",
        "\n",
        "\n",
        "## Works Well\n",
        "\n",
        "\n",
        "## Doesn't Work\n",
        "\n",
        "\n",
        "## Not To Do\n",
        "\n",
        "- [2つのモデルを作る](https://www.kaggle.com/c/chaii-hindi-and-tamil-question-answering/discussion/267604) - [経緯](https://www.kaggle.com/c/chaii-hindi-and-tamil-question-answering/discussion/264749)\n",
        "- [位置によるペナルティを課す Loss](https://www.kaggle.com/c/chaii-hindi-and-tamil-question-answering/discussion/266832)\n",
        "\n",
        "\n",
        "## Additional Datasets\n",
        "\n",
        "Search from [here](https://www.kaggle.com/c/chaii-hindi-and-tamil-question-answering/discussion/264581).\n",
        "\n",
        "- [External Data - MLQA, XQUAD Preprocessing](https://www.kaggle.com/rhtsingh/external-data-mlqa-xquad-preprocessing) hindi のみ\n",
        "- [Squad_Translated_to_Tamil for Chaii](https://www.kaggle.com/msafi04/squad-translated-to-tamil-for-chaii) tamil のみ\n",
        "\n",
        "\n",
        "## Reference Notebooks\n",
        "\n",
        "- [ChAII - EDA & Baseline](https://www.kaggle.com/thedrcat/chaii-eda-baseline/)\n",
        "- [chaii QA - 5 Fold XLMRoberta Torch | FIT](https://www.kaggle.com/rhtsingh/chaii-qa-5-fold-xlmroberta-torch-fit/)\n",
        "- [chaii QA - 5 Fold XLMRoberta Torch | Infer](https://www.kaggle.com/rhtsingh/chaii-qa-5-fold-xlmroberta-torch-infer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VBhwVS89vKZ"
      },
      "source": [
        "# Prepare for Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEN6L1ol9d6d",
        "outputId": "ecf1c9b7-d414-4314-f275-fe0b4716c095"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Sep 14 15:32:07 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl14Cnli91Ol",
        "outputId": "a08c07c3-9354-4584-f086-c18a30630d9e"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import zipfile\n",
        "\n",
        "if os.path.exists('init.txt'):\n",
        "    print(\"Already initialized.\")\n",
        "\n",
        "else:\n",
        "    if 'google.colab' in sys.modules:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        dataset_dir = \"/content/drive/MyDrive/Datasets\"\n",
        "\n",
        "        # ====================================================\n",
        "        # Competition datasets\n",
        "        # ====================================================\n",
        "        with zipfile.ZipFile(f\"{dataset_dir}/chaii-hindi-and-tamil-question-answering.zip\", \"r\") as zp:\n",
        "            zp.extractall(path=\"./\")\n",
        "        #with zipfile.ZipFile(f\"{dataset_dir}/chaii-external-data-mlqa-xquad-preprocessing.zip\", \"r\") as zp:\n",
        "        #    zp.extractall(path=\"./\")\n",
        "        #with zipfile.ZipFile(f\"{dataset_dir}/chaii-Squad_Translated_to_Tamil.zip\", \"r\") as zp:\n",
        "        #    zp.extractall(path=\"./\")\n",
        "\n",
        "    # for StratifiedGroupKFold\n",
        "    # !pip uninstall -y scikit-learn\n",
        "    # !pip install --pre --extra-index https://pypi.anaconda.org/scipy-wheels-nightly/simple scikit-learn\n",
        "\n",
        "    # for MultilabelStratifiedKFold\n",
        "    # !pip install -q iterative-stratification\n",
        "\n",
        "    # for CosineAnnealingWarmupRestarts\n",
        "    # !pip install -qU 'git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup'\n",
        "\n",
        "    !pip install -q wandb\n",
        "    # !pip install -q optuna\n",
        "\n",
        "    # ====================================================\n",
        "    # Competition specific libraries\n",
        "    # ====================================================\n",
        "    !pip install -q transformers\n",
        "    !pip install -q sentencepiece\n",
        "    # !pip install -q textstat\n",
        "    # !pip install -q nlpaug\n",
        "\n",
        "    !touch init.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 7.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 170 kB 83.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 89.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 71.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 52 kB 2.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 83.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 81.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 4.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DXvMPm5_4h0"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB47hsio_5y6"
      },
      "source": [
        "# General libraries\n",
        "import collections\n",
        "import glob\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import statistics\n",
        "import time\n",
        "import warnings\n",
        "from contextlib import contextmanager\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.cuda.amp as amp\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import wandb\n",
        "# from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
        "# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error, jaccard_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold  # , StratifiedGroupKFold\n",
        "from torch.optim import SGD, Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyiVJefp4oOi"
      },
      "source": [
        "# Competition specific libraries\n",
        "# import nlpaug.augmenter.word as naw\n",
        "# import nlpaug.augmenter.sentence as nas\n",
        "# import nltk\n",
        "# import textstat\n",
        "import transformers as T"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-snxxwfCAO92"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxr17nzJAS2c"
      },
      "source": [
        "#nltk.download('stopwords')\n",
        "#nltk.download('punkt')\n",
        "#nltk.download('wordnet')\n",
        "#nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxTu8mx-AXcw",
        "outputId": "abb82ef4-3abc-4be0-984d-40fc24c8cbe9"
      },
      "source": [
        "netrc = \"/content/drive/MyDrive/.netrc\" if 'google.colab' in sys.modules else \"../input/wandbtoken/.netrc\"\n",
        "!cp -f {netrc} ~/\n",
        "!wandb login\n",
        "\n",
        "wandb_tags = []"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WavcpUepAQOs"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    wandb_tags.append(torch.cuda.get_device_name(0))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_GYEnAnAqmJ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbzq6jTIAszZ"
      },
      "source": [
        "DATA_DIR = \"./\" if 'google.colab' in sys.modules else \"../input/chaii-hindi-and-tamil-question-answering/\"\n",
        "OUTPUT_DIR = \"./\"\n",
        "MODEL_DIR = \"./models/\"\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ey9Vh4CBMgo"
      },
      "source": [
        "train = pd.read_csv(DATA_DIR + \"train.csv\")\n",
        "test = pd.read_csv(DATA_DIR + \"test.csv\")\n",
        "sub = pd.read_csv(DATA_DIR + \"sample_submission.csv\")\n",
        "\n",
        "#external_squad_translated_tamil = pd.read_csv(DATA_DIR + \"squad_translated_tamil.csv\")\n",
        "#external_mlqa = pd.read_csv(DATA_DIR + \"mlqa_hindi.csv\")\n",
        "#external_xquad = pd.read_csv(DATA_DIR + \"xquad.csv\")\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm2Lqm0KBeb_"
      },
      "source": [
        "#  Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWsNi7VmB9_M",
        "outputId": "a2d49d84-37ce-458c-94dd-689e27cbb721"
      },
      "source": [
        "# seed = random.randrange(10000)\n",
        "seed = 440\n",
        "print(seed)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDIEcAvEBdqj"
      },
      "source": [
        "class Config:\n",
        "    wandb_entity = \"imokuri\"\n",
        "    wandb_project = \"chaii\"\n",
        "    print_freq = 100\n",
        "\n",
        "    preprocess = False\n",
        "    train = True\n",
        "    validate = False\n",
        "    inference = False\n",
        "\n",
        "    debug = False\n",
        "    num_debug_data = 50\n",
        "\n",
        "    amp = False"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI5SEjO0CS8k"
      },
      "source": [
        "config_defaults = {\n",
        "    \"seed\": seed,\n",
        "    # \"n_class\": 1,\n",
        "    \"n_fold\": 5,\n",
        "    \"epochs\": 2,\n",
        "    \"batch_size\": 4,\n",
        "    \"gradient_accumulation_steps\": 5,\n",
        "    \"max_grad_norm\": 1.0,\n",
        "    \"criterion\": \"ChaiiCrossEntropyLoss\",\n",
        "    \"optimizer\": \"BertAdamW\",\n",
        "    \"scheduler\": \"get_cosine_schedule_with_warmup\",\n",
        "    \"max_lr\": 5e-5,\n",
        "    \"lr\": 2e-5,\n",
        "    \"min_lr\": 1e-5,\n",
        "    \"weight_decay\": 0.01,\n",
        "    \"model_name\": \"deepset/xlm-roberta-large-squad2\",\n",
        "    # \"model_name\": \"deepset/xlm-roberta-base-squad2\",\n",
        "    # \"model_name\": \"google/rembert\",\n",
        "    \"model_class\": \"bare\", # bare, qa\n",
        "    \"max_len\": 384,\n",
        "    \"doc_stride\": 128,\n",
        "    \"dropout\": 0.0,\n",
        "    \"init_weights\": True,\n",
        "    \"init_layers\": 1,\n",
        "    # \"freeze_layers\": 0,\n",
        "    \"datasets\": [\n",
        "        \"mlqa:v1\",\n",
        "        \"xquad:v1\",\n",
        "        \"squad_translated_tamil:v1\",\n",
        "    ],\n",
        "    \"models\": [\n",
        "        \"base-models:v1\",\n",
        "    ]\n",
        "}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1Pk66rRDTGC"
      },
      "source": [
        "if Config.debug:\n",
        "    config_defaults[\"n_fold\"] = 3\n",
        "    config_defaults[\"epochs\"] = 1\n",
        "    Config.print_freq = 10"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB9WtvbYBtfN"
      },
      "source": [
        "if Config.train:\n",
        "    wandb_job_type = \"training\"\n",
        "\n",
        "elif Config.inference:\n",
        "    wandb_job_type = \"inference\"\n",
        "\n",
        "elif Config.validate:\n",
        "    wandb_job_type = \"validation\"\n",
        "\n",
        "elif Config.preprocess:\n",
        "    wandb_job_type = \"preprocess\"\n",
        "\n",
        "else:\n",
        "    wandb_job_type = \"\""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2rVE3iK7Xaf"
      },
      "source": [
        "if Config.debug:\n",
        "    wandb_tags.append(\"debug\")\n",
        "    \n",
        "if Config.amp:\n",
        "    wandb_tags.append(\"amp\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kskKEy9Dyqk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ebc1aaaf-f038-4bdb-82c4-ad3f1b711de5"
      },
      "source": [
        "if Config.debug:\n",
        "    run = wandb.init(\n",
        "        entity=Config.wandb_entity,\n",
        "        project=Config.wandb_project,\n",
        "        config=config_defaults,\n",
        "        tags=wandb_tags,\n",
        "        mode=\"disabled\",\n",
        "    )\n",
        "else:\n",
        "    run = wandb.init(\n",
        "        entity=Config.wandb_entity,\n",
        "        project=Config.wandb_project,\n",
        "        config=config_defaults,\n",
        "        job_type=wandb_job_type,\n",
        "        tags=wandb_tags,\n",
        "        save_code=True,\n",
        "    )"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.1<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">youthful-valley-9</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/imokuri/chaii\" target=\"_blank\">https://wandb.ai/imokuri/chaii</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/imokuri/chaii/runs/16cifk7p\" target=\"_blank\">https://wandb.ai/imokuri/chaii/runs/16cifk7p</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210914_153302-16cifk7p</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev3bvwDvEMuS"
      },
      "source": [
        "config = wandb.config"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF1pXRWoHy1_"
      },
      "source": [
        "# Load Artifacts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRSYiJXBD4oy"
      },
      "source": [
        "if config.datasets != []:\n",
        "    external_data = []\n",
        "    for name_version in config.datasets:\n",
        "        name, version = name_version.split(\":\")\n",
        "        os.makedirs(name, exist_ok=True)\n",
        "\n",
        "        if Config.debug:\n",
        "            artifact_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{name_version}\"\n",
        "            api = wandb.Api()\n",
        "            artifact = api.artifact(artifact_path)\n",
        "\n",
        "        else:\n",
        "            artifact_path = f\"{name_version}\"\n",
        "            artifact = run.use_artifact(artifact_path)\n",
        "\n",
        "        artifact.download(name)\n",
        "\n",
        "        df = pd.read_csv(f\"{name}/{name}.csv\")\n",
        "        external_data.append(df)\n",
        "\n",
        "    external_train = pd.concat(external_data)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWh7C_jN8EGC"
      },
      "source": [
        "if Config.inference:\n",
        "    api = wandb.Api()\n",
        "    for artifact_id in config.models:\n",
        "        name_version = artifact_id.replace(\":\", \"-\")\n",
        "        if not os.path.exists(name_version):\n",
        "            os.makedirs(name_version)\n",
        "\n",
        "        for fold in range(config.n_fold):\n",
        "            try:\n",
        "                artifact_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{artifact_id}\"\n",
        "                artifact = api.artifact(artifact_path)\n",
        "                artifact.download(name_version)\n",
        "            except Exception as e:\n",
        "                print(f\"Error: {artifact_path}, {e}\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JepYxTDVFarm"
      },
      "source": [
        "# EDA-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGORKcNtFcAk",
        "outputId": "9f88c687-8fe0-4f88-c855-06979f170d67"
      },
      "source": [
        "for df in [train, test]:\n",
        "    print(f\"=\" * 120)\n",
        "    print(df.isnull().sum())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================================================================================================\n",
            "id              0\n",
            "context         0\n",
            "question        0\n",
            "answer_text     0\n",
            "answer_start    0\n",
            "language        0\n",
            "dtype: int64\n",
            "========================================================================================================================\n",
            "id          0\n",
            "context     0\n",
            "question    0\n",
            "language    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvCjtVwvGacB",
        "outputId": "f4e27977-6b96-4f54-af1e-911736c7db76"
      },
      "source": [
        "for df in [train, test]:\n",
        "    print(f\"=\" * 120)\n",
        "    print(df[\"language\"].value_counts())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================================================================================================\n",
            "hindi    746\n",
            "tamil    368\n",
            "Name: language, dtype: int64\n",
            "========================================================================================================================\n",
            "hindi    3\n",
            "tamil    2\n",
            "Name: language, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUXUouHDHa-i",
        "outputId": "99a674a3-99c8-4594-aac4-59731809e6f2"
      },
      "source": [
        "if config.datasets != []:\n",
        "    print(external_train.isnull().sum())\n",
        "    print(f\"=\" * 120)\n",
        "    print(external_train[\"language\"].value_counts())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context         0\n",
            "question        0\n",
            "answer_text     0\n",
            "answer_start    0\n",
            "language        0\n",
            "dtype: int64\n",
            "========================================================================================================================\n",
            "hindi    6615\n",
            "tamil    3567\n",
            "Name: language, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW1WEUKWEPrV"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0_3tcXS_AEO"
      },
      "source": [
        "def convert_answers(row):\n",
        "    return {'answer_start': [row[0]], 'text': [row[1]]}"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mGJYUQ0liem"
      },
      "source": [
        "def correct_labels(df):\n",
        "    df.loc[df['id'] == '', 'answer_text'] = ''\n",
        "    df.loc[df['id'] == '', 'answer_start'] = 0\n",
        "    pass"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdjatcP_FJ9r"
      },
      "source": [
        "def get_train_data(train):\n",
        "    train['answers'] = train[['answer_start', 'answer_text']].apply(convert_answers, axis=1)\n",
        "\n",
        "    return train"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-A8bRGjFVMw"
      },
      "source": [
        "def get_test_data(test):\n",
        "\n",
        "    return test"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yae6ysRGvMH"
      },
      "source": [
        "train = get_train_data(train)\n",
        "\n",
        "if config.datasets != []:\n",
        "    external_train = get_train_data(external_train)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-okotQ7GwJT"
      },
      "source": [
        "test = get_test_data(test)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54joajJkBRbm"
      },
      "source": [
        "### External Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8RSTX1SBZef"
      },
      "source": [
        "# 前処理\n",
        "if False and Config.preprocess:\n",
        "    external_squad_translated_tamil[\"language\"] = \"tamil\"\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0bvUgZyzasg"
      },
      "source": [
        "# dataset 保存\n",
        "if False and Config.preprocess:\n",
        "    !mkdir -p squad_translated_tamil\n",
        "    external_squad_translated_tamil.to_csv(\"squad_translated_tamil/squad_translated_tamil.csv\", index=False)\n",
        "    artifact = wandb.Artifact('squad_translated_tamil', type='dataset')\n",
        "    artifact.add_dir(\"squad_translated_tamil/\")\n",
        "    run.log_artifact(artifact)\n",
        "\n",
        "    !mkdir -p mlqa\n",
        "    external_mlqa.to_csv(\"mlqa/mlqa.csv\", index=False)\n",
        "    artifact = wandb.Artifact('mlqa', type='dataset')\n",
        "    artifact.add_dir(\"mlqa/\")\n",
        "    run.log_artifact(artifact)\n",
        "\n",
        "    !mkdir -p xquad\n",
        "    external_xquad.to_csv(\"xquad/xquad.csv\", index=False)\n",
        "    artifact = wandb.Artifact('xquad', type='dataset')\n",
        "    artifact.add_dir(\"xquad/\")\n",
        "    run.log_artifact(artifact)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEkueCnpHpGW"
      },
      "source": [
        "# EDA-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CEM8_FTTHqrM",
        "outputId": "e920471f-f5a9-42df-8ca4-29ba9f3e24f9"
      },
      "source": [
        "for df in [train, test, sub]:\n",
        "    print(f\"=\" * 120)\n",
        "    df.info()\n",
        "    display(df.head())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1114 entries, 0 to 1113\n",
            "Data columns (total 7 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   id            1114 non-null   object\n",
            " 1   context       1114 non-null   object\n",
            " 2   question      1114 non-null   object\n",
            " 3   answer_text   1114 non-null   object\n",
            " 4   answer_start  1114 non-null   int64 \n",
            " 5   language      1114 non-null   object\n",
            " 6   answers       1114 non-null   object\n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 61.0+ KB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>language</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>903deec17</td>\n",
              "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
              "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
              "      <td>206</td>\n",
              "      <td>53</td>\n",
              "      <td>tamil</td>\n",
              "      <td>{'answer_start': [53], 'text': ['206']}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d9841668c</td>\n",
              "      <td>காளிதாசன் (தேவநாகரி: कालिदास) சமஸ்கிருத இலக்கி...</td>\n",
              "      <td>காளிதாசன் எங்கு பிறந்தார்?</td>\n",
              "      <td>காசுமீரில்</td>\n",
              "      <td>2358</td>\n",
              "      <td>tamil</td>\n",
              "      <td>{'answer_start': [2358], 'text': ['காசுமீரில்']}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29d154b56</td>\n",
              "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...</td>\n",
              "      <td>பென்சிலின் கண்டுபிடித்தவர் யார்?</td>\n",
              "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங்</td>\n",
              "      <td>0</td>\n",
              "      <td>tamil</td>\n",
              "      <td>{'answer_start': [0], 'text': ['சர் அலெக்ஸாண்ட...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>41660850a</td>\n",
              "      <td>குழந்தையின் அழுகையை  நிறுத்தவும், தூங்க வைக்கவ...</td>\n",
              "      <td>தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...</td>\n",
              "      <td>தாலாட்டு</td>\n",
              "      <td>68</td>\n",
              "      <td>tamil</td>\n",
              "      <td>{'answer_start': [68], 'text': ['தாலாட்டு']}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b29c82c22</td>\n",
              "      <td>சூரியக் குடும்பம் \\nசூரியக் குடும்பம் (Solar S...</td>\n",
              "      <td>பூமியின் அருகில் உள்ள விண்மீன் எது?</td>\n",
              "      <td>சூரியனும்</td>\n",
              "      <td>585</td>\n",
              "      <td>tamil</td>\n",
              "      <td>{'answer_start': [585], 'text': ['சூரியனும்']}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                            answers\n",
              "0  903deec17  ...            {'answer_start': [53], 'text': ['206']}\n",
              "1  d9841668c  ...   {'answer_start': [2358], 'text': ['காசுமீரில்']}\n",
              "2  29d154b56  ...  {'answer_start': [0], 'text': ['சர் அலெக்ஸாண்ட...\n",
              "3  41660850a  ...       {'answer_start': [68], 'text': ['தாலாட்டு']}\n",
              "4  b29c82c22  ...     {'answer_start': [585], 'text': ['சூரியனும்']}\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5 entries, 0 to 4\n",
            "Data columns (total 4 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        5 non-null      object\n",
            " 1   context   5 non-null      object\n",
            " 2   question  5 non-null      object\n",
            " 3   language  5 non-null      object\n",
            "dtypes: object(4)\n",
            "memory usage: 288.0+ bytes\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22bff3dec</td>\n",
              "      <td>ज्वाला गुट्टा (जन्म: 7 सितंबर 1983; वर्धा, महा...</td>\n",
              "      <td>ज्वाला गुट्टा की माँ का नाम क्या है</td>\n",
              "      <td>hindi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>282758170</td>\n",
              "      <td>गूगल मानचित्र (Google Maps) (पूर्व में गूगल लो...</td>\n",
              "      <td>गूगल मैप्स कब लॉन्च किया गया था?</td>\n",
              "      <td>hindi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d60987e0e</td>\n",
              "      <td>गुस्ताव रॉबर्ट किरचॉफ़ (१२ मार्च १८२४ - १७ अक्...</td>\n",
              "      <td>गुस्ताव किरचॉफ का जन्म कब हुआ था?</td>\n",
              "      <td>hindi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>f99c770dc</td>\n",
              "      <td>அலுமினியம் (ஆங்கிலம்: அலுமினியம்; வட அமெரிக்க ...</td>\n",
              "      <td>அலுமினியத்தின் அணு எண் என்ன?</td>\n",
              "      <td>tamil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40dec1964</td>\n",
              "      <td>கூட்டுறவு இயக்க வரலாறு, இங்கிலாந்து  நாட்டில் ...</td>\n",
              "      <td>இந்தியாவில் பசுமை புரட்சியின் தந்தை என்று கருத...</td>\n",
              "      <td>tamil</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ... language\n",
              "0  22bff3dec  ...    hindi\n",
              "1  282758170  ...    hindi\n",
              "2  d60987e0e  ...    hindi\n",
              "3  f99c770dc  ...    tamil\n",
              "4  40dec1964  ...    tamil\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5 entries, 0 to 4\n",
            "Data columns (total 2 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   id                5 non-null      object \n",
            " 1   PredictionString  0 non-null      float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 208.0+ bytes\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>PredictionString</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22bff3dec</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>282758170</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d60987e0e</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>f99c770dc</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40dec1964</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  PredictionString\n",
              "0  22bff3dec               NaN\n",
              "1  282758170               NaN\n",
              "2  d60987e0e               NaN\n",
              "3  f99c770dc               NaN\n",
              "4  40dec1964               NaN"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODUeiq5P_O8s"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqyZ9-uMH2gK"
      },
      "source": [
        "# CV Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM6xvuGssH-4"
      },
      "source": [
        "if Config.debug:\n",
        "    train = train.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)\n",
        "    if config.datasets != []:\n",
        "        external_train = external_train.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)\n",
        "    if len(sub) > Config.num_debug_data:\n",
        "        test = test.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)\n",
        "        sub = sub.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XnW0e1AH4Cn",
        "outputId": "4ce1dd04-92ef-4005-e601-c643853fd8a6"
      },
      "source": [
        "Fold = StratifiedKFold(n_splits=config.n_fold, shuffle=True, random_state=seed)\n",
        "for n, (train_index, val_index) in enumerate(Fold.split(train, train[\"language\"])):\n",
        "    train.loc[val_index, \"fold\"] = int(n)\n",
        "train[\"fold\"] = train[\"fold\"].astype(np.int8)\n",
        "print(train.groupby([\"fold\", \"language\"]).size())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold  language\n",
            "0     hindi       149\n",
            "      tamil        74\n",
            "1     hindi       149\n",
            "      tamil        74\n",
            "2     hindi       149\n",
            "      tamil        74\n",
            "3     hindi       150\n",
            "      tamil        73\n",
            "4     hindi       149\n",
            "      tamil        73\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W902aP490hEk"
      },
      "source": [
        "if config.datasets != []:\n",
        "    external_train[\"fold\"] = -1\n",
        "    external_train['id'] = list(np.arange(1, len(external_train)+1))\n",
        "    train = pd.concat([train, external_train]).reset_index(drop=True)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD0991CRIMH-"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veHPCKXQIJRv"
      },
      "source": [
        "@contextmanager\n",
        "def timer(name):\n",
        "    t0 = time.time()\n",
        "    LOGGER.info(f\"[{name}] start\")\n",
        "    yield\n",
        "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
        "\n",
        "\n",
        "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
        "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
        "\n",
        "    logger = getLogger(__name__)\n",
        "    logger.setLevel(INFO)\n",
        "    handler1 = StreamHandler()\n",
        "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
        "    handler2 = FileHandler(filename=log_file)\n",
        "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
        "    logger.addHandler(handler1)\n",
        "    logger.addHandler(handler2)\n",
        "    return logger\n",
        "\n",
        "\n",
        "LOGGER = init_logger()\n",
        "\n",
        "\n",
        "def seed_torch(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "seed_torch(seed=config.seed)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTjVqALnIXKQ"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqzv3qSpITRU"
      },
      "source": [
        "class BaseDataset(Dataset):\n",
        "    def __init__(self, df, model_name, include_labels=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.tokenizer = T.AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "        self.features = []\n",
        "        if include_labels:\n",
        "            for i, row in df.iterrows():\n",
        "                self.features += self.prepare_train_features(row)\n",
        "        else:\n",
        "            for i, row in df.iterrows():\n",
        "                self.features += self.prepare_test_features(row)\n",
        "\n",
        "        self.include_labels = include_labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        feature = self.features[item]\n",
        "\n",
        "        if self.include_labels:\n",
        "            return {\n",
        "                'input_ids':torch.tensor(feature['input_ids'], dtype=torch.long),\n",
        "                'attention_mask':torch.tensor(feature['attention_mask'], dtype=torch.long),\n",
        "                # 'offset_mapping':torch.tensor(feature['offset_mapping'], dtype=torch.long),\n",
        "                'start_position':torch.tensor(feature['start_position'], dtype=torch.long),\n",
        "                'end_position':torch.tensor(feature['end_position'], dtype=torch.long)\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'input_ids':torch.tensor(feature['input_ids'], dtype=torch.long),\n",
        "                'attention_mask':torch.tensor(feature['attention_mask'], dtype=torch.long),\n",
        "                'offset_mapping':feature['offset_mapping'],\n",
        "                'sequence_ids':feature['sequence_ids'],\n",
        "                'id':feature['example_id'],\n",
        "                'context': feature['context'],\n",
        "                'question': feature['question']\n",
        "            }\n",
        "\n",
        "    def prepare_train_features(self, example):\n",
        "        example[\"question\"] = example[\"question\"].lstrip()\n",
        "        tokenized_example = self.tokenizer(\n",
        "            example[\"question\"],\n",
        "            example[\"context\"],\n",
        "            truncation=\"only_second\",\n",
        "            max_length=config.max_len,\n",
        "            stride=config.doc_stride,\n",
        "            return_overflowing_tokens=True,\n",
        "            return_offsets_mapping=True,\n",
        "            padding=\"max_length\",\n",
        "        )\n",
        "\n",
        "        sample_mapping = tokenized_example.pop(\"overflow_to_sample_mapping\")\n",
        "        offset_mapping = tokenized_example.pop(\"offset_mapping\")\n",
        "\n",
        "        features = []\n",
        "        for i, offsets in enumerate(offset_mapping):\n",
        "            feature = {}\n",
        "            feature[\"example_id\"] = example['id']\n",
        "            feature['context'] = example['context']\n",
        "            feature['question'] = example['question']\n",
        "\n",
        "            input_ids = tokenized_example[\"input_ids\"][i]\n",
        "            attention_mask = tokenized_example[\"attention_mask\"][i]\n",
        "\n",
        "            feature['input_ids'] = input_ids\n",
        "            feature['attention_mask'] = attention_mask\n",
        "            feature['offset_mapping'] = offsets\n",
        "\n",
        "            cls_index = input_ids.index(self.tokenizer.cls_token_id)\n",
        "            sequence_ids = tokenized_example.sequence_ids(i)\n",
        "            feature['sequence_ids'] = [0 if i is None else i for i in sequence_ids]\n",
        "\n",
        "            sample_index = sample_mapping[i]\n",
        "            answers = example[\"answers\"]\n",
        "\n",
        "            if len(answers[\"answer_start\"]) == 0:\n",
        "                feature[\"start_position\"] = cls_index\n",
        "                feature[\"end_position\"] = cls_index\n",
        "            else:\n",
        "                start_char = answers[\"answer_start\"][0]\n",
        "                end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "                token_start_index = 0\n",
        "                while sequence_ids[token_start_index] != 1:\n",
        "                    token_start_index += 1\n",
        "\n",
        "                token_end_index = len(input_ids) - 1\n",
        "                while sequence_ids[token_end_index] != 1:\n",
        "                    token_end_index -= 1\n",
        "\n",
        "                if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "                    feature[\"start_position\"] = cls_index\n",
        "                    feature[\"end_position\"] = cls_index\n",
        "                else:\n",
        "                    while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "                        token_start_index += 1\n",
        "                    feature[\"start_position\"] = token_start_index - 1\n",
        "                    while offsets[token_end_index][1] >= end_char:\n",
        "                        token_end_index -= 1\n",
        "                    feature[\"end_position\"] = token_end_index + 1\n",
        "\n",
        "            features.append(feature)\n",
        "        return features\n",
        "\n",
        "    def prepare_test_features(self, example):\n",
        "        example[\"question\"] = example[\"question\"].lstrip()\n",
        "        tokenized_example = self.tokenizer(\n",
        "            example[\"question\"],\n",
        "            example[\"context\"],\n",
        "            truncation=\"only_second\",\n",
        "            max_length=config.max_len,\n",
        "            stride=config.doc_stride,\n",
        "            return_overflowing_tokens=True,\n",
        "            return_offsets_mapping=True,\n",
        "            padding=\"max_length\",\n",
        "        )\n",
        "\n",
        "        features = []\n",
        "        for i in range(len(tokenized_example[\"input_ids\"])):\n",
        "            feature = {}\n",
        "            feature[\"example_id\"] = example['id']\n",
        "            feature['context'] = example['context']\n",
        "            feature['question'] = example['question']\n",
        "            feature['input_ids'] = tokenized_example['input_ids'][i]\n",
        "            feature['attention_mask'] = tokenized_example['attention_mask'][i]\n",
        "            feature['offset_mapping'] = tokenized_example['offset_mapping'][i]\n",
        "            feature['sequence_ids'] = [0 if i is None else i for i in tokenized_example.sequence_ids(i)]\n",
        "            features.append(feature)\n",
        "        return features"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7c93ed481db94b38967637fea4ae35fb",
            "ff2fcb75a8524e9f84f4607f3c3b4ad3",
            "8555a716f5f4489d80c2fc2983c2babe",
            "6caacf2867d6421abc45322156e1c967",
            "625b70b578c24d6da65c0ff1df39ec99",
            "62243f0c5b2144c4b07f7a79254a321a",
            "f840d81fcf2648fbb21c9bcc3c7e6641",
            "547ea405337345fb861dcf1ac9e3bbae",
            "4092e571264c4e38b8570d0f21110c10",
            "dfe88ad423d8464ba86b256442b26b15",
            "641efef8a3ae4beaa4683156ad575a93",
            "544e8ba722e04a27add8bb2ede6edab2",
            "4ef60073c0304d968a5ee469a98e5e6d",
            "a19e6cf1390749f4999be35fd7bd1eea",
            "a36c5a42f87b48eeb02159106cedb528",
            "68f2a71832f442049d6bc5e6bcee97b1",
            "2496bf863649484a900d6c93dd65bf7a",
            "dcfb3d9660d54480bdc4b153a36a99b5",
            "2edad0c78c254a1b993d787350f1fada",
            "632b78a74dcd47fcb258e77f69a7a609",
            "d56e39f166394fc7ae6103e3954c00ac",
            "c9019d0604974d39b4da30d78155a222",
            "55a1db1d104d4a2e868e617cd36095a6",
            "add8e8135925455781c3a1b7231f1d88",
            "43b348c785574c01a8a7810694669ba5",
            "9956d355bdbc491f976bf9d1f8663b37",
            "95bfbbce3cfe4128a5c99095fa3794b3",
            "4b69088fba33446fa3004807c475d257",
            "9544741b6ae144c5b103eeba9eaf290e",
            "c41801cb6a7f44a191b29292b8bce784",
            "57c7a5492ad64010b2a546f6e8170a74",
            "8e614a4f021a40aeac65b434d654a454",
            "d9d03d242945484983ecb860750fe265",
            "d5864e15378740d4a6d70da6c2102a73",
            "d0b9234fa7e14a8d999f36bcf6fec876",
            "d935556582854f6eba5591d3e6d20c04",
            "c6b5944e16574ee7ae24f021a6cdcd3f",
            "872ba6e4cc42464ca1667a5f657db5af",
            "a783f6aa32fd4a649937be8358d80a6e",
            "cea95718a11a49fb87b72f2f4bddc5b8",
            "51acacaee52a44e6abf2e4218c52d402",
            "cd4ca6c2ec3f437991b9376e8cc2bd1e",
            "281eac8bec124df9bdbf607a1242eb84",
            "bd0e1792b62d42d18ee0cb5b5c0fae8b"
          ]
        },
        "id": "77rjufTiUtJb",
        "outputId": "58fea70c-aad8-4405-d1c0-cea3939e6c7f"
      },
      "source": [
        "if config.model_name != \"\":\n",
        "    train_ds = BaseDataset(train, config.model_name)\n",
        "    print(train_ds[0])\n",
        "    print(len(train_ds))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c93ed481db94b38967637fea4ae35fb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/179 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "544e8ba722e04a27add8bb2ede6edab2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/606 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55a1db1d104d4a2e868e617cd36095a6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5864e15378740d4a6d70da6c2102a73",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([     0,  69535,  81049,  37368, 153264,  12095,  52989,  21883,   1629,\n",
            "        145615,     32,      2,      2,   3219, 224013, 124335,   5966,  69535,\n",
            "          4930,  74149,  12095,  52989,  21883, 182394,   3686,  51833,  57210,\n",
            "        101912,     15,   6161,   2912,  70597,  52989,  21883, 102080,  54512,\n",
            "         91585,   1962, 212933,  18599,  16242,  94236,     16, 198236,  29160,\n",
            "         12095,  52989,  21883, 173139,  23618,  72817,      5,   5894, 198236,\n",
            "         81049,  37334, 144257,   7827,  82890,  84853,  80517, 114452, 232094,\n",
            "          3686,  17984,  11830,  62001, 182394,   4167,      5, 203312,  10753,\n",
            "         50667,   2650,      4,  45303,   1962, 163062, 198236,  29160, 176030,\n",
            "         15453,      4,   3219, 171093,   5944,   2650,   8120,  10175,  12095,\n",
            "         52989,  21883,     15,   2650,  24183,   5638,  14861,     16,  56735,\n",
            "          3219, 171093,   5944,   2650,  12009, 145578,  10832,   2802,   2650,\n",
            "         26873,  52989,  21883,  53336,  26415,  38640,  31067,     74, 105457,\n",
            "          5966,  22050,  12095,  52989,  21883, 202342,  59386,  12095,  52989,\n",
            "         13070,   2650,   1962,  39311,   9654,  37964,  18806,      4, 196586,\n",
            "        105457,   5966,  22467,  78876,  52989,  21883,     74, 102080,   6896,\n",
            "            20,  21162,  14233,  94097,   4864,  12152,  12095,  52989,  21883,\n",
            "          1629, 210828,   1381, 198236,   2782, 191297,  10832,   2802,   2650,\n",
            "         26873,  52989,  21883,   1629,   3912,  59987,   1962, 212933,  26415,\n",
            "         20567,      5,  69535,   9696, 184936,  28258,  89933,   1039,  12095,\n",
            "         52989,  21883,   1629,     15,  10753,   2802,   6149,  11674,  16043,\n",
            "         26873,   2913,  21883, 202342, 137010,     16, 145615,     74, 164359,\n",
            "         12095,  11993, 181576,  87783,  35186,     15,  15182,  53208,     16,\n",
            "         12095,  52989,  21883,  91585,  11772,    616,  71987,  12095,  52989,\n",
            "         21883,  91585,  11772,     15,   1021,  26136,  32881,      7,     16,\n",
            "         73417,  73949, 163493,      5,     15,   4875,   5427,   3770, 136259,\n",
            "          1629,  88115,   2650, 230988, 112578,  53336,   4167, 136259, 173139,\n",
            "             6,  79464,   2798, 143825,      5,     16, 181576,  87783,  35186,\n",
            "         12095,  52989,  21883,   1629,  10021,    106, 190707,   4875, 128236,\n",
            "         52989,  21883,     15,  20549,    289,  32881,     16,    116,  14184,\n",
            "          3937, 145181,  52989,  21883,     15,  24980,     13,   1803,  32881,\n",
            "            16,   1737,    138, 116180,  17056,   3686,   4875, 128236,  52989,\n",
            "         21883,     15,  99736,    289,  32881,     16,   1737,    201,  22262,\n",
            "         95344,  12095,  52989,  21883,     15,   6652,  88354,    289,  32881,\n",
            "            16,   6001,   6343,   8850,  12095,  52989,  21883,     15,      7,\n",
            "         88322,  48899,  32881,     16,  60070,  12784,   2782,  35424,  26873,\n",
            "         52989,  21883,     15,  12421,    432,    532,  32881,     16,  71987,\n",
            "         12095,  52989,  21883,   1629,  31203,    361, 145578,  51153,  18805,\n",
            "         12095,  52989,  21883,     15,  12018,  28236,     16,    305, 177292,\n",
            "         95424,  18805,  12095,  52989,  21883,     15,  24084,   2298,     16,\n",
            "          1737,   2690,  42353,  78876,  52989,  21883,     15,  16917,  10325,\n",
            "         32881,     16,   1737,    190,   6390,  62481,  12095,  52989,  21883,\n",
            "            15,   3285,    519,  47148,  32881,      2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'start_position': tensor(27), 'end_position': tensor(27)}\n",
            "26881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YBEpGYP-kjH",
        "outputId": "d8ffa558-8377-4146-9eac-5c37806a0ff1"
      },
      "source": [
        "if config.model_name != \"\":\n",
        "    test_ds = BaseDataset(test, config.model_name, include_labels=False)\n",
        "    print(test_ds[0])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([     0,      6,  38033,  91262,  20546,  85149,    471,  58380,    641,\n",
            "          8062,   6004,    460,      2,      2,      6,  38033,  91262,  20546,\n",
            "         85149,     15, 206327,     12,    361, 182198,  26819,     74,      6,\n",
            "        196859,   1026,      4,  15297,     16,    967,   9261,  41162, 156793,\n",
            "         64382,  46297, 103766,   1404,   7294,   1293,    125, 222600,   5725,\n",
            "         11515,      6,  38033,  91262,  20546,  85149,    641,  22274,    361,\n",
            "        182198,  26819,    629,      6, 196859,   1026,      4,  15297,    421,\n",
            "         11645,   3813,    125,  24939,  62573,  39477,      5, 233097,   4429,\n",
            "         45951,  25594,    871,  56980,   4149,   1471,    998,  23263,    646,\n",
            "          1293,    125,  35056,  56980,   4149,   1471,    998,  20546,  85149,\n",
            "         47211,  12797,  27193,    421,   5564, 220307,   9331,    287,   3765,\n",
            "          3946,  13430, 120116,    125,      6,  38033,  91262,  20546,  85149,\n",
            "           471, 222600,   5725,  53812,   9729, 204778,    646,  17035,    871,\n",
            "         33171,    838,    646,  21191,  41162, 156793,  64382,  46297,  12189,\n",
            "          1748,   1780,  26252,   4029,    125,  82645, 209393,    209,   9512,\n",
            "           471,  78087,    646,   2093,      6,  38033,  91262,  20546,  85149,\n",
            "          1142,  31160,      5,  31598,      5,  33142, 160674,    646,  77022,\n",
            "         10067, 166922,  26252,   1896,   8785,   3813,    125,  31160,      5,\n",
            "         31598,      5,  33142, 160674,   3946,    287,  13325,   4592,   1187,\n",
            "         12189, 201742,   1293, 207411,   8771,  74163,   4846, 157426, 138314,\n",
            "           646, 191604,   4029,   5349,    460,    125,  47211,  12797,    702,\n",
            "          9512,    471,  78087,    421,  21191,  22009,   4415, 188408,  41162,\n",
            "        156793,  64382,  46297, 115739,  77666,  51476, 151576,  41657,    659,\n",
            "          9917,    125,   9512,   3576,    421,      6,  38033,  91262,  20546,\n",
            "         85149,   1142,    729,   9512,    471,  78087,    421,  70159,  85134,\n",
            "        188408,  41162, 156793,  64382,  46297, 115739,  77666,  51476, 151576,\n",
            "         41657,    659,    125,  64021,   9512,  21191,      6, 170555,   3558,\n",
            "        159967,  51476,    287,   3765, 227649,   6473,    421,  91298,    659,\n",
            "         17837,   2617,   9179,  73457,    287, 227649,   6473,  70159,  85134,\n",
            "        188408,  41162, 156793,  64382,  46297, 115739,  77666,  51476, 151576,\n",
            "           871,  13371,    998,  85134, 188408,  41162, 156793,  64382,  46297,\n",
            "        115739,  77666,  51476, 151576,    421,  41657,  76613,    471,    125,\n",
            "             6, 170555,   3558, 159967,  51476,    287,   3765,  35056,  91298,\n",
            "           659,  52170, 195730,   6927,   7231, 192872,    125,   5726,    646,\n",
            "          2021,   7231,  73451,  32534,  12797,      6,  38033,  91262,  20546,\n",
            "         85149,   1142,  73457,    287, 188408, 115474,   1471,  73254,    421,\n",
            "         41657,  76613,    471,    125,  39556,   9236, 227649,   6473,    287,\n",
            "          3765,      9, 105456,      6,  38033,  91262,  20546,  85149,   1142,\n",
            "        119253,   3282, 227649,   6473,    421,   1780,  67963,  76613,    471,\n",
            "           871,   3946,    471, 227649,   6473,    421,  13353, 203104, 160161,\n",
            "        118689,    838,    125,  54968,   1532,  59308,  26609,   8683,  13056,\n",
            "          8531, 156180,   6473,    421,   1780,      6,  38033,  91262,  20546,\n",
            "         85149,   1142,   5564, 221876,   2139,      2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'offset_mapping': [(0, 0), (0, 1), (0, 2), (2, 6), (6, 9), (9, 13), (13, 16), (16, 20), (20, 23), (23, 27), (27, 32), (32, 35), (0, 0), (0, 0), (0, 1), (0, 2), (2, 6), (6, 9), (9, 13), (13, 15), (15, 19), (19, 20), (20, 22), (22, 29), (29, 34), (34, 35), (35, 36), (36, 40), (40, 41), (41, 42), (42, 53), (53, 54), (54, 57), (57, 64), (64, 67), (67, 69), (69, 71), (71, 73), (73, 76), (76, 78), (78, 80), (80, 84), (84, 85), (87, 95), (95, 97), (97, 102), (103, 104), (104, 106), (106, 110), (110, 113), (113, 117), (117, 120), (120, 125), (125, 127), (127, 134), (134, 139), (139, 142), (142, 143), (143, 147), (147, 148), (148, 149), (149, 160), (160, 164), (164, 168), (168, 171), (171, 172), (172, 177), (177, 182), (182, 185), (185, 186), (186, 194), (194, 197), (197, 199), (199, 201), (201, 204), (204, 208), (208, 211), (211, 212), (212, 213), (213, 217), (217, 220), (220, 224), (224, 225), (225, 230), (230, 234), (234, 237), (237, 238), (238, 239), (239, 242), (242, 246), (246, 251), (251, 255), (255, 260), (260, 264), (264, 269), (269, 274), (274, 277), (277, 280), (280, 284), (284, 289), (289, 292), (292, 296), (296, 297), (297, 298), (298, 300), (300, 304), (304, 307), (307, 311), (311, 314), (314, 322), (322, 324), (324, 328), (328, 330), (330, 339), (339, 342), (342, 346), (346, 349), (349, 353), (353, 354), (354, 357), (357, 366), (366, 369), (369, 371), (371, 373), (373, 375), (375, 379), (379, 381), (381, 384), (384, 389), (389, 394), (394, 395), (397, 400), (400, 404), (405, 408), (408, 412), (412, 415), (415, 420), (420, 423), (423, 426), (426, 427), (427, 429), (429, 433), (433, 436), (436, 440), (440, 443), (443, 446), (446, 447), (447, 449), (449, 450), (450, 453), (453, 455), (455, 458), (458, 464), (464, 467), (467, 472), (472, 477), (477, 480), (480, 485), (485, 488), (488, 489), (489, 492), (492, 493), (493, 495), (495, 496), (496, 499), (499, 501), (501, 506), (506, 509), (509, 514), (514, 517), (517, 519), (519, 523), (523, 533), (533, 537), (537, 545), (545, 547), (547, 550), (550, 551), (551, 557), (557, 564), (564, 567), (567, 576), (576, 581), (581, 585), (585, 588), (588, 589), (589, 594), (594, 598), (598, 601), (601, 605), (605, 608), (608, 613), (613, 617), (617, 626), (626, 629), (629, 631), (631, 637), (637, 640), (640, 642), (642, 644), (644, 646), (646, 649), (649, 651), (651, 654), (654, 657), (657, 661), (661, 662), (662, 665), (665, 666), (666, 670), (670, 675), (675, 679), (679, 680), (680, 682), (682, 686), (686, 689), (689, 693), (693, 696), (696, 699), (699, 703), (703, 706), (706, 711), (711, 715), (715, 719), (719, 722), (722, 728), (728, 731), (731, 733), (733, 735), (735, 737), (737, 740), (740, 742), (742, 745), (745, 748), (748, 752), (752, 753), (753, 754), (754, 758), (758, 762), (762, 771), (771, 772), (772, 777), (777, 778), (778, 782), (782, 785), (785, 788), (788, 792), (792, 796), (796, 798), (798, 802), (802, 807), (807, 808), (808, 812), (812, 814), (814, 818), (818, 826), (826, 829), (829, 833), (833, 835), (835, 839), (839, 842), (842, 848), (848, 851), (851, 853), (853, 855), (855, 857), (857, 860), (860, 862), (862, 865), (865, 868), (868, 871), (871, 874), (874, 875), (875, 878), (878, 884), (884, 887), (887, 889), (889, 891), (891, 893), (893, 896), (896, 898), (898, 901), (901, 904), (904, 908), (908, 912), (912, 918), (918, 921), (921, 922), (922, 923), (923, 928), (928, 929), (929, 933), (933, 936), (936, 939), (939, 943), (943, 948), (948, 953), (953, 954), (954, 959), (959, 964), (964, 968), (968, 971), (971, 975), (975, 976), (976, 981), (981, 984), (984, 989), (989, 992), (992, 999), (999, 1003), (1003, 1007), (1007, 1008), (1008, 1010), (1010, 1014), (1014, 1017), (1017, 1021), (1021, 1024), (1024, 1032), (1032, 1035), (1035, 1041), (1041, 1045), (1045, 1046), (1046, 1058), (1058, 1062), (1062, 1066), (1066, 1072), (1072, 1075), (1075, 1076), (1076, 1079), (1079, 1085), (1085, 1089), (1089, 1091), (1091, 1094), (1094, 1098), (1098, 1099), (1099, 1102), (1102, 1103), (1103, 1105), (1105, 1109), (1109, 1112), (1112, 1116), (1116, 1119), (1119, 1125), (1125, 1127), (1127, 1131), (1131, 1133), (1133, 1137), (1137, 1140), (1140, 1146), (1146, 1152), (1152, 1155), (1155, 1158), (1158, 1163), (1163, 1166), (1166, 1170), (1170, 1172), (1172, 1176), (1176, 1181), (1181, 1189), (1189, 1197), (1197, 1201), (1201, 1202), (1202, 1203), (1203, 1206), (1206, 1211), (1211, 1214), (1214, 1216), (1216, 1218), (1218, 1220), (1220, 1221), (1221, 1225), (1225, 1227), (1227, 1231), (1231, 1234), (1234, 1235), (1235, 1237), (1237, 1241), (1241, 1244), (1244, 1248), (1248, 1251), (1251, 1256), (1256, 1264), (1264, 1266), (0, 0)], 'sequence_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], 'id': '22bff3dec', 'context': 'ज्वाला गुट्टा (जन्म: 7 सितंबर 1983; वर्धा, महाराष्ट्र) एक भारतीय बैडमिंटन खिलाडी हैं। \\n प्रारंभिक जीवन \\nज्वाला गुट्टा का जन्म 7 सितंबर 1983 को वर्धा, महाराष्ट्र में हुआ था। उनके पिता एम. क्रांति तेलुगु और मां येलन चीन से हैं। उनकी मां येलन गुट्टा पहली बार 1977 में अपने दादा जी के साथ भारत आई थीं। ज्वाला गुट्टा की प्रारंभिक पढ़ाई हैदराबाद से हुई और यहीं से उन्होंने बैडमिंटन खेलना भी शुरू किया। \\n कॅरियर \\n10 साल की उम्र से ही ज्वाला गुट्टा ने एस.एम. आरिफ से ट्रेनिंग लेना शुरू कर दिया था। एस.एम. आरिफ भारत के जाने माने खेल प्रशिक्षक हैं जिन्हें द्रोणाचार्य अवार्ड से सम्मानित किया गया है। पहली बार 13 साल की उम्र में उन्होंने मिनी नेशनल बैडमिंटन चैंपियनशिप जीती थी। साल 2000 में ज्वाला गुट्टा ने 17 साल की उम्र में जूनियर नेशनल बैडमिंटन चैंपियनशिप जीती। इसी साल उन्होंने श्रुति कुरियन के साथ डबल्स में जोड़ी बनाते हुए महिलाओं के डबल्स जूनियर नेशनल बैडमिंटन चैंपियनशिप और सीनियर नेशनल बैडमिंटन चैंपियनशिप में जीत हासिल की। श्रुति कुरियन के साथ उनकी जोड़ी काफी लंबे समय तक चली। 2002 से 2008 तक लगातार सात बार ज्वाला गुट्टा ने महिलाओं के नेशनल युगल प्रतियोगिता में जीत हासिल की।[2]\\nमहिला डबल्स के साथ-साथ ज्वाला गुट्टा ने मिश्रित डबल्स में भी सफलता हासिल की और भारत की डबल्स में सबसे बेहतरीन खिलाड़ी बनीं।[3] 2010 कॉमनवेल्थ गेम्स में भी ज्वाला गुट्टा ने अपने पार्टनर अश्विनी पोनप्पा के साथ भारत के लिए स्वर्ण पदक जीता। कॉमनवेल्थ गेम्स के बाद से एक बार फिर ज्वाला गुट्टा भारतीय बैडमिंटन में चर्चा का विषय बन गई हैं।[4][5]\\nग्लासगो में आयोजित कॉमनवेल्थ गेम्स, 2014 में ज्वाला गुट्टा ने स्वर्ण पदक हासिल किया।\\n व्यक्तिगत जीवन \\nमैदान पर बाएं हाथ से तेज-तर्रार शॉट लगाने वाली ज्वाला निजी जिंदगी में भी काफी तेज और चर्चाओं में छाई रहती हैं। ज्वाला ने 2005 में बैडमिंटन खिलाड़ी चेतन आनंद से शादी की थी, 29 जून 2011 को उन्होंने अपने पति पूर्व बैडमिंटन खिलाड़ी चेतन आनंद से तलाक लिया है। चेतन आनंद भी एक बेहतरीन भारतीय बैडमिंटन खिलाड़ी हैं।\\n फिल्मोग्राफी \\nGunde Jaari Gallanthayyinde[6] \\nफुगली (2014)\\n उपलब्धियां \\nरिकॉर्ड 13 बार नेशनल बैडमिंटन चैंपियनशिप की विजेता। \\nभारत की सबसे बेहतरीन डबल्स प्लेयर। \\nसाल 2011 में उन्हें “अर्जुन पुरस्कार” से सम्मानित किया गया। \\nराष्ट्रमंडल खेल, 2014 (ग्लासगो) में स्वर्ण पदक जीता। \\n चित्र दीर्घा \\n\\n\\nवी दीजू और ज्वाला गुट्टा\\nकेबीसी के सेट पर सुशील कुमार, ज्वाला गुट्टा, लिएंडर पेस, श्रीसंत\\nकेबीसी के सेट पर सुशील कुमार, ज्वाला गुट्टा, लिएंडर पेस, श्रीसंत\\n\\n सन्दर्भ \\n\\n बाहरी कड़ियाँ \\n\\n\\n\\n\\n\\nश्रेणी:हिन्द की बेटियाँ\\nश्रेणी:विकिपरियोजना हिन्द की बेटियाँ\\nश्रेणी:भारत के खिलाड़ी\\nश्रेणी:1983 में जन्मे लोग\\nश्रेणी:जीवित लोग\\nश्रेणी:भारतीय महिला बैडमिंटन खिलाड़ी\\nश्रेणी:राष्ट्रमंडल खेलों के पदक प्राप्तकर्ता\\nश्रेणी:महाराष्ट्र के लोग\\nश्रेणी:बैडमिंटन खिलाड़ी', 'question': 'ज्वाला गुट्टा की माँ का नाम क्या है'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4zuBuCCAv-8"
      },
      "source": [
        "# 🚗 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tJieX2AAueP",
        "outputId": "a0a99196-543c-4714-ca56-2da057b20b80"
      },
      "source": [
        "if config.model_name != \"\":\n",
        "    print(T.AutoConfig.from_pretrained(config.model_name))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XLMRobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"language\": \"english\",\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"name\": \"XLMRoberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZtghUknA1b8"
      },
      "source": [
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__()\n",
        "\n",
        "        self.auto_config = T.AutoConfig.from_pretrained(model_name)\n",
        "        self.auto_config.update({\n",
        "            \"hidden_dropout_prob\": config.dropout,\n",
        "            \"layer_norm_eps\": 1e-7,\n",
        "        })\n",
        "\n",
        "        self.auto_model = T.AutoModel.from_pretrained(model_name, config=self.auto_config, add_pooling_layer=False)\n",
        "        self.qa_outputs = nn.Linear(self.auto_config.hidden_size, 2)\n",
        "\n",
        "        if config.init_weights:\n",
        "            self._init_weights(self.qa_outputs)\n",
        "\n",
        "        if config.init_layers > 0:\n",
        "            self._init_layers()\n",
        "        \n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.auto_config.initializer_range)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "    def _init_layers(self):\n",
        "        # re-init pooler\n",
        "        # self.auto_model.pooler.dense.weight.data.normal_(mean=0.0, std=self.auto_model.config.initializer_range)\n",
        "        # self.auto_model.pooler.dense.bias.data.zero_()\n",
        "        # for p in self.auto_model.pooler.parameters():\n",
        "        #     p.requires_grad = True\n",
        "\n",
        "        # re-init encoder\n",
        "        layers = self.auto_model.encoder.layer[-config.init_layers:]\n",
        "        for layer in layers:\n",
        "            for module in layer.modules():\n",
        "                if isinstance(module, nn.Linear):\n",
        "                    # Slightly different from the TF version which uses truncated_normal for initialization\n",
        "                    # cf https://github.com/pytorch/pytorch/pull/5617\n",
        "                    module.weight.data.normal_(mean=0.0, std=self.auto_model.config.initializer_range)\n",
        "                    if module.bias is not None:\n",
        "                        module.bias.data.zero_()\n",
        "                elif isinstance(module, nn.Embedding):\n",
        "                    module.weight.data.normal_(mean=0.0, std=self.auto_model.config.initializer_range)\n",
        "                    if module.padding_idx is not None:\n",
        "                        module.weight.data[module.padding_idx].zero_()\n",
        "                elif isinstance(module, nn.LayerNorm):\n",
        "                    module.bias.data.zero_()\n",
        "                    module.weight.data.fill_(1.0)\n",
        "\n",
        "    def forward(\n",
        "        self, \n",
        "        input_ids, \n",
        "        attention_mask=None, \n",
        "    ):\n",
        "        outputs = self.auto_model(\n",
        "            input_ids,\n",
        "            attention_mask,\n",
        "        )\n",
        "\n",
        "        last_hidden_state = outputs[0]\n",
        "        \n",
        "        qa_logits = self.qa_outputs(last_hidden_state)\n",
        "        \n",
        "        start_logits, end_logits = qa_logits.split(1, dim=-1)\n",
        "        start_logits = start_logits.squeeze(-1)\n",
        "        end_logits = end_logits.squeeze(-1)\n",
        "    \n",
        "        return start_logits, end_logits"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1cZpfnGmuyI"
      },
      "source": [
        "class QAModel(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__()\n",
        "\n",
        "        self.auto_config = T.AutoConfig.from_pretrained(model_name)\n",
        "        self.auto_config.update({\n",
        "            \"hidden_dropout_prob\": config.dropout,\n",
        "            # \"layer_norm_eps\": 1e-7,\n",
        "        })\n",
        "\n",
        "        self.auto_model = T.AutoModelForQuestionAnswering.from_pretrained(model_name, config=self.auto_config)\n",
        "\n",
        "    def forward(\n",
        "        self, \n",
        "        input_ids, \n",
        "        attention_mask=None, \n",
        "    ):\n",
        "        outputs = self.auto_model(\n",
        "            input_ids,\n",
        "            attention_mask,\n",
        "        )\n",
        "\n",
        "        return outputs.start_logits, outputs.end_logits"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "36e4738a65474c2480db43003c0e36f6",
            "a3b118b28c694bc3a44344ddea1e90b5",
            "272caf9759de4a1a89b63e4e1fffa1b8",
            "4c19719da3504573a0e947d5c162a5b0",
            "bb3a405e64c84de3958e46ab593a1dcf",
            "8d189f9004384e899e229a2b4136650c",
            "6e6f2d21fad6452ab577f17fc2624c93",
            "cf301d6bd6bb41b9aa62cc6638502c5c",
            "4f55655a29b94410ba8b5071cdceffa5",
            "0d345378098c4d3bbb8e20bfdf480f4c",
            "c37d4f02973b4b6e95041d68c8043f29"
          ]
        },
        "id": "M92xPyOyCSQZ",
        "outputId": "34d19d5c-8a83-4d1e-8885-a4303b69bee3"
      },
      "source": [
        "if config.model_name != \"\":\n",
        "    if config.model_class == \"bare\":\n",
        "        model = BaseModel(config.model_name)\n",
        "    elif config.model_class == \"qa\":\n",
        "        model = QAModel(config.model_name)\n",
        "    print(model)\n",
        "\n",
        "    train_dataset = BaseDataset(train, config.model_name)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "    for features in train_loader:\n",
        "        output = model(features[\"input_ids\"], features[\"attention_mask\"])\n",
        "        print(output)\n",
        "        break"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36e4738a65474c2480db43003c0e36f6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'qa_outputs.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaseModel(\n",
            "  (auto_model): XLMRobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 1024)\n",
            "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (12): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (13): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (14): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (15): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (16): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (17): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (18): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (19): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (20): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (21): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (22): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (23): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",
            ")\n",
            "(tensor([[-0.3975, -0.1206, -0.5748,  ...,  0.1906, -0.2890,  0.0632],\n",
            "        [-0.3060, -0.1187,  0.0277,  ...,  0.0485,  0.0485,  0.0485],\n",
            "        [-0.3055, -0.5288, -0.3366,  ...,  0.0819,  0.0819,  0.0819],\n",
            "        [-0.2414, -0.6567, -0.0696,  ..., -0.4762, -0.1426,  0.0624]],\n",
            "       grad_fn=<SqueezeBackward1>), tensor([[ 0.3880,  0.6623,  0.7906,  ...,  0.8861,  0.6380, -0.0270],\n",
            "        [ 0.3180,  0.4705,  0.4791,  ..., -0.0856, -0.0856, -0.0856],\n",
            "        [ 0.1775,  0.7089,  0.3864,  ..., -0.0424, -0.0424, -0.0424],\n",
            "        [ 0.4582,  0.5835,  0.8310,  ...,  0.5266,  0.8035, -0.0364]],\n",
            "       grad_fn=<SqueezeBackward1>))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35wEQxmYCwUr",
        "outputId": "43fa1870-0d3e-441c-fa37-4b2ccc60faf0"
      },
      "source": [
        "if config.model_name != \"\":\n",
        "    for n, (name, tensor) in enumerate(list(model.named_parameters())):\n",
        "        print(f\"{n:>4}: {tensor.requires_grad}, {name}\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0: True, auto_model.embeddings.word_embeddings.weight\n",
            "   1: True, auto_model.embeddings.position_embeddings.weight\n",
            "   2: True, auto_model.embeddings.token_type_embeddings.weight\n",
            "   3: True, auto_model.embeddings.LayerNorm.weight\n",
            "   4: True, auto_model.embeddings.LayerNorm.bias\n",
            "   5: True, auto_model.encoder.layer.0.attention.self.query.weight\n",
            "   6: True, auto_model.encoder.layer.0.attention.self.query.bias\n",
            "   7: True, auto_model.encoder.layer.0.attention.self.key.weight\n",
            "   8: True, auto_model.encoder.layer.0.attention.self.key.bias\n",
            "   9: True, auto_model.encoder.layer.0.attention.self.value.weight\n",
            "  10: True, auto_model.encoder.layer.0.attention.self.value.bias\n",
            "  11: True, auto_model.encoder.layer.0.attention.output.dense.weight\n",
            "  12: True, auto_model.encoder.layer.0.attention.output.dense.bias\n",
            "  13: True, auto_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "  14: True, auto_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "  15: True, auto_model.encoder.layer.0.intermediate.dense.weight\n",
            "  16: True, auto_model.encoder.layer.0.intermediate.dense.bias\n",
            "  17: True, auto_model.encoder.layer.0.output.dense.weight\n",
            "  18: True, auto_model.encoder.layer.0.output.dense.bias\n",
            "  19: True, auto_model.encoder.layer.0.output.LayerNorm.weight\n",
            "  20: True, auto_model.encoder.layer.0.output.LayerNorm.bias\n",
            "  21: True, auto_model.encoder.layer.1.attention.self.query.weight\n",
            "  22: True, auto_model.encoder.layer.1.attention.self.query.bias\n",
            "  23: True, auto_model.encoder.layer.1.attention.self.key.weight\n",
            "  24: True, auto_model.encoder.layer.1.attention.self.key.bias\n",
            "  25: True, auto_model.encoder.layer.1.attention.self.value.weight\n",
            "  26: True, auto_model.encoder.layer.1.attention.self.value.bias\n",
            "  27: True, auto_model.encoder.layer.1.attention.output.dense.weight\n",
            "  28: True, auto_model.encoder.layer.1.attention.output.dense.bias\n",
            "  29: True, auto_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "  30: True, auto_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "  31: True, auto_model.encoder.layer.1.intermediate.dense.weight\n",
            "  32: True, auto_model.encoder.layer.1.intermediate.dense.bias\n",
            "  33: True, auto_model.encoder.layer.1.output.dense.weight\n",
            "  34: True, auto_model.encoder.layer.1.output.dense.bias\n",
            "  35: True, auto_model.encoder.layer.1.output.LayerNorm.weight\n",
            "  36: True, auto_model.encoder.layer.1.output.LayerNorm.bias\n",
            "  37: True, auto_model.encoder.layer.2.attention.self.query.weight\n",
            "  38: True, auto_model.encoder.layer.2.attention.self.query.bias\n",
            "  39: True, auto_model.encoder.layer.2.attention.self.key.weight\n",
            "  40: True, auto_model.encoder.layer.2.attention.self.key.bias\n",
            "  41: True, auto_model.encoder.layer.2.attention.self.value.weight\n",
            "  42: True, auto_model.encoder.layer.2.attention.self.value.bias\n",
            "  43: True, auto_model.encoder.layer.2.attention.output.dense.weight\n",
            "  44: True, auto_model.encoder.layer.2.attention.output.dense.bias\n",
            "  45: True, auto_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "  46: True, auto_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "  47: True, auto_model.encoder.layer.2.intermediate.dense.weight\n",
            "  48: True, auto_model.encoder.layer.2.intermediate.dense.bias\n",
            "  49: True, auto_model.encoder.layer.2.output.dense.weight\n",
            "  50: True, auto_model.encoder.layer.2.output.dense.bias\n",
            "  51: True, auto_model.encoder.layer.2.output.LayerNorm.weight\n",
            "  52: True, auto_model.encoder.layer.2.output.LayerNorm.bias\n",
            "  53: True, auto_model.encoder.layer.3.attention.self.query.weight\n",
            "  54: True, auto_model.encoder.layer.3.attention.self.query.bias\n",
            "  55: True, auto_model.encoder.layer.3.attention.self.key.weight\n",
            "  56: True, auto_model.encoder.layer.3.attention.self.key.bias\n",
            "  57: True, auto_model.encoder.layer.3.attention.self.value.weight\n",
            "  58: True, auto_model.encoder.layer.3.attention.self.value.bias\n",
            "  59: True, auto_model.encoder.layer.3.attention.output.dense.weight\n",
            "  60: True, auto_model.encoder.layer.3.attention.output.dense.bias\n",
            "  61: True, auto_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "  62: True, auto_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "  63: True, auto_model.encoder.layer.3.intermediate.dense.weight\n",
            "  64: True, auto_model.encoder.layer.3.intermediate.dense.bias\n",
            "  65: True, auto_model.encoder.layer.3.output.dense.weight\n",
            "  66: True, auto_model.encoder.layer.3.output.dense.bias\n",
            "  67: True, auto_model.encoder.layer.3.output.LayerNorm.weight\n",
            "  68: True, auto_model.encoder.layer.3.output.LayerNorm.bias\n",
            "  69: True, auto_model.encoder.layer.4.attention.self.query.weight\n",
            "  70: True, auto_model.encoder.layer.4.attention.self.query.bias\n",
            "  71: True, auto_model.encoder.layer.4.attention.self.key.weight\n",
            "  72: True, auto_model.encoder.layer.4.attention.self.key.bias\n",
            "  73: True, auto_model.encoder.layer.4.attention.self.value.weight\n",
            "  74: True, auto_model.encoder.layer.4.attention.self.value.bias\n",
            "  75: True, auto_model.encoder.layer.4.attention.output.dense.weight\n",
            "  76: True, auto_model.encoder.layer.4.attention.output.dense.bias\n",
            "  77: True, auto_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "  78: True, auto_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "  79: True, auto_model.encoder.layer.4.intermediate.dense.weight\n",
            "  80: True, auto_model.encoder.layer.4.intermediate.dense.bias\n",
            "  81: True, auto_model.encoder.layer.4.output.dense.weight\n",
            "  82: True, auto_model.encoder.layer.4.output.dense.bias\n",
            "  83: True, auto_model.encoder.layer.4.output.LayerNorm.weight\n",
            "  84: True, auto_model.encoder.layer.4.output.LayerNorm.bias\n",
            "  85: True, auto_model.encoder.layer.5.attention.self.query.weight\n",
            "  86: True, auto_model.encoder.layer.5.attention.self.query.bias\n",
            "  87: True, auto_model.encoder.layer.5.attention.self.key.weight\n",
            "  88: True, auto_model.encoder.layer.5.attention.self.key.bias\n",
            "  89: True, auto_model.encoder.layer.5.attention.self.value.weight\n",
            "  90: True, auto_model.encoder.layer.5.attention.self.value.bias\n",
            "  91: True, auto_model.encoder.layer.5.attention.output.dense.weight\n",
            "  92: True, auto_model.encoder.layer.5.attention.output.dense.bias\n",
            "  93: True, auto_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "  94: True, auto_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "  95: True, auto_model.encoder.layer.5.intermediate.dense.weight\n",
            "  96: True, auto_model.encoder.layer.5.intermediate.dense.bias\n",
            "  97: True, auto_model.encoder.layer.5.output.dense.weight\n",
            "  98: True, auto_model.encoder.layer.5.output.dense.bias\n",
            "  99: True, auto_model.encoder.layer.5.output.LayerNorm.weight\n",
            " 100: True, auto_model.encoder.layer.5.output.LayerNorm.bias\n",
            " 101: True, auto_model.encoder.layer.6.attention.self.query.weight\n",
            " 102: True, auto_model.encoder.layer.6.attention.self.query.bias\n",
            " 103: True, auto_model.encoder.layer.6.attention.self.key.weight\n",
            " 104: True, auto_model.encoder.layer.6.attention.self.key.bias\n",
            " 105: True, auto_model.encoder.layer.6.attention.self.value.weight\n",
            " 106: True, auto_model.encoder.layer.6.attention.self.value.bias\n",
            " 107: True, auto_model.encoder.layer.6.attention.output.dense.weight\n",
            " 108: True, auto_model.encoder.layer.6.attention.output.dense.bias\n",
            " 109: True, auto_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            " 110: True, auto_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            " 111: True, auto_model.encoder.layer.6.intermediate.dense.weight\n",
            " 112: True, auto_model.encoder.layer.6.intermediate.dense.bias\n",
            " 113: True, auto_model.encoder.layer.6.output.dense.weight\n",
            " 114: True, auto_model.encoder.layer.6.output.dense.bias\n",
            " 115: True, auto_model.encoder.layer.6.output.LayerNorm.weight\n",
            " 116: True, auto_model.encoder.layer.6.output.LayerNorm.bias\n",
            " 117: True, auto_model.encoder.layer.7.attention.self.query.weight\n",
            " 118: True, auto_model.encoder.layer.7.attention.self.query.bias\n",
            " 119: True, auto_model.encoder.layer.7.attention.self.key.weight\n",
            " 120: True, auto_model.encoder.layer.7.attention.self.key.bias\n",
            " 121: True, auto_model.encoder.layer.7.attention.self.value.weight\n",
            " 122: True, auto_model.encoder.layer.7.attention.self.value.bias\n",
            " 123: True, auto_model.encoder.layer.7.attention.output.dense.weight\n",
            " 124: True, auto_model.encoder.layer.7.attention.output.dense.bias\n",
            " 125: True, auto_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            " 126: True, auto_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            " 127: True, auto_model.encoder.layer.7.intermediate.dense.weight\n",
            " 128: True, auto_model.encoder.layer.7.intermediate.dense.bias\n",
            " 129: True, auto_model.encoder.layer.7.output.dense.weight\n",
            " 130: True, auto_model.encoder.layer.7.output.dense.bias\n",
            " 131: True, auto_model.encoder.layer.7.output.LayerNorm.weight\n",
            " 132: True, auto_model.encoder.layer.7.output.LayerNorm.bias\n",
            " 133: True, auto_model.encoder.layer.8.attention.self.query.weight\n",
            " 134: True, auto_model.encoder.layer.8.attention.self.query.bias\n",
            " 135: True, auto_model.encoder.layer.8.attention.self.key.weight\n",
            " 136: True, auto_model.encoder.layer.8.attention.self.key.bias\n",
            " 137: True, auto_model.encoder.layer.8.attention.self.value.weight\n",
            " 138: True, auto_model.encoder.layer.8.attention.self.value.bias\n",
            " 139: True, auto_model.encoder.layer.8.attention.output.dense.weight\n",
            " 140: True, auto_model.encoder.layer.8.attention.output.dense.bias\n",
            " 141: True, auto_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            " 142: True, auto_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            " 143: True, auto_model.encoder.layer.8.intermediate.dense.weight\n",
            " 144: True, auto_model.encoder.layer.8.intermediate.dense.bias\n",
            " 145: True, auto_model.encoder.layer.8.output.dense.weight\n",
            " 146: True, auto_model.encoder.layer.8.output.dense.bias\n",
            " 147: True, auto_model.encoder.layer.8.output.LayerNorm.weight\n",
            " 148: True, auto_model.encoder.layer.8.output.LayerNorm.bias\n",
            " 149: True, auto_model.encoder.layer.9.attention.self.query.weight\n",
            " 150: True, auto_model.encoder.layer.9.attention.self.query.bias\n",
            " 151: True, auto_model.encoder.layer.9.attention.self.key.weight\n",
            " 152: True, auto_model.encoder.layer.9.attention.self.key.bias\n",
            " 153: True, auto_model.encoder.layer.9.attention.self.value.weight\n",
            " 154: True, auto_model.encoder.layer.9.attention.self.value.bias\n",
            " 155: True, auto_model.encoder.layer.9.attention.output.dense.weight\n",
            " 156: True, auto_model.encoder.layer.9.attention.output.dense.bias\n",
            " 157: True, auto_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            " 158: True, auto_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            " 159: True, auto_model.encoder.layer.9.intermediate.dense.weight\n",
            " 160: True, auto_model.encoder.layer.9.intermediate.dense.bias\n",
            " 161: True, auto_model.encoder.layer.9.output.dense.weight\n",
            " 162: True, auto_model.encoder.layer.9.output.dense.bias\n",
            " 163: True, auto_model.encoder.layer.9.output.LayerNorm.weight\n",
            " 164: True, auto_model.encoder.layer.9.output.LayerNorm.bias\n",
            " 165: True, auto_model.encoder.layer.10.attention.self.query.weight\n",
            " 166: True, auto_model.encoder.layer.10.attention.self.query.bias\n",
            " 167: True, auto_model.encoder.layer.10.attention.self.key.weight\n",
            " 168: True, auto_model.encoder.layer.10.attention.self.key.bias\n",
            " 169: True, auto_model.encoder.layer.10.attention.self.value.weight\n",
            " 170: True, auto_model.encoder.layer.10.attention.self.value.bias\n",
            " 171: True, auto_model.encoder.layer.10.attention.output.dense.weight\n",
            " 172: True, auto_model.encoder.layer.10.attention.output.dense.bias\n",
            " 173: True, auto_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            " 174: True, auto_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            " 175: True, auto_model.encoder.layer.10.intermediate.dense.weight\n",
            " 176: True, auto_model.encoder.layer.10.intermediate.dense.bias\n",
            " 177: True, auto_model.encoder.layer.10.output.dense.weight\n",
            " 178: True, auto_model.encoder.layer.10.output.dense.bias\n",
            " 179: True, auto_model.encoder.layer.10.output.LayerNorm.weight\n",
            " 180: True, auto_model.encoder.layer.10.output.LayerNorm.bias\n",
            " 181: True, auto_model.encoder.layer.11.attention.self.query.weight\n",
            " 182: True, auto_model.encoder.layer.11.attention.self.query.bias\n",
            " 183: True, auto_model.encoder.layer.11.attention.self.key.weight\n",
            " 184: True, auto_model.encoder.layer.11.attention.self.key.bias\n",
            " 185: True, auto_model.encoder.layer.11.attention.self.value.weight\n",
            " 186: True, auto_model.encoder.layer.11.attention.self.value.bias\n",
            " 187: True, auto_model.encoder.layer.11.attention.output.dense.weight\n",
            " 188: True, auto_model.encoder.layer.11.attention.output.dense.bias\n",
            " 189: True, auto_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            " 190: True, auto_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            " 191: True, auto_model.encoder.layer.11.intermediate.dense.weight\n",
            " 192: True, auto_model.encoder.layer.11.intermediate.dense.bias\n",
            " 193: True, auto_model.encoder.layer.11.output.dense.weight\n",
            " 194: True, auto_model.encoder.layer.11.output.dense.bias\n",
            " 195: True, auto_model.encoder.layer.11.output.LayerNorm.weight\n",
            " 196: True, auto_model.encoder.layer.11.output.LayerNorm.bias\n",
            " 197: True, auto_model.encoder.layer.12.attention.self.query.weight\n",
            " 198: True, auto_model.encoder.layer.12.attention.self.query.bias\n",
            " 199: True, auto_model.encoder.layer.12.attention.self.key.weight\n",
            " 200: True, auto_model.encoder.layer.12.attention.self.key.bias\n",
            " 201: True, auto_model.encoder.layer.12.attention.self.value.weight\n",
            " 202: True, auto_model.encoder.layer.12.attention.self.value.bias\n",
            " 203: True, auto_model.encoder.layer.12.attention.output.dense.weight\n",
            " 204: True, auto_model.encoder.layer.12.attention.output.dense.bias\n",
            " 205: True, auto_model.encoder.layer.12.attention.output.LayerNorm.weight\n",
            " 206: True, auto_model.encoder.layer.12.attention.output.LayerNorm.bias\n",
            " 207: True, auto_model.encoder.layer.12.intermediate.dense.weight\n",
            " 208: True, auto_model.encoder.layer.12.intermediate.dense.bias\n",
            " 209: True, auto_model.encoder.layer.12.output.dense.weight\n",
            " 210: True, auto_model.encoder.layer.12.output.dense.bias\n",
            " 211: True, auto_model.encoder.layer.12.output.LayerNorm.weight\n",
            " 212: True, auto_model.encoder.layer.12.output.LayerNorm.bias\n",
            " 213: True, auto_model.encoder.layer.13.attention.self.query.weight\n",
            " 214: True, auto_model.encoder.layer.13.attention.self.query.bias\n",
            " 215: True, auto_model.encoder.layer.13.attention.self.key.weight\n",
            " 216: True, auto_model.encoder.layer.13.attention.self.key.bias\n",
            " 217: True, auto_model.encoder.layer.13.attention.self.value.weight\n",
            " 218: True, auto_model.encoder.layer.13.attention.self.value.bias\n",
            " 219: True, auto_model.encoder.layer.13.attention.output.dense.weight\n",
            " 220: True, auto_model.encoder.layer.13.attention.output.dense.bias\n",
            " 221: True, auto_model.encoder.layer.13.attention.output.LayerNorm.weight\n",
            " 222: True, auto_model.encoder.layer.13.attention.output.LayerNorm.bias\n",
            " 223: True, auto_model.encoder.layer.13.intermediate.dense.weight\n",
            " 224: True, auto_model.encoder.layer.13.intermediate.dense.bias\n",
            " 225: True, auto_model.encoder.layer.13.output.dense.weight\n",
            " 226: True, auto_model.encoder.layer.13.output.dense.bias\n",
            " 227: True, auto_model.encoder.layer.13.output.LayerNorm.weight\n",
            " 228: True, auto_model.encoder.layer.13.output.LayerNorm.bias\n",
            " 229: True, auto_model.encoder.layer.14.attention.self.query.weight\n",
            " 230: True, auto_model.encoder.layer.14.attention.self.query.bias\n",
            " 231: True, auto_model.encoder.layer.14.attention.self.key.weight\n",
            " 232: True, auto_model.encoder.layer.14.attention.self.key.bias\n",
            " 233: True, auto_model.encoder.layer.14.attention.self.value.weight\n",
            " 234: True, auto_model.encoder.layer.14.attention.self.value.bias\n",
            " 235: True, auto_model.encoder.layer.14.attention.output.dense.weight\n",
            " 236: True, auto_model.encoder.layer.14.attention.output.dense.bias\n",
            " 237: True, auto_model.encoder.layer.14.attention.output.LayerNorm.weight\n",
            " 238: True, auto_model.encoder.layer.14.attention.output.LayerNorm.bias\n",
            " 239: True, auto_model.encoder.layer.14.intermediate.dense.weight\n",
            " 240: True, auto_model.encoder.layer.14.intermediate.dense.bias\n",
            " 241: True, auto_model.encoder.layer.14.output.dense.weight\n",
            " 242: True, auto_model.encoder.layer.14.output.dense.bias\n",
            " 243: True, auto_model.encoder.layer.14.output.LayerNorm.weight\n",
            " 244: True, auto_model.encoder.layer.14.output.LayerNorm.bias\n",
            " 245: True, auto_model.encoder.layer.15.attention.self.query.weight\n",
            " 246: True, auto_model.encoder.layer.15.attention.self.query.bias\n",
            " 247: True, auto_model.encoder.layer.15.attention.self.key.weight\n",
            " 248: True, auto_model.encoder.layer.15.attention.self.key.bias\n",
            " 249: True, auto_model.encoder.layer.15.attention.self.value.weight\n",
            " 250: True, auto_model.encoder.layer.15.attention.self.value.bias\n",
            " 251: True, auto_model.encoder.layer.15.attention.output.dense.weight\n",
            " 252: True, auto_model.encoder.layer.15.attention.output.dense.bias\n",
            " 253: True, auto_model.encoder.layer.15.attention.output.LayerNorm.weight\n",
            " 254: True, auto_model.encoder.layer.15.attention.output.LayerNorm.bias\n",
            " 255: True, auto_model.encoder.layer.15.intermediate.dense.weight\n",
            " 256: True, auto_model.encoder.layer.15.intermediate.dense.bias\n",
            " 257: True, auto_model.encoder.layer.15.output.dense.weight\n",
            " 258: True, auto_model.encoder.layer.15.output.dense.bias\n",
            " 259: True, auto_model.encoder.layer.15.output.LayerNorm.weight\n",
            " 260: True, auto_model.encoder.layer.15.output.LayerNorm.bias\n",
            " 261: True, auto_model.encoder.layer.16.attention.self.query.weight\n",
            " 262: True, auto_model.encoder.layer.16.attention.self.query.bias\n",
            " 263: True, auto_model.encoder.layer.16.attention.self.key.weight\n",
            " 264: True, auto_model.encoder.layer.16.attention.self.key.bias\n",
            " 265: True, auto_model.encoder.layer.16.attention.self.value.weight\n",
            " 266: True, auto_model.encoder.layer.16.attention.self.value.bias\n",
            " 267: True, auto_model.encoder.layer.16.attention.output.dense.weight\n",
            " 268: True, auto_model.encoder.layer.16.attention.output.dense.bias\n",
            " 269: True, auto_model.encoder.layer.16.attention.output.LayerNorm.weight\n",
            " 270: True, auto_model.encoder.layer.16.attention.output.LayerNorm.bias\n",
            " 271: True, auto_model.encoder.layer.16.intermediate.dense.weight\n",
            " 272: True, auto_model.encoder.layer.16.intermediate.dense.bias\n",
            " 273: True, auto_model.encoder.layer.16.output.dense.weight\n",
            " 274: True, auto_model.encoder.layer.16.output.dense.bias\n",
            " 275: True, auto_model.encoder.layer.16.output.LayerNorm.weight\n",
            " 276: True, auto_model.encoder.layer.16.output.LayerNorm.bias\n",
            " 277: True, auto_model.encoder.layer.17.attention.self.query.weight\n",
            " 278: True, auto_model.encoder.layer.17.attention.self.query.bias\n",
            " 279: True, auto_model.encoder.layer.17.attention.self.key.weight\n",
            " 280: True, auto_model.encoder.layer.17.attention.self.key.bias\n",
            " 281: True, auto_model.encoder.layer.17.attention.self.value.weight\n",
            " 282: True, auto_model.encoder.layer.17.attention.self.value.bias\n",
            " 283: True, auto_model.encoder.layer.17.attention.output.dense.weight\n",
            " 284: True, auto_model.encoder.layer.17.attention.output.dense.bias\n",
            " 285: True, auto_model.encoder.layer.17.attention.output.LayerNorm.weight\n",
            " 286: True, auto_model.encoder.layer.17.attention.output.LayerNorm.bias\n",
            " 287: True, auto_model.encoder.layer.17.intermediate.dense.weight\n",
            " 288: True, auto_model.encoder.layer.17.intermediate.dense.bias\n",
            " 289: True, auto_model.encoder.layer.17.output.dense.weight\n",
            " 290: True, auto_model.encoder.layer.17.output.dense.bias\n",
            " 291: True, auto_model.encoder.layer.17.output.LayerNorm.weight\n",
            " 292: True, auto_model.encoder.layer.17.output.LayerNorm.bias\n",
            " 293: True, auto_model.encoder.layer.18.attention.self.query.weight\n",
            " 294: True, auto_model.encoder.layer.18.attention.self.query.bias\n",
            " 295: True, auto_model.encoder.layer.18.attention.self.key.weight\n",
            " 296: True, auto_model.encoder.layer.18.attention.self.key.bias\n",
            " 297: True, auto_model.encoder.layer.18.attention.self.value.weight\n",
            " 298: True, auto_model.encoder.layer.18.attention.self.value.bias\n",
            " 299: True, auto_model.encoder.layer.18.attention.output.dense.weight\n",
            " 300: True, auto_model.encoder.layer.18.attention.output.dense.bias\n",
            " 301: True, auto_model.encoder.layer.18.attention.output.LayerNorm.weight\n",
            " 302: True, auto_model.encoder.layer.18.attention.output.LayerNorm.bias\n",
            " 303: True, auto_model.encoder.layer.18.intermediate.dense.weight\n",
            " 304: True, auto_model.encoder.layer.18.intermediate.dense.bias\n",
            " 305: True, auto_model.encoder.layer.18.output.dense.weight\n",
            " 306: True, auto_model.encoder.layer.18.output.dense.bias\n",
            " 307: True, auto_model.encoder.layer.18.output.LayerNorm.weight\n",
            " 308: True, auto_model.encoder.layer.18.output.LayerNorm.bias\n",
            " 309: True, auto_model.encoder.layer.19.attention.self.query.weight\n",
            " 310: True, auto_model.encoder.layer.19.attention.self.query.bias\n",
            " 311: True, auto_model.encoder.layer.19.attention.self.key.weight\n",
            " 312: True, auto_model.encoder.layer.19.attention.self.key.bias\n",
            " 313: True, auto_model.encoder.layer.19.attention.self.value.weight\n",
            " 314: True, auto_model.encoder.layer.19.attention.self.value.bias\n",
            " 315: True, auto_model.encoder.layer.19.attention.output.dense.weight\n",
            " 316: True, auto_model.encoder.layer.19.attention.output.dense.bias\n",
            " 317: True, auto_model.encoder.layer.19.attention.output.LayerNorm.weight\n",
            " 318: True, auto_model.encoder.layer.19.attention.output.LayerNorm.bias\n",
            " 319: True, auto_model.encoder.layer.19.intermediate.dense.weight\n",
            " 320: True, auto_model.encoder.layer.19.intermediate.dense.bias\n",
            " 321: True, auto_model.encoder.layer.19.output.dense.weight\n",
            " 322: True, auto_model.encoder.layer.19.output.dense.bias\n",
            " 323: True, auto_model.encoder.layer.19.output.LayerNorm.weight\n",
            " 324: True, auto_model.encoder.layer.19.output.LayerNorm.bias\n",
            " 325: True, auto_model.encoder.layer.20.attention.self.query.weight\n",
            " 326: True, auto_model.encoder.layer.20.attention.self.query.bias\n",
            " 327: True, auto_model.encoder.layer.20.attention.self.key.weight\n",
            " 328: True, auto_model.encoder.layer.20.attention.self.key.bias\n",
            " 329: True, auto_model.encoder.layer.20.attention.self.value.weight\n",
            " 330: True, auto_model.encoder.layer.20.attention.self.value.bias\n",
            " 331: True, auto_model.encoder.layer.20.attention.output.dense.weight\n",
            " 332: True, auto_model.encoder.layer.20.attention.output.dense.bias\n",
            " 333: True, auto_model.encoder.layer.20.attention.output.LayerNorm.weight\n",
            " 334: True, auto_model.encoder.layer.20.attention.output.LayerNorm.bias\n",
            " 335: True, auto_model.encoder.layer.20.intermediate.dense.weight\n",
            " 336: True, auto_model.encoder.layer.20.intermediate.dense.bias\n",
            " 337: True, auto_model.encoder.layer.20.output.dense.weight\n",
            " 338: True, auto_model.encoder.layer.20.output.dense.bias\n",
            " 339: True, auto_model.encoder.layer.20.output.LayerNorm.weight\n",
            " 340: True, auto_model.encoder.layer.20.output.LayerNorm.bias\n",
            " 341: True, auto_model.encoder.layer.21.attention.self.query.weight\n",
            " 342: True, auto_model.encoder.layer.21.attention.self.query.bias\n",
            " 343: True, auto_model.encoder.layer.21.attention.self.key.weight\n",
            " 344: True, auto_model.encoder.layer.21.attention.self.key.bias\n",
            " 345: True, auto_model.encoder.layer.21.attention.self.value.weight\n",
            " 346: True, auto_model.encoder.layer.21.attention.self.value.bias\n",
            " 347: True, auto_model.encoder.layer.21.attention.output.dense.weight\n",
            " 348: True, auto_model.encoder.layer.21.attention.output.dense.bias\n",
            " 349: True, auto_model.encoder.layer.21.attention.output.LayerNorm.weight\n",
            " 350: True, auto_model.encoder.layer.21.attention.output.LayerNorm.bias\n",
            " 351: True, auto_model.encoder.layer.21.intermediate.dense.weight\n",
            " 352: True, auto_model.encoder.layer.21.intermediate.dense.bias\n",
            " 353: True, auto_model.encoder.layer.21.output.dense.weight\n",
            " 354: True, auto_model.encoder.layer.21.output.dense.bias\n",
            " 355: True, auto_model.encoder.layer.21.output.LayerNorm.weight\n",
            " 356: True, auto_model.encoder.layer.21.output.LayerNorm.bias\n",
            " 357: True, auto_model.encoder.layer.22.attention.self.query.weight\n",
            " 358: True, auto_model.encoder.layer.22.attention.self.query.bias\n",
            " 359: True, auto_model.encoder.layer.22.attention.self.key.weight\n",
            " 360: True, auto_model.encoder.layer.22.attention.self.key.bias\n",
            " 361: True, auto_model.encoder.layer.22.attention.self.value.weight\n",
            " 362: True, auto_model.encoder.layer.22.attention.self.value.bias\n",
            " 363: True, auto_model.encoder.layer.22.attention.output.dense.weight\n",
            " 364: True, auto_model.encoder.layer.22.attention.output.dense.bias\n",
            " 365: True, auto_model.encoder.layer.22.attention.output.LayerNorm.weight\n",
            " 366: True, auto_model.encoder.layer.22.attention.output.LayerNorm.bias\n",
            " 367: True, auto_model.encoder.layer.22.intermediate.dense.weight\n",
            " 368: True, auto_model.encoder.layer.22.intermediate.dense.bias\n",
            " 369: True, auto_model.encoder.layer.22.output.dense.weight\n",
            " 370: True, auto_model.encoder.layer.22.output.dense.bias\n",
            " 371: True, auto_model.encoder.layer.22.output.LayerNorm.weight\n",
            " 372: True, auto_model.encoder.layer.22.output.LayerNorm.bias\n",
            " 373: True, auto_model.encoder.layer.23.attention.self.query.weight\n",
            " 374: True, auto_model.encoder.layer.23.attention.self.query.bias\n",
            " 375: True, auto_model.encoder.layer.23.attention.self.key.weight\n",
            " 376: True, auto_model.encoder.layer.23.attention.self.key.bias\n",
            " 377: True, auto_model.encoder.layer.23.attention.self.value.weight\n",
            " 378: True, auto_model.encoder.layer.23.attention.self.value.bias\n",
            " 379: True, auto_model.encoder.layer.23.attention.output.dense.weight\n",
            " 380: True, auto_model.encoder.layer.23.attention.output.dense.bias\n",
            " 381: True, auto_model.encoder.layer.23.attention.output.LayerNorm.weight\n",
            " 382: True, auto_model.encoder.layer.23.attention.output.LayerNorm.bias\n",
            " 383: True, auto_model.encoder.layer.23.intermediate.dense.weight\n",
            " 384: True, auto_model.encoder.layer.23.intermediate.dense.bias\n",
            " 385: True, auto_model.encoder.layer.23.output.dense.weight\n",
            " 386: True, auto_model.encoder.layer.23.output.dense.bias\n",
            " 387: True, auto_model.encoder.layer.23.output.LayerNorm.weight\n",
            " 388: True, auto_model.encoder.layer.23.output.LayerNorm.bias\n",
            " 389: True, qa_outputs.weight\n",
            " 390: True, qa_outputs.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6NSxPjSDAp0"
      },
      "source": [
        "# Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_stCiHpfE4Cj"
      },
      "source": [
        "def bert_optimizer(model):\n",
        "    named_parameters = list(model.named_parameters())    \n",
        "\n",
        "    if (\n",
        "        \"base\" in config.model_name\n",
        "        or \"L-12\" in config.model_name\n",
        "    ):\n",
        "        bert_parameters = named_parameters[:197]    \n",
        "        regressor_parameters = named_parameters[197:]\n",
        "        second_block = 69\n",
        "        third_block = 133\n",
        "\n",
        "    elif (\n",
        "        \"large\" in config.model_name\n",
        "        or \"L-24\" in config.model_name\n",
        "    ):\n",
        "        bert_parameters = named_parameters[:389]    \n",
        "        regressor_parameters = named_parameters[389:]\n",
        "        second_block = 133\n",
        "        third_block = 261\n",
        "\n",
        "    elif \"rembert\" in config.model_name:\n",
        "        bert_parameters = named_parameters[:519]\n",
        "        regressor_parameters = named_parameters[519:]\n",
        "        second_block = 199\n",
        "        third_block = 359\n",
        "        \n",
        "    regressor_group = [params for (name, params) in regressor_parameters]\n",
        "\n",
        "    parameters = []\n",
        "    parameters.append({\"params\": regressor_group})\n",
        "\n",
        "    for layer_num, (name, params) in enumerate(bert_parameters):\n",
        "        weight_decay = 0.0 if \"bias\" in name else config.weight_decay\n",
        "\n",
        "        if layer_num >= third_block:\n",
        "            lr = config.max_lr\n",
        "        elif layer_num >= second_block:\n",
        "            lr = config.lr\n",
        "        else:\n",
        "            lr = config.min_lr\n",
        "\n",
        "        parameters.append({\"params\": params, \"weight_decay\": weight_decay, \"lr\": lr})\n",
        "\n",
        "    return T.AdamW(parameters, eps=1e-7)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENcidivxDVIj"
      },
      "source": [
        "# Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkAGe7WFDWG4"
      },
      "source": [
        "def chaii_cross_entropy(preds, labels):\n",
        "    start_preds, end_preds = preds\n",
        "    start_labels, end_labels = labels\n",
        "    \n",
        "    start_loss = nn.CrossEntropyLoss(ignore_index=-1)(start_preds, start_labels)\n",
        "    end_loss = nn.CrossEntropyLoss(ignore_index=-1)(end_preds, end_labels)\n",
        "    total_loss = (start_loss + end_loss) / 2\n",
        "    return total_loss"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJr7FSz5KvLt"
      },
      "source": [
        "# Scoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXFVz_OVKu2O"
      },
      "source": [
        "def jaccard(row): \n",
        "    str1 = row[0]\n",
        "    str2 = row[1]\n",
        "    a = set(str1.lower().split()) \n",
        "    b = set(str2.lower().split())\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfqKjGpLaMMX"
      },
      "source": [
        "def get_result(result_df, fold=config.n_fold):\n",
        "    score = result_df[\"jaccard\"].mean()\n",
        "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
        "    if fold == config.n_fold:\n",
        "        wandb.log({\"CV\": score})\n",
        "    else:\n",
        "        wandb.log({f\"CV_fold{fold}\": score})"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7aZ38xCMG__"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD2wDdHMMMSc"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return \"%dm %ds\" % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrVjLs3H8DXV"
      },
      "source": [
        "def compute_grad_norm(parameters, norm_type=2.0):\n",
        "    \"\"\"Refer to torch.nn.utils.clip_grad_norm_\"\"\"\n",
        "    if isinstance(parameters, torch.Tensor):\n",
        "        parameters = [parameters]\n",
        "    parameters = [p for p in parameters if p.grad is not None]\n",
        "    norm_type = float(norm_type)\n",
        "    total_norm = 0\n",
        "    for p in parameters:\n",
        "        param_norm = p.grad.data.norm(norm_type)\n",
        "        total_norm += param_norm.item() ** norm_type\n",
        "    total_norm = total_norm ** (1. / norm_type)\n",
        "    return total_norm"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laoX2YvHMW40"
      },
      "source": [
        "def train_fn(train_loader, model, criterion, optimizer, scheduler, scaler, fold, epoch, device):\n",
        "    losses = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    start = time.time()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for step, features in enumerate(train_loader):\n",
        "        input_ids = features[\"input_ids\"].to(device)\n",
        "        attention_mask = features[\"attention_mask\"].to(device)\n",
        "        labels_start = features[\"start_position\"].to(device)\n",
        "        labels_end = features[\"end_position\"].to(device)\n",
        "        batch_size = labels_start.size(0)\n",
        "\n",
        "        with amp.autocast(enabled=Config.amp):\n",
        "            out_start, out_end = model(input_ids, attention_mask)\n",
        "            loss = criterion((out_start, out_end), (labels_start, labels_end))\n",
        "            losses.update(loss.item(), batch_size)\n",
        "            loss = loss / config.gradient_accumulation_steps\n",
        "            \n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if (step + 1) % config.gradient_accumulation_steps == 0:\n",
        "            scaler.unscale_(optimizer)\n",
        "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "        else:\n",
        "            grad_norm = compute_grad_norm(model.parameters())\n",
        "\n",
        "        end = time.time()\n",
        "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
        "            print(\n",
        "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
        "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
        "                f\"Loss: {losses.avg:.4f} \"\n",
        "                f\"Grad: {grad_norm:.4f} \"\n",
        "                f\"LR: {scheduler.get_lr()[0]:.6f} \"\n",
        "            )\n",
        "            # wandb.log({\n",
        "            #     \"step\": (epoch) * len(train_loader) + step,\n",
        "            #     f\"loss/fold{fold}\": losses.avg,\n",
        "            #     f\"grad/fold{fold}\": grad_norm,\n",
        "            #     f\"lr/fold{fold}\": scheduler.get_lr()[0],\n",
        "            # })\n",
        "\n",
        "    return losses.avg"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-4GZ8PcPpLt"
      },
      "source": [
        "def valid_fn(valid_loader, model, criterion, device):\n",
        "    losses = AverageMeter()\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    preds_start = []\n",
        "    preds_end = []\n",
        "    start = time.time()\n",
        "\n",
        "    for step, features in enumerate(valid_loader):\n",
        "        input_ids = features[\"input_ids\"].to(device)\n",
        "        attention_mask = features[\"attention_mask\"].to(device)\n",
        "        labels_start = features[\"start_position\"].to(device)\n",
        "        labels_end = features[\"end_position\"].to(device)\n",
        "        batch_size = labels_start.size(0)\n",
        "\n",
        "        # compute loss\n",
        "        with torch.no_grad():\n",
        "            out_start, out_end = model(input_ids, attention_mask)\n",
        "\n",
        "        loss = criterion((out_start, out_end), (labels_start, labels_end))\n",
        "        losses.update(loss.item(), batch_size)\n",
        "\n",
        "        preds_start.append(out_start.to(\"cpu\").numpy())\n",
        "        preds_end.append(out_end.to(\"cpu\").numpy())\n",
        "        # preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
        "        # preds.append(y_preds.to(\"cpu\").numpy())\n",
        "\n",
        "        end = time.time()\n",
        "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
        "            print(\n",
        "                f\"EVAL: [{step}/{len(valid_loader)}] \"\n",
        "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
        "                f\"Loss: {losses.avg:.4f} \"\n",
        "            )\n",
        "\n",
        "    predictions_start = np.concatenate(preds_start)\n",
        "    predictions_end = np.concatenate(preds_end)\n",
        "    return losses.avg, predictions_start, predictions_end"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aS_0cqjWy5P"
      },
      "source": [
        "# Postprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn5pkRxmW0z_"
      },
      "source": [
        "def postprocess_qa_predictions(examples, features, tokenizer, raw_predictions, n_best_size=20, max_answer_length=30):\n",
        "    all_start_logits, all_end_logits = raw_predictions\n",
        "    \n",
        "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
        "    features_per_example = collections.defaultdict(list)\n",
        "    for i, feature in enumerate(features):\n",
        "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
        "\n",
        "    predictions = collections.OrderedDict()\n",
        "\n",
        "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
        "\n",
        "    for example_index, example in examples.iterrows():\n",
        "        feature_indices = features_per_example[example_index]\n",
        "\n",
        "        min_null_score = None\n",
        "        valid_answers = []\n",
        "        \n",
        "        context = example[\"context\"]\n",
        "        for feature_index in feature_indices:\n",
        "            start_logits = all_start_logits[feature_index]\n",
        "            end_logits = all_end_logits[feature_index]\n",
        "\n",
        "            sequence_ids = features[feature_index][\"sequence_ids\"]\n",
        "            context_index = 1\n",
        "\n",
        "            features[feature_index][\"offset_mapping\"] = [\n",
        "                (o if sequence_ids[k] == context_index else None)\n",
        "                for k, o in enumerate(features[feature_index][\"offset_mapping\"])\n",
        "            ]\n",
        "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
        "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
        "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
        "            if min_null_score is None or min_null_score < feature_null_score:\n",
        "                min_null_score = feature_null_score\n",
        "\n",
        "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            for start_index in start_indexes:\n",
        "                for end_index in end_indexes:\n",
        "                    if (\n",
        "                        start_index >= len(offset_mapping)\n",
        "                        or end_index >= len(offset_mapping)\n",
        "                        or offset_mapping[start_index] is None\n",
        "                        or offset_mapping[end_index] is None\n",
        "                    ):\n",
        "                        continue\n",
        "                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
        "                        continue\n",
        "\n",
        "                    start_char = offset_mapping[start_index][0]\n",
        "                    end_char = offset_mapping[end_index][1]\n",
        "                    valid_answers.append(\n",
        "                        {\n",
        "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                            \"text\": context[start_char: end_char]\n",
        "                        }\n",
        "                    )\n",
        "        \n",
        "        if len(valid_answers) > 0:\n",
        "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
        "        else:\n",
        "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
        "        \n",
        "        predictions[example[\"id\"]] = best_answer[\"text\"]\n",
        "\n",
        "    return predictions"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUqyC9I8xyd9"
      },
      "source": [
        "# https://www.kaggle.com/nbroad/chaii-qa-torch-5-fold-with-post-processing-765\n",
        "def postpurocess_by_nbroad(preds_df):\n",
        "    bad_starts = [\".\", \",\", \"(\", \")\", \"-\", \"–\",  \",\", \";\"]\n",
        "    bad_endings = [\"...\", \"-\", \"(\", \")\", \"–\", \",\", \";\"]\n",
        "\n",
        "    cleaned_preds = []\n",
        "    for pred, context in preds_df[[\"prediction\", \"context\"]].to_numpy():\n",
        "        if pred == \"\":\n",
        "            cleaned_preds.append(pred)\n",
        "            continue\n",
        "        while any([pred.startswith(y) for y in bad_starts]):\n",
        "            pred = pred[1:]\n",
        "        while any([pred.endswith(y) for y in bad_endings]):\n",
        "            if pred.endswith(\"...\"):\n",
        "                pred = pred[:-3]\n",
        "            else:\n",
        "                pred = pred[:-1]\n",
        "\n",
        "        cleaned_preds.append(pred)\n",
        "\n",
        "    preds_df[\"prediction\"] = cleaned_preds\n",
        "\n",
        "    return preds_df"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vwcRHThRbcm"
      },
      "source": [
        "# Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKmu1ZdXRdA7"
      },
      "source": [
        "def train_loop(df, fold):\n",
        "\n",
        "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
        "\n",
        "    # ====================================================\n",
        "    # Data Loader\n",
        "    # ====================================================\n",
        "    trn_idx = df[df[\"fold\"] != fold].index\n",
        "    val_idx = df[df[\"fold\"] == fold].index\n",
        "\n",
        "    train_folds = df.loc[trn_idx].reset_index(drop=True)\n",
        "    valid_folds = df.loc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    train_dataset = BaseDataset(train_folds, config.model_name)\n",
        "    valid_dataset = BaseDataset(valid_folds, config.model_name)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=4,\n",
        "        pin_memory=True,\n",
        "        drop_last=False,\n",
        "    )\n",
        "\n",
        "    # ====================================================\n",
        "    # Optimizer\n",
        "    # ====================================================\n",
        "    def get_optimizer(model):\n",
        "        if config.optimizer == \"Adam\":\n",
        "            optimizer = Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
        "        elif config.optimizer == \"AdamW\":\n",
        "            optimizer = T.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
        "        elif config.optimizer == \"BertAdamW\":\n",
        "            optimizer = bert_optimizer(model)\n",
        "        return optimizer\n",
        "\n",
        "    # ====================================================\n",
        "    # Scheduler\n",
        "    # ====================================================\n",
        "    def get_scheduler(optimizer):\n",
        "        # num_data = len(train_folds)\n",
        "        num_data = len(train_dataset)\n",
        "        num_steps = num_data // (config.batch_size * config.gradient_accumulation_steps) * config.epochs\n",
        "\n",
        "        if config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
        "            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=num_steps, T_mult=1, eta_min=config.min_lr, last_epoch=-1)\n",
        "        elif config.scheduler == \"CosineAnnealingLR\":\n",
        "            scheduler = CosineAnnealingLR(optimizer, T_max=num_steps, eta_min=config.min_lr, last_epoch=-1)\n",
        "        elif config.scheduler == \"CosineAnnealingWarmupRestarts\":\n",
        "            scheduler = CosineAnnealingWarmupRestarts(\n",
        "                optimizer, first_cycle_steps=num_steps, max_lr=config.lr, min_lr=config.min_lr, warmup_steps=(num_steps // 10)\n",
        "            )\n",
        "        elif config.scheduler == \"get_cosine_schedule_with_warmup\":\n",
        "            scheduler = T.get_cosine_schedule_with_warmup(\n",
        "                optimizer, num_training_steps=num_steps, num_warmup_steps=(num_steps // 10)\n",
        "            )\n",
        "        return scheduler\n",
        "\n",
        "    # ====================================================\n",
        "    # Model\n",
        "    # ====================================================\n",
        "    if config.model_class == \"bare\":\n",
        "        model = BaseModel(config.model_name)\n",
        "    elif config.model_class == \"qa\":\n",
        "        model = QAModel(config.model_name)\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = get_optimizer(model)\n",
        "    scaler = amp.GradScaler(enabled=Config.amp)\n",
        "    scheduler = get_scheduler(optimizer)\n",
        "\n",
        "    # ====================================================\n",
        "    # Criterion\n",
        "    # ====================================================\n",
        "    def get_criterion():\n",
        "        if config.criterion == \"CrossEntropyLoss\":\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "        elif config.criterion == \"BCEWithLogitsLoss\":\n",
        "            criterion = nn.BCEWithLogitsLoss()\n",
        "        elif config.criterion == \"MSELoss\":\n",
        "            criterion = nn.MSELoss()\n",
        "        elif config.criterion == \"ChaiiCrossEntropyLoss\":\n",
        "            criterion = chaii_cross_entropy\n",
        "        return criterion\n",
        "\n",
        "    criterion = get_criterion()\n",
        "\n",
        "    # ====================================================\n",
        "    # Loop\n",
        "    # ====================================================\n",
        "    best_score = -1\n",
        "    best_loss = np.inf\n",
        "    best_preds = None\n",
        "\n",
        "    wandb.watch(model, log_freq=Config.print_freq)\n",
        "\n",
        "    for epoch in range(config.epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # train\n",
        "        avg_loss = train_fn(train_loader, model, criterion, optimizer, scheduler, scaler, fold, epoch, device)\n",
        "\n",
        "        # eval\n",
        "        avg_val_loss, preds_start, preds_end = valid_fn(valid_loader, model, criterion, device)\n",
        "\n",
        "        # postprocess 1\n",
        "        predictions = postprocess_qa_predictions(\n",
        "            valid_folds, valid_dataset.features, valid_dataset.tokenizer, (preds_start, preds_end)\n",
        "        )\n",
        "\n",
        "        oof_df = valid_folds[[\"id\", \"context\", \"answer_text\"]]\n",
        "        oof_df[\"prediction\"] = oof_df['id'].apply(lambda r: predictions[r])\n",
        "\n",
        "        # postprocess 2\n",
        "        oof_df = postpurocess_by_nbroad(oof_df)\n",
        "\n",
        "        # scoring\n",
        "        oof_df['jaccard'] = oof_df[['answer_text', 'prediction']].apply(jaccard, axis=1)\n",
        "        score = oof_df[\"jaccard\"].mean()\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        LOGGER.info(f\"Epoch {epoch+1} - Score: {score}, Train Loss: {avg_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Time: {elapsed:.0f}s\")\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            f\"val_loss/fold{fold}\": avg_val_loss,\n",
        "            f\"score/fold{fold}\": score,\n",
        "        })\n",
        "        if avg_val_loss < best_loss:\n",
        "            best_score = score\n",
        "            best_loss = avg_val_loss\n",
        "            best_preds = predictions\n",
        "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Model. score: {best_score:.4f}, loss: {best_loss:.4f}\")\n",
        "\n",
        "            model_subdir = MODEL_DIR + f\"fold{fold}/\"\n",
        "            os.makedirs(model_subdir, exist_ok=True)\n",
        "            torch.save(model.state_dict(), f\"{model_subdir}/pytorch_model.bin\")\n",
        "            with open(f'{model_subdir}/preds.json', 'w') as f:\n",
        "                f.write(json.dumps(predictions, sort_keys=True, indent=4, ensure_ascii=False))\n",
        "            model.auto_config.save_pretrained(model_subdir)\n",
        "            train_dataset.tokenizer.save_pretrained(model_subdir)\n",
        "\n",
        "    valid_folds[\"prediction\"] = valid_folds['id'].apply(lambda r: best_preds[r])\n",
        "    valid_folds['jaccard'] = valid_folds[['answer_text', 'prediction']].apply(jaccard, axis=1)\n",
        "\n",
        "    return valid_folds, best_score, best_loss"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znc9U4s9YPqs"
      },
      "source": [
        "# 🚀 Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIPgK02eYRCX"
      },
      "source": [
        "def main():\n",
        "    # ====================================================\n",
        "    # Training\n",
        "    # ====================================================\n",
        "    if Config.train:\n",
        "        oof_df = pd.DataFrame()\n",
        "        oof_result = []\n",
        "        for fold in range(config.n_fold):\n",
        "            seed_torch(seed + fold)\n",
        "\n",
        "            _oof_df, score, loss = train_loop(train, fold)\n",
        "            oof_df = pd.concat([oof_df, _oof_df])\n",
        "            oof_result.append([fold, score, loss])\n",
        "\n",
        "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
        "            get_result(_oof_df, fold)\n",
        "\n",
        "        # CV result\n",
        "        LOGGER.info(f\"========== CV ==========\")\n",
        "        get_result(oof_df)\n",
        "        \n",
        "        loss = statistics.mean([d[2] for d in oof_result])\n",
        "        wandb.log({\"loss\": loss})\n",
        "\n",
        "        table = wandb.Table(data=oof_result, columns = [\"fold\", \"score\", \"loss\"])\n",
        "        run.log({\"Fold Result\": table})\n",
        "        \n",
        "        # save result\n",
        "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"oof_df.csv\")\n",
        "\n",
        "        artifact = wandb.Artifact(config.model_name.replace('/', '-'), type='model')\n",
        "        artifact.add_dir(MODEL_DIR)\n",
        "        run.log_artifact(artifact)\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4Q3YuoeYiLS",
        "outputId": "f34a9ea6-a133-4944-cf82-b866d1b3acbf"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "========== fold: 0 training ==========\n",
            "Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'qa_outputs.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1][0/5982] Elapsed 0m 1s (remain 116m 50s) Loss: 6.1654 Grad: 5.6987 LR: 0.000000 \n",
            "Epoch: [1][100/5982] Elapsed 0m 58s (remain 56m 40s) Loss: 5.5192 Grad: 7.9162 LR: 0.000084 \n",
            "Epoch: [1][200/5982] Elapsed 1m 54s (remain 54m 59s) Loss: 3.8947 Grad: 6.1532 LR: 0.000167 \n",
            "Epoch: [1][300/5982] Elapsed 2m 51s (remain 53m 48s) Loss: 2.9398 Grad: 16.4977 LR: 0.000251 \n",
            "Epoch: [1][400/5982] Elapsed 3m 47s (remain 52m 45s) Loss: 2.4894 Grad: 14.4766 LR: 0.000335 \n",
            "Epoch: [1][500/5982] Elapsed 4m 43s (remain 51m 43s) Loss: 2.1770 Grad: 13.4975 LR: 0.000418 \n",
            "Epoch: [1][600/5982] Elapsed 5m 40s (remain 50m 44s) Loss: 1.9631 Grad: 15.2799 LR: 0.000502 \n",
            "Epoch: [1][700/5982] Elapsed 6m 36s (remain 49m 46s) Loss: 1.8082 Grad: 10.4813 LR: 0.000586 \n",
            "Epoch: [1][800/5982] Elapsed 7m 32s (remain 48m 48s) Loss: 1.6902 Grad: 19.0783 LR: 0.000669 \n",
            "Epoch: [1][900/5982] Elapsed 8m 29s (remain 47m 50s) Loss: 1.6073 Grad: 0.6474 LR: 0.000753 \n",
            "Epoch: [1][1000/5982] Elapsed 9m 25s (remain 46m 53s) Loss: 1.5379 Grad: 4.7147 LR: 0.000837 \n",
            "Epoch: [1][1100/5982] Elapsed 10m 21s (remain 45m 56s) Loss: 1.4692 Grad: 3.4237 LR: 0.000921 \n",
            "Epoch: [1][1200/5982] Elapsed 11m 18s (remain 44m 59s) Loss: 1.4253 Grad: 7.2599 LR: 0.001000 \n",
            "Epoch: [1][1300/5982] Elapsed 12m 14s (remain 44m 2s) Loss: 1.3936 Grad: 9.3497 LR: 0.001000 \n",
            "Epoch: [1][1400/5982] Elapsed 13m 10s (remain 43m 5s) Loss: 1.3666 Grad: 8.1562 LR: 0.000999 \n",
            "Epoch: [1][1500/5982] Elapsed 14m 7s (remain 42m 8s) Loss: 1.3488 Grad: 6.5448 LR: 0.000998 \n",
            "Epoch: [1][1600/5982] Elapsed 15m 3s (remain 41m 12s) Loss: 1.3272 Grad: 7.3746 LR: 0.000997 \n",
            "Epoch: [1][1700/5982] Elapsed 15m 59s (remain 40m 15s) Loss: 1.3069 Grad: 4.5353 LR: 0.000995 \n",
            "Epoch: [1][1800/5982] Elapsed 16m 56s (remain 39m 18s) Loss: 1.2795 Grad: 11.2796 LR: 0.000992 \n",
            "Epoch: [1][1900/5982] Elapsed 17m 52s (remain 38m 22s) Loss: 1.2560 Grad: 16.4303 LR: 0.000989 \n",
            "Epoch: [1][2000/5982] Elapsed 18m 48s (remain 37m 25s) Loss: 1.2410 Grad: 3.7691 LR: 0.000986 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1pdUFYKYmOM"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fEjvHZUbgpH"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}