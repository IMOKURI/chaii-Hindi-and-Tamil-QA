{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "chaii.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPNQ3EhOPGj6tjOI2B1UnfE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7c93ed481db94b38967637fea4ae35fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8555a716f5f4489d80c2fc2983c2babe",
              "IPY_MODEL_6caacf2867d6421abc45322156e1c967",
              "IPY_MODEL_625b70b578c24d6da65c0ff1df39ec99"
            ],
            "layout": "IPY_MODEL_ff2fcb75a8524e9f84f4607f3c3b4ad3"
          }
        },
        "8555a716f5f4489d80c2fc2983c2babe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f840d81fcf2648fbb21c9bcc3c7e6641",
            "placeholder": "​",
            "style": "IPY_MODEL_62243f0c5b2144c4b07f7a79254a321a",
            "value": "Downloading: 100%"
          }
        },
        "6caacf2867d6421abc45322156e1c967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4092e571264c4e38b8570d0f21110c10",
            "max": 179,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_547ea405337345fb861dcf1ac9e3bbae",
            "value": 179
          }
        },
        "625b70b578c24d6da65c0ff1df39ec99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_641efef8a3ae4beaa4683156ad575a93",
            "placeholder": "​",
            "style": "IPY_MODEL_dfe88ad423d8464ba86b256442b26b15",
            "value": " 179/179 [00:00&lt;00:00, 7.73kB/s]"
          }
        },
        "ff2fcb75a8524e9f84f4607f3c3b4ad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f840d81fcf2648fbb21c9bcc3c7e6641": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62243f0c5b2144c4b07f7a79254a321a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4092e571264c4e38b8570d0f21110c10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "547ea405337345fb861dcf1ac9e3bbae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "641efef8a3ae4beaa4683156ad575a93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfe88ad423d8464ba86b256442b26b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "544e8ba722e04a27add8bb2ede6edab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a19e6cf1390749f4999be35fd7bd1eea",
              "IPY_MODEL_a36c5a42f87b48eeb02159106cedb528",
              "IPY_MODEL_68f2a71832f442049d6bc5e6bcee97b1"
            ],
            "layout": "IPY_MODEL_4ef60073c0304d968a5ee469a98e5e6d"
          }
        },
        "a19e6cf1390749f4999be35fd7bd1eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcfb3d9660d54480bdc4b153a36a99b5",
            "placeholder": "​",
            "style": "IPY_MODEL_2496bf863649484a900d6c93dd65bf7a",
            "value": "Downloading: 100%"
          }
        },
        "a36c5a42f87b48eeb02159106cedb528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_632b78a74dcd47fcb258e77f69a7a609",
            "max": 606,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2edad0c78c254a1b993d787350f1fada",
            "value": 606
          }
        },
        "68f2a71832f442049d6bc5e6bcee97b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9019d0604974d39b4da30d78155a222",
            "placeholder": "​",
            "style": "IPY_MODEL_d56e39f166394fc7ae6103e3954c00ac",
            "value": " 606/606 [00:00&lt;00:00, 26.3kB/s]"
          }
        },
        "4ef60073c0304d968a5ee469a98e5e6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcfb3d9660d54480bdc4b153a36a99b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2496bf863649484a900d6c93dd65bf7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "632b78a74dcd47fcb258e77f69a7a609": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2edad0c78c254a1b993d787350f1fada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9019d0604974d39b4da30d78155a222": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d56e39f166394fc7ae6103e3954c00ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55a1db1d104d4a2e868e617cd36095a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43b348c785574c01a8a7810694669ba5",
              "IPY_MODEL_9956d355bdbc491f976bf9d1f8663b37",
              "IPY_MODEL_95bfbbce3cfe4128a5c99095fa3794b3"
            ],
            "layout": "IPY_MODEL_add8e8135925455781c3a1b7231f1d88"
          }
        },
        "43b348c785574c01a8a7810694669ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9544741b6ae144c5b103eeba9eaf290e",
            "placeholder": "​",
            "style": "IPY_MODEL_4b69088fba33446fa3004807c475d257",
            "value": "Downloading: 100%"
          }
        },
        "9956d355bdbc491f976bf9d1f8663b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57c7a5492ad64010b2a546f6e8170a74",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c41801cb6a7f44a191b29292b8bce784",
            "value": 5069051
          }
        },
        "95bfbbce3cfe4128a5c99095fa3794b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9d03d242945484983ecb860750fe265",
            "placeholder": "​",
            "style": "IPY_MODEL_8e614a4f021a40aeac65b434d654a454",
            "value": " 5.07M/5.07M [00:01&lt;00:00, 4.92MB/s]"
          }
        },
        "add8e8135925455781c3a1b7231f1d88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9544741b6ae144c5b103eeba9eaf290e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b69088fba33446fa3004807c475d257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57c7a5492ad64010b2a546f6e8170a74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c41801cb6a7f44a191b29292b8bce784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9d03d242945484983ecb860750fe265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e614a4f021a40aeac65b434d654a454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5864e15378740d4a6d70da6c2102a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d935556582854f6eba5591d3e6d20c04",
              "IPY_MODEL_c6b5944e16574ee7ae24f021a6cdcd3f",
              "IPY_MODEL_872ba6e4cc42464ca1667a5f657db5af"
            ],
            "layout": "IPY_MODEL_d0b9234fa7e14a8d999f36bcf6fec876"
          }
        },
        "d935556582854f6eba5591d3e6d20c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cea95718a11a49fb87b72f2f4bddc5b8",
            "placeholder": "​",
            "style": "IPY_MODEL_a783f6aa32fd4a649937be8358d80a6e",
            "value": "Downloading: 100%"
          }
        },
        "c6b5944e16574ee7ae24f021a6cdcd3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd4ca6c2ec3f437991b9376e8cc2bd1e",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51acacaee52a44e6abf2e4218c52d402",
            "value": 150
          }
        },
        "872ba6e4cc42464ca1667a5f657db5af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd0e1792b62d42d18ee0cb5b5c0fae8b",
            "placeholder": "​",
            "style": "IPY_MODEL_281eac8bec124df9bdbf607a1242eb84",
            "value": " 150/150 [00:00&lt;00:00, 6.10kB/s]"
          }
        },
        "d0b9234fa7e14a8d999f36bcf6fec876": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea95718a11a49fb87b72f2f4bddc5b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a783f6aa32fd4a649937be8358d80a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd4ca6c2ec3f437991b9376e8cc2bd1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51acacaee52a44e6abf2e4218c52d402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd0e1792b62d42d18ee0cb5b5c0fae8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "281eac8bec124df9bdbf607a1242eb84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36e4738a65474c2480db43003c0e36f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_272caf9759de4a1a89b63e4e1fffa1b8",
              "IPY_MODEL_4c19719da3504573a0e947d5c162a5b0",
              "IPY_MODEL_bb3a405e64c84de3958e46ab593a1dcf"
            ],
            "layout": "IPY_MODEL_a3b118b28c694bc3a44344ddea1e90b5"
          }
        },
        "272caf9759de4a1a89b63e4e1fffa1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e6f2d21fad6452ab577f17fc2624c93",
            "placeholder": "​",
            "style": "IPY_MODEL_8d189f9004384e899e229a2b4136650c",
            "value": "Downloading: 100%"
          }
        },
        "4c19719da3504573a0e947d5c162a5b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f55655a29b94410ba8b5071cdceffa5",
            "max": 2239666418,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf301d6bd6bb41b9aa62cc6638502c5c",
            "value": 2239666418
          }
        },
        "bb3a405e64c84de3958e46ab593a1dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c37d4f02973b4b6e95041d68c8043f29",
            "placeholder": "​",
            "style": "IPY_MODEL_0d345378098c4d3bbb8e20bfdf480f4c",
            "value": " 2.24G/2.24G [00:36&lt;00:00, 65.2MB/s]"
          }
        },
        "a3b118b28c694bc3a44344ddea1e90b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e6f2d21fad6452ab577f17fc2624c93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d189f9004384e899e229a2b4136650c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f55655a29b94410ba8b5071cdceffa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf301d6bd6bb41b9aa62cc6638502c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c37d4f02973b4b6e95041d68c8043f29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d345378098c4d3bbb8e20bfdf480f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IMOKURI/chaii-Hindi-and-Tamil-QA/blob/main/chaii.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p8HABKC9jNl"
      },
      "source": [
        "# 📔 About this notebook ...\n",
        "\n",
        "[chaii - Hindi and Tamil Question Answering](https://www.kaggle.com/c/chaii-hindi-and-tamil-question-answering/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U4_rc_e9rOY"
      },
      "source": [
        "# Memo\n",
        "\n",
        "\n",
        "\n",
        "## ToDo\n",
        "\n",
        "- [ ] [ラベルノイズ補正](https://www.kaggle.com/c/chaii-hindi-and-tamil-question-answering/discussion/264395)\n",
        "    - [ ] [これもかな](https://www.kaggle.com/c/chaii-hindi-and-tamil-question-answering/discussion/266109)\n",
        "- [x] [Post process でスコアアップ](https://www.kaggle.com/nbroad/chaii-qa-torch-5-fold-with-post-processing-765)\n",
        "- モデル\n",
        "    - [ ] [monsoon-nlp/hindi-tpu-electra](https://huggingface.co/monsoon-nlp/hindi-tpu-electra)\n",
        "    - [ ] [RemBERT](https://www.kaggle.com/c/chaii-hindi-and-tamil-question-answering/discussion/267827)\n",
        "    - [ ] [google/muril-base-cased](https://huggingface.co/google/muril-base-cased)\n",
        "    - その他 [multilingual & QA models](https://huggingface.co/models?filter=multilingual&pipeline_tag=question-answering)\n",
        "- [x] モデルクラスで  `AutoModelForQuestionAnswering` クラス を使ってみる\n",
        "\n",
        "## Done\n",
        "\n",
        "\n",
        "## Works Well\n",
        "\n",
        "\n",
        "## Doesn't Work\n",
        "\n",
        "\n",
        "## Not To Do\n",
        "\n",
        "- [2つのモデルを作る](https://www.kaggle.com/c/chaii-hindi-and-tamil-question-answering/discussion/267604) - [経緯](https://www.kaggle.com/c/chaii-hindi-and-tamil-question-answering/discussion/264749)\n",
        "- [位置によるペナルティを課す Loss](https://www.kaggle.com/c/chaii-hindi-and-tamil-question-answering/discussion/266832)\n",
        "\n",
        "\n",
        "## Additional Datasets\n",
        "\n",
        "Search from [here](https://www.kaggle.com/c/chaii-hindi-and-tamil-question-answering/discussion/264581).\n",
        "\n",
        "- [External Data - MLQA, XQUAD Preprocessing](https://www.kaggle.com/rhtsingh/external-data-mlqa-xquad-preprocessing) hindi のみ\n",
        "- [Squad_Translated_to_Tamil for Chaii](https://www.kaggle.com/msafi04/squad-translated-to-tamil-for-chaii) tamil のみ\n",
        "\n",
        "\n",
        "## Reference Notebooks\n",
        "\n",
        "- [ChAII - EDA & Baseline](https://www.kaggle.com/thedrcat/chaii-eda-baseline/)\n",
        "- [chaii QA - 5 Fold XLMRoberta Torch | FIT](https://www.kaggle.com/rhtsingh/chaii-qa-5-fold-xlmroberta-torch-fit/)\n",
        "- [chaii QA - 5 Fold XLMRoberta Torch | Infer](https://www.kaggle.com/rhtsingh/chaii-qa-5-fold-xlmroberta-torch-infer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VBhwVS89vKZ"
      },
      "source": [
        "# Prepare for Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEN6L1ol9d6d",
        "outputId": "ecf1c9b7-d414-4314-f275-fe0b4716c095"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Sep 14 15:32:07 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl14Cnli91Ol",
        "outputId": "a08c07c3-9354-4584-f086-c18a30630d9e"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import zipfile\n",
        "\n",
        "if os.path.exists('init.txt'):\n",
        "    print(\"Already initialized.\")\n",
        "\n",
        "else:\n",
        "    if 'google.colab' in sys.modules:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        dataset_dir = \"/content/drive/MyDrive/Datasets\"\n",
        "\n",
        "        # ====================================================\n",
        "        # Competition datasets\n",
        "        # ====================================================\n",
        "        with zipfile.ZipFile(f\"{dataset_dir}/chaii-hindi-and-tamil-question-answering.zip\", \"r\") as zp:\n",
        "            zp.extractall(path=\"./\")\n",
        "        # with zipfile.ZipFile(f\"{dataset_dir}/chaii-external-data-mlqa-xquad-preprocessing.zip\", \"r\") as zp:\n",
        "        #     zp.extractall(path=\"./\")\n",
        "        # with zipfile.ZipFile(f\"{dataset_dir}/chaii-Squad_Translated_to_Tamil.zip\", \"r\") as zp:\n",
        "        #     zp.extractall(path=\"./\")\n",
        "\n",
        "    # for StratifiedGroupKFold\n",
        "    # !pip uninstall -y scikit-learn\n",
        "    # !pip install --pre --extra-index https://pypi.anaconda.org/scipy-wheels-nightly/simple scikit-learn\n",
        "\n",
        "    # for MultilabelStratifiedKFold\n",
        "    # !pip install -q iterative-stratification\n",
        "\n",
        "    # for CosineAnnealingWarmupRestarts\n",
        "    # !pip install -qU 'git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup'\n",
        "\n",
        "    !pip install -q wandb\n",
        "    # !pip install -q optuna\n",
        "\n",
        "    # ====================================================\n",
        "    # Competition specific libraries\n",
        "    # ====================================================\n",
        "    !pip install -q transformers\n",
        "    !pip install -q sentencepiece\n",
        "    # !pip install -q textstat\n",
        "    # !pip install -q nlpaug\n",
        "\n",
        "    !touch init.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 7.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 170 kB 83.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 89.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 71.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 52 kB 2.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 83.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 81.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 4.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DXvMPm5_4h0"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB47hsio_5y6"
      },
      "source": [
        "# General libraries\n",
        "import collections\n",
        "import glob\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import statistics\n",
        "import time\n",
        "import warnings\n",
        "from contextlib import contextmanager\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.cuda.amp as amp\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import wandb\n",
        "# from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
        "# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error, jaccard_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold  # , StratifiedGroupKFold\n",
        "from torch.optim import SGD, Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyiVJefp4oOi"
      },
      "source": [
        "# Competition specific libraries\n",
        "# import nlpaug.augmenter.word as naw\n",
        "# import nlpaug.augmenter.sentence as nas\n",
        "# import nltk\n",
        "# import textstat\n",
        "import transformers as T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-snxxwfCAO92"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxr17nzJAS2c"
      },
      "source": [
        "#nltk.download('stopwords')\n",
        "#nltk.download('punkt')\n",
        "#nltk.download('wordnet')\n",
        "#nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxTu8mx-AXcw",
        "outputId": "abb82ef4-3abc-4be0-984d-40fc24c8cbe9"
      },
      "source": [
        "netrc = \"/content/drive/MyDrive/.netrc\" if 'google.colab' in sys.modules else \"../input/wandbtoken/.netrc\"\n",
        "!cp -f {netrc} ~/\n",
        "!wandb login\n",
        "\n",
        "wandb_tags = []"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WavcpUepAQOs"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    wandb_tags.append(torch.cuda.get_device_name(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_GYEnAnAqmJ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbzq6jTIAszZ"
      },
      "source": [
        "DATA_DIR = \"./\" if 'google.colab' in sys.modules else \"../input/chaii-hindi-and-tamil-question-answering/\"\n",
        "OUTPUT_DIR = \"./\"\n",
        "MODEL_DIR = \"./models/\"\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ey9Vh4CBMgo"
      },
      "source": [
        "train = pd.read_csv(DATA_DIR + \"train.csv\")\n",
        "test = pd.read_csv(DATA_DIR + \"test.csv\")\n",
        "sub = pd.read_csv(DATA_DIR + \"sample_submission.csv\")\n",
        "\n",
        "#external_squad_translated_tamil = pd.read_csv(DATA_DIR + \"squad_translated_tamil.csv\")\n",
        "#external_mlqa = pd.read_csv(DATA_DIR + \"mlqa_hindi.csv\")\n",
        "#external_xquad = pd.read_csv(DATA_DIR + \"xquad.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm2Lqm0KBeb_"
      },
      "source": [
        "#  Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWsNi7VmB9_M",
        "outputId": "a2d49d84-37ce-458c-94dd-689e27cbb721"
      },
      "source": [
        "# seed = random.randrange(10000)\n",
        "seed = 440\n",
        "print(seed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDIEcAvEBdqj"
      },
      "source": [
        "class Config:\n",
        "    wandb_entity = \"imokuri\"\n",
        "    wandb_project = \"chaii\"\n",
        "    print_freq = 100\n",
        "\n",
        "    preprocess = False\n",
        "    train = True\n",
        "    validate = False\n",
        "    inference = False\n",
        "\n",
        "    debug = False\n",
        "    num_debug_data = 50\n",
        "\n",
        "    amp = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI5SEjO0CS8k"
      },
      "source": [
        "config_defaults = {\n",
        "    \"seed\": seed,\n",
        "    # \"n_class\": 1,\n",
        "    \"n_fold\": 5,\n",
        "    \"epochs\": 2,\n",
        "    \"batch_size\": 4,\n",
        "    \"gradient_accumulation_steps\": 5,\n",
        "    \"max_grad_norm\": 1.0,\n",
        "    \"criterion\": \"ChaiiCrossEntropyLoss\",\n",
        "    \"optimizer\": \"BertAdamW\",\n",
        "    \"scheduler\": \"get_cosine_schedule_with_warmup\",\n",
        "    \"max_lr\": 5e-5,\n",
        "    \"lr\": 2e-5,\n",
        "    \"min_lr\": 1e-5,\n",
        "    \"weight_decay\": 0.01,\n",
        "    \"model_name\": \"deepset/xlm-roberta-large-squad2\",\n",
        "    # \"model_name\": \"deepset/xlm-roberta-base-squad2\",\n",
        "    # \"model_name\": \"google/rembert\",\n",
        "    \"model_class\": \"bare\", # bare, qa\n",
        "    \"max_len\": 384,\n",
        "    \"doc_stride\": 128,\n",
        "    \"dropout\": 0.0,\n",
        "    \"init_weights\": True,\n",
        "    \"init_layers\": 1,\n",
        "    # \"freeze_layers\": 0,\n",
        "    \"datasets\": [\n",
        "        \"mlqa:v1\",\n",
        "        \"xquad:v1\",\n",
        "        \"squad_translated_tamil:v1\",\n",
        "    ],\n",
        "    \"models\": [\n",
        "        \"base-models:v1\",\n",
        "    ]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1Pk66rRDTGC"
      },
      "source": [
        "if Config.debug:\n",
        "    config_defaults[\"n_fold\"] = 3\n",
        "    config_defaults[\"epochs\"] = 1\n",
        "    Config.print_freq = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB9WtvbYBtfN"
      },
      "source": [
        "if Config.train:\n",
        "    wandb_job_type = \"training\"\n",
        "\n",
        "elif Config.inference:\n",
        "    wandb_job_type = \"inference\"\n",
        "\n",
        "elif Config.validate:\n",
        "    wandb_job_type = \"validation\"\n",
        "\n",
        "elif Config.preprocess:\n",
        "    wandb_job_type = \"preprocess\"\n",
        "\n",
        "else:\n",
        "    wandb_job_type = \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2rVE3iK7Xaf"
      },
      "source": [
        "if Config.debug:\n",
        "    wandb_tags.append(\"debug\")\n",
        "    \n",
        "if Config.amp:\n",
        "    wandb_tags.append(\"amp\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "9kskKEy9Dyqk",
        "outputId": "ebc1aaaf-f038-4bdb-82c4-ad3f1b711de5"
      },
      "source": [
        "if Config.debug:\n",
        "    run = wandb.init(\n",
        "        entity=Config.wandb_entity,\n",
        "        project=Config.wandb_project,\n",
        "        config=config_defaults,\n",
        "        tags=wandb_tags,\n",
        "        mode=\"disabled\",\n",
        "    )\n",
        "else:\n",
        "    run = wandb.init(\n",
        "        entity=Config.wandb_entity,\n",
        "        project=Config.wandb_project,\n",
        "        config=config_defaults,\n",
        "        job_type=wandb_job_type,\n",
        "        tags=wandb_tags,\n",
        "        save_code=True,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.1<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">youthful-valley-9</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/imokuri/chaii\" target=\"_blank\">https://wandb.ai/imokuri/chaii</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/imokuri/chaii/runs/16cifk7p\" target=\"_blank\">https://wandb.ai/imokuri/chaii/runs/16cifk7p</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210914_153302-16cifk7p</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev3bvwDvEMuS"
      },
      "source": [
        "config = wandb.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF1pXRWoHy1_"
      },
      "source": [
        "# Load Artifacts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRSYiJXBD4oy"
      },
      "source": [
        "if config.datasets != []:\n",
        "    external_data = []\n",
        "    for name_version in config.datasets:\n",
        "        name, version = name_version.split(\":\")\n",
        "        os.makedirs(name, exist_ok=True)\n",
        "\n",
        "        if Config.debug:\n",
        "            artifact_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{name_version}\"\n",
        "            api = wandb.Api()\n",
        "            artifact = api.artifact(artifact_path)\n",
        "\n",
        "        else:\n",
        "            artifact_path = f\"{name_version}\"\n",
        "            artifact = run.use_artifact(artifact_path)\n",
        "\n",
        "        artifact.download(name)\n",
        "\n",
        "        df = pd.read_csv(f\"{name}/{name}.csv\")\n",
        "        external_data.append(df)\n",
        "\n",
        "    external_train = pd.concat(external_data)\n",
        "\n",
        "    external_data = external_data.drop_duplicates(keep=\"last\")\n",
        "    external_data = external_data.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWh7C_jN8EGC"
      },
      "source": [
        "if Config.inference:\n",
        "    api = wandb.Api()\n",
        "    for artifact_id in config.models:\n",
        "        name_version = artifact_id.replace(\":\", \"-\")\n",
        "        if not os.path.exists(name_version):\n",
        "            os.makedirs(name_version)\n",
        "\n",
        "        for fold in range(config.n_fold):\n",
        "            try:\n",
        "                artifact_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{artifact_id}\"\n",
        "                artifact = api.artifact(artifact_path)\n",
        "                artifact.download(name_version)\n",
        "            except Exception as e:\n",
        "                print(f\"Error: {artifact_path}, {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JepYxTDVFarm"
      },
      "source": [
        "# EDA-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGORKcNtFcAk",
        "outputId": "9f88c687-8fe0-4f88-c855-06979f170d67"
      },
      "source": [
        "for df in [train, test]:\n",
        "    print(f\"=\" * 120)\n",
        "    print(df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================================================================================================\n",
            "id              0\n",
            "context         0\n",
            "question        0\n",
            "answer_text     0\n",
            "answer_start    0\n",
            "language        0\n",
            "dtype: int64\n",
            "========================================================================================================================\n",
            "id          0\n",
            "context     0\n",
            "question    0\n",
            "language    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvCjtVwvGacB",
        "outputId": "f4e27977-6b96-4f54-af1e-911736c7db76"
      },
      "source": [
        "for df in [train, test]:\n",
        "    print(f\"=\" * 120)\n",
        "    print(df[\"language\"].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================================================================================================\n",
            "hindi    746\n",
            "tamil    368\n",
            "Name: language, dtype: int64\n",
            "========================================================================================================================\n",
            "hindi    3\n",
            "tamil    2\n",
            "Name: language, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUXUouHDHa-i",
        "outputId": "99a674a3-99c8-4594-aac4-59731809e6f2"
      },
      "source": [
        "if config.datasets != []:\n",
        "    print(external_train.isnull().sum())\n",
        "    print(f\"=\" * 120)\n",
        "    print(external_train[\"language\"].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "context         0\n",
            "question        0\n",
            "answer_text     0\n",
            "answer_start    0\n",
            "language        0\n",
            "dtype: int64\n",
            "========================================================================================================================\n",
            "hindi    6615\n",
            "tamil    3567\n",
            "Name: language, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW1WEUKWEPrV"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0_3tcXS_AEO"
      },
      "source": [
        "def convert_answers(row):\n",
        "    return {'answer_start': [row[0]], 'text': [row[1]]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mGJYUQ0liem"
      },
      "source": [
        "def correct_labels(df):\n",
        "    df.loc[df['id'] == '', 'answer_text'] = ''\n",
        "    df.loc[df['id'] == '', 'answer_start'] = 0\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdjatcP_FJ9r"
      },
      "source": [
        "def get_train_data(train):\n",
        "    train['answers'] = train[['answer_start', 'answer_text']].apply(convert_answers, axis=1)\n",
        "\n",
        "    return train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-A8bRGjFVMw"
      },
      "source": [
        "def get_test_data(test):\n",
        "\n",
        "    return test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yae6ysRGvMH"
      },
      "source": [
        "train = get_train_data(train)\n",
        "\n",
        "if config.datasets != []:\n",
        "    external_train = get_train_data(external_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-okotQ7GwJT"
      },
      "source": [
        "test = get_test_data(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54joajJkBRbm"
      },
      "source": [
        "### External Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8RSTX1SBZef"
      },
      "source": [
        "# 前処理\n",
        "if False and Config.preprocess:\n",
        "    external_squad_translated_tamil[\"language\"] = \"tamil\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0bvUgZyzasg"
      },
      "source": [
        "# dataset 保存\n",
        "if False and Config.preprocess:\n",
        "    !mkdir -p squad_translated_tamil\n",
        "    external_squad_translated_tamil.to_csv(\"squad_translated_tamil/squad_translated_tamil.csv\", index=False)\n",
        "    artifact = wandb.Artifact('squad_translated_tamil', type='dataset')\n",
        "    artifact.add_dir(\"squad_translated_tamil/\")\n",
        "    run.log_artifact(artifact)\n",
        "\n",
        "    !mkdir -p mlqa\n",
        "    external_mlqa.to_csv(\"mlqa/mlqa.csv\", index=False)\n",
        "    artifact = wandb.Artifact('mlqa', type='dataset')\n",
        "    artifact.add_dir(\"mlqa/\")\n",
        "    run.log_artifact(artifact)\n",
        "\n",
        "    !mkdir -p xquad\n",
        "    external_xquad.to_csv(\"xquad/xquad.csv\", index=False)\n",
        "    artifact = wandb.Artifact('xquad', type='dataset')\n",
        "    artifact.add_dir(\"xquad/\")\n",
        "    run.log_artifact(artifact)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEkueCnpHpGW"
      },
      "source": [
        "# EDA-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CEM8_FTTHqrM",
        "outputId": "e920471f-f5a9-42df-8ca4-29ba9f3e24f9"
      },
      "source": [
        "for df in [train, test, sub]:\n",
        "    print(f\"=\" * 120)\n",
        "    df.info()\n",
        "    display(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1114 entries, 0 to 1113\n",
            "Data columns (total 7 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   id            1114 non-null   object\n",
            " 1   context       1114 non-null   object\n",
            " 2   question      1114 non-null   object\n",
            " 3   answer_text   1114 non-null   object\n",
            " 4   answer_start  1114 non-null   int64 \n",
            " 5   language      1114 non-null   object\n",
            " 6   answers       1114 non-null   object\n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 61.0+ KB\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>language</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>903deec17</td>\n",
              "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
              "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
              "      <td>206</td>\n",
              "      <td>53</td>\n",
              "      <td>tamil</td>\n",
              "      <td>{'answer_start': [53], 'text': ['206']}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d9841668c</td>\n",
              "      <td>காளிதாசன் (தேவநாகரி: कालिदास) சமஸ்கிருத இலக்கி...</td>\n",
              "      <td>காளிதாசன் எங்கு பிறந்தார்?</td>\n",
              "      <td>காசுமீரில்</td>\n",
              "      <td>2358</td>\n",
              "      <td>tamil</td>\n",
              "      <td>{'answer_start': [2358], 'text': ['காசுமீரில்']}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29d154b56</td>\n",
              "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...</td>\n",
              "      <td>பென்சிலின் கண்டுபிடித்தவர் யார்?</td>\n",
              "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங்</td>\n",
              "      <td>0</td>\n",
              "      <td>tamil</td>\n",
              "      <td>{'answer_start': [0], 'text': ['சர் அலெக்ஸாண்ட...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>41660850a</td>\n",
              "      <td>குழந்தையின் அழுகையை  நிறுத்தவும், தூங்க வைக்கவ...</td>\n",
              "      <td>தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...</td>\n",
              "      <td>தாலாட்டு</td>\n",
              "      <td>68</td>\n",
              "      <td>tamil</td>\n",
              "      <td>{'answer_start': [68], 'text': ['தாலாட்டு']}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b29c82c22</td>\n",
              "      <td>சூரியக் குடும்பம் \\nசூரியக் குடும்பம் (Solar S...</td>\n",
              "      <td>பூமியின் அருகில் உள்ள விண்மீன் எது?</td>\n",
              "      <td>சூரியனும்</td>\n",
              "      <td>585</td>\n",
              "      <td>tamil</td>\n",
              "      <td>{'answer_start': [585], 'text': ['சூரியனும்']}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                            answers\n",
              "0  903deec17  ...            {'answer_start': [53], 'text': ['206']}\n",
              "1  d9841668c  ...   {'answer_start': [2358], 'text': ['காசுமீரில்']}\n",
              "2  29d154b56  ...  {'answer_start': [0], 'text': ['சர் அலெக்ஸாண்ட...\n",
              "3  41660850a  ...       {'answer_start': [68], 'text': ['தாலாட்டு']}\n",
              "4  b29c82c22  ...     {'answer_start': [585], 'text': ['சூரியனும்']}\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5 entries, 0 to 4\n",
            "Data columns (total 4 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        5 non-null      object\n",
            " 1   context   5 non-null      object\n",
            " 2   question  5 non-null      object\n",
            " 3   language  5 non-null      object\n",
            "dtypes: object(4)\n",
            "memory usage: 288.0+ bytes\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22bff3dec</td>\n",
              "      <td>ज्वाला गुट्टा (जन्म: 7 सितंबर 1983; वर्धा, महा...</td>\n",
              "      <td>ज्वाला गुट्टा की माँ का नाम क्या है</td>\n",
              "      <td>hindi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>282758170</td>\n",
              "      <td>गूगल मानचित्र (Google Maps) (पूर्व में गूगल लो...</td>\n",
              "      <td>गूगल मैप्स कब लॉन्च किया गया था?</td>\n",
              "      <td>hindi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d60987e0e</td>\n",
              "      <td>गुस्ताव रॉबर्ट किरचॉफ़ (१२ मार्च १८२४ - १७ अक्...</td>\n",
              "      <td>गुस्ताव किरचॉफ का जन्म कब हुआ था?</td>\n",
              "      <td>hindi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>f99c770dc</td>\n",
              "      <td>அலுமினியம் (ஆங்கிலம்: அலுமினியம்; வட அமெரிக்க ...</td>\n",
              "      <td>அலுமினியத்தின் அணு எண் என்ன?</td>\n",
              "      <td>tamil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40dec1964</td>\n",
              "      <td>கூட்டுறவு இயக்க வரலாறு, இங்கிலாந்து  நாட்டில் ...</td>\n",
              "      <td>இந்தியாவில் பசுமை புரட்சியின் தந்தை என்று கருத...</td>\n",
              "      <td>tamil</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ... language\n",
              "0  22bff3dec  ...    hindi\n",
              "1  282758170  ...    hindi\n",
              "2  d60987e0e  ...    hindi\n",
              "3  f99c770dc  ...    tamil\n",
              "4  40dec1964  ...    tamil\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5 entries, 0 to 4\n",
            "Data columns (total 2 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   id                5 non-null      object \n",
            " 1   PredictionString  0 non-null      float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 208.0+ bytes\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>PredictionString</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22bff3dec</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>282758170</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d60987e0e</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>f99c770dc</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40dec1964</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  PredictionString\n",
              "0  22bff3dec               NaN\n",
              "1  282758170               NaN\n",
              "2  d60987e0e               NaN\n",
              "3  f99c770dc               NaN\n",
              "4  40dec1964               NaN"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODUeiq5P_O8s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqyZ9-uMH2gK"
      },
      "source": [
        "# CV Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM6xvuGssH-4"
      },
      "source": [
        "if Config.debug:\n",
        "    train = train.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)\n",
        "    if config.datasets != []:\n",
        "        external_train = external_train.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)\n",
        "    if len(sub) > Config.num_debug_data:\n",
        "        test = test.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)\n",
        "        sub = sub.sample(n=Config.num_debug_data, random_state=config.seed).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XnW0e1AH4Cn",
        "outputId": "4ce1dd04-92ef-4005-e601-c643853fd8a6"
      },
      "source": [
        "Fold = StratifiedKFold(n_splits=config.n_fold, shuffle=True, random_state=seed)\n",
        "for n, (train_index, val_index) in enumerate(Fold.split(train, train[\"language\"])):\n",
        "    train.loc[val_index, \"fold\"] = int(n)\n",
        "train[\"fold\"] = train[\"fold\"].astype(np.int8)\n",
        "print(train.groupby([\"fold\", \"language\"]).size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold  language\n",
            "0     hindi       149\n",
            "      tamil        74\n",
            "1     hindi       149\n",
            "      tamil        74\n",
            "2     hindi       149\n",
            "      tamil        74\n",
            "3     hindi       150\n",
            "      tamil        73\n",
            "4     hindi       149\n",
            "      tamil        73\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W902aP490hEk"
      },
      "source": [
        "if config.datasets != []:\n",
        "    external_train[\"fold\"] = -1\n",
        "    external_train['id'] = list(np.arange(1, len(external_train)+1))\n",
        "    train = pd.concat([train, external_train]).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD0991CRIMH-"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veHPCKXQIJRv"
      },
      "source": [
        "@contextmanager\n",
        "def timer(name):\n",
        "    t0 = time.time()\n",
        "    LOGGER.info(f\"[{name}] start\")\n",
        "    yield\n",
        "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
        "\n",
        "\n",
        "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
        "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
        "\n",
        "    logger = getLogger(__name__)\n",
        "    logger.setLevel(INFO)\n",
        "    handler1 = StreamHandler()\n",
        "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
        "    handler2 = FileHandler(filename=log_file)\n",
        "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
        "    logger.addHandler(handler1)\n",
        "    logger.addHandler(handler2)\n",
        "    return logger\n",
        "\n",
        "\n",
        "LOGGER = init_logger()\n",
        "\n",
        "\n",
        "def seed_torch(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "seed_torch(seed=config.seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTjVqALnIXKQ"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqzv3qSpITRU"
      },
      "source": [
        "class BaseDataset(Dataset):\n",
        "    def __init__(self, df, model_name, include_labels=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.tokenizer = T.AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "        self.features = []\n",
        "        if include_labels:\n",
        "            for i, row in df.iterrows():\n",
        "                self.features += self.prepare_train_features(row)\n",
        "        else:\n",
        "            for i, row in df.iterrows():\n",
        "                self.features += self.prepare_test_features(row)\n",
        "\n",
        "        self.include_labels = include_labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        feature = self.features[item]\n",
        "\n",
        "        if self.include_labels:\n",
        "            return {\n",
        "                'input_ids':torch.tensor(feature['input_ids'], dtype=torch.long),\n",
        "                'attention_mask':torch.tensor(feature['attention_mask'], dtype=torch.long),\n",
        "                # 'offset_mapping':torch.tensor(feature['offset_mapping'], dtype=torch.long),\n",
        "                'start_position':torch.tensor(feature['start_position'], dtype=torch.long),\n",
        "                'end_position':torch.tensor(feature['end_position'], dtype=torch.long)\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'input_ids':torch.tensor(feature['input_ids'], dtype=torch.long),\n",
        "                'attention_mask':torch.tensor(feature['attention_mask'], dtype=torch.long),\n",
        "                'offset_mapping':feature['offset_mapping'],\n",
        "                'sequence_ids':feature['sequence_ids'],\n",
        "                'id':feature['example_id'],\n",
        "                'context': feature['context'],\n",
        "                'question': feature['question']\n",
        "            }\n",
        "\n",
        "    def prepare_train_features(self, example):\n",
        "        example[\"question\"] = example[\"question\"].lstrip()\n",
        "        tokenized_example = self.tokenizer(\n",
        "            example[\"question\"],\n",
        "            example[\"context\"],\n",
        "            truncation=\"only_second\",\n",
        "            max_length=config.max_len,\n",
        "            stride=config.doc_stride,\n",
        "            return_overflowing_tokens=True,\n",
        "            return_offsets_mapping=True,\n",
        "            padding=\"max_length\",\n",
        "        )\n",
        "\n",
        "        sample_mapping = tokenized_example.pop(\"overflow_to_sample_mapping\")\n",
        "        offset_mapping = tokenized_example.pop(\"offset_mapping\")\n",
        "\n",
        "        features = []\n",
        "        for i, offsets in enumerate(offset_mapping):\n",
        "            feature = {}\n",
        "            feature[\"example_id\"] = example['id']\n",
        "            feature['context'] = example['context']\n",
        "            feature['question'] = example['question']\n",
        "\n",
        "            input_ids = tokenized_example[\"input_ids\"][i]\n",
        "            attention_mask = tokenized_example[\"attention_mask\"][i]\n",
        "\n",
        "            feature['input_ids'] = input_ids\n",
        "            feature['attention_mask'] = attention_mask\n",
        "            feature['offset_mapping'] = offsets\n",
        "\n",
        "            cls_index = input_ids.index(self.tokenizer.cls_token_id)\n",
        "            sequence_ids = tokenized_example.sequence_ids(i)\n",
        "            feature['sequence_ids'] = [0 if i is None else i for i in sequence_ids]\n",
        "\n",
        "            sample_index = sample_mapping[i]\n",
        "            answers = example[\"answers\"]\n",
        "\n",
        "            if len(answers[\"answer_start\"]) == 0:\n",
        "                feature[\"start_position\"] = cls_index\n",
        "                feature[\"end_position\"] = cls_index\n",
        "            else:\n",
        "                start_char = answers[\"answer_start\"][0]\n",
        "                end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "                token_start_index = 0\n",
        "                while sequence_ids[token_start_index] != 1:\n",
        "                    token_start_index += 1\n",
        "\n",
        "                token_end_index = len(input_ids) - 1\n",
        "                while sequence_ids[token_end_index] != 1:\n",
        "                    token_end_index -= 1\n",
        "\n",
        "                if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "                    feature[\"start_position\"] = cls_index\n",
        "                    feature[\"end_position\"] = cls_index\n",
        "                else:\n",
        "                    while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "                        token_start_index += 1\n",
        "                    feature[\"start_position\"] = token_start_index - 1\n",
        "                    while offsets[token_end_index][1] >= end_char:\n",
        "                        token_end_index -= 1\n",
        "                    feature[\"end_position\"] = token_end_index + 1\n",
        "\n",
        "            features.append(feature)\n",
        "        return features\n",
        "\n",
        "    def prepare_test_features(self, example):\n",
        "        example[\"question\"] = example[\"question\"].lstrip()\n",
        "        tokenized_example = self.tokenizer(\n",
        "            example[\"question\"],\n",
        "            example[\"context\"],\n",
        "            truncation=\"only_second\",\n",
        "            max_length=config.max_len,\n",
        "            stride=config.doc_stride,\n",
        "            return_overflowing_tokens=True,\n",
        "            return_offsets_mapping=True,\n",
        "            padding=\"max_length\",\n",
        "        )\n",
        "\n",
        "        features = []\n",
        "        for i in range(len(tokenized_example[\"input_ids\"])):\n",
        "            feature = {}\n",
        "            feature[\"example_id\"] = example['id']\n",
        "            feature['context'] = example['context']\n",
        "            feature['question'] = example['question']\n",
        "            feature['input_ids'] = tokenized_example['input_ids'][i]\n",
        "            feature['attention_mask'] = tokenized_example['attention_mask'][i]\n",
        "            feature['offset_mapping'] = tokenized_example['offset_mapping'][i]\n",
        "            feature['sequence_ids'] = [0 if i is None else i for i in tokenized_example.sequence_ids(i)]\n",
        "            features.append(feature)\n",
        "        return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7c93ed481db94b38967637fea4ae35fb",
            "8555a716f5f4489d80c2fc2983c2babe",
            "6caacf2867d6421abc45322156e1c967",
            "625b70b578c24d6da65c0ff1df39ec99",
            "ff2fcb75a8524e9f84f4607f3c3b4ad3",
            "f840d81fcf2648fbb21c9bcc3c7e6641",
            "62243f0c5b2144c4b07f7a79254a321a",
            "4092e571264c4e38b8570d0f21110c10",
            "547ea405337345fb861dcf1ac9e3bbae",
            "641efef8a3ae4beaa4683156ad575a93",
            "dfe88ad423d8464ba86b256442b26b15",
            "544e8ba722e04a27add8bb2ede6edab2",
            "a19e6cf1390749f4999be35fd7bd1eea",
            "a36c5a42f87b48eeb02159106cedb528",
            "68f2a71832f442049d6bc5e6bcee97b1",
            "4ef60073c0304d968a5ee469a98e5e6d",
            "dcfb3d9660d54480bdc4b153a36a99b5",
            "2496bf863649484a900d6c93dd65bf7a",
            "632b78a74dcd47fcb258e77f69a7a609",
            "2edad0c78c254a1b993d787350f1fada",
            "c9019d0604974d39b4da30d78155a222",
            "d56e39f166394fc7ae6103e3954c00ac",
            "55a1db1d104d4a2e868e617cd36095a6",
            "43b348c785574c01a8a7810694669ba5",
            "9956d355bdbc491f976bf9d1f8663b37",
            "95bfbbce3cfe4128a5c99095fa3794b3",
            "add8e8135925455781c3a1b7231f1d88",
            "9544741b6ae144c5b103eeba9eaf290e",
            "4b69088fba33446fa3004807c475d257",
            "57c7a5492ad64010b2a546f6e8170a74",
            "c41801cb6a7f44a191b29292b8bce784",
            "d9d03d242945484983ecb860750fe265",
            "8e614a4f021a40aeac65b434d654a454",
            "d5864e15378740d4a6d70da6c2102a73",
            "d935556582854f6eba5591d3e6d20c04",
            "c6b5944e16574ee7ae24f021a6cdcd3f",
            "872ba6e4cc42464ca1667a5f657db5af",
            "d0b9234fa7e14a8d999f36bcf6fec876",
            "cea95718a11a49fb87b72f2f4bddc5b8",
            "a783f6aa32fd4a649937be8358d80a6e",
            "cd4ca6c2ec3f437991b9376e8cc2bd1e",
            "51acacaee52a44e6abf2e4218c52d402",
            "bd0e1792b62d42d18ee0cb5b5c0fae8b",
            "281eac8bec124df9bdbf607a1242eb84"
          ]
        },
        "id": "77rjufTiUtJb",
        "outputId": "58fea70c-aad8-4405-d1c0-cea3939e6c7f"
      },
      "source": [
        "if config.model_name != \"\":\n",
        "    train_ds = BaseDataset(train, config.model_name)\n",
        "    print(train_ds[0])\n",
        "    print(len(train_ds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c93ed481db94b38967637fea4ae35fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/179 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "544e8ba722e04a27add8bb2ede6edab2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/606 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55a1db1d104d4a2e868e617cd36095a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5864e15378740d4a6d70da6c2102a73",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([     0,  69535,  81049,  37368, 153264,  12095,  52989,  21883,   1629,\n",
            "        145615,     32,      2,      2,   3219, 224013, 124335,   5966,  69535,\n",
            "          4930,  74149,  12095,  52989,  21883, 182394,   3686,  51833,  57210,\n",
            "        101912,     15,   6161,   2912,  70597,  52989,  21883, 102080,  54512,\n",
            "         91585,   1962, 212933,  18599,  16242,  94236,     16, 198236,  29160,\n",
            "         12095,  52989,  21883, 173139,  23618,  72817,      5,   5894, 198236,\n",
            "         81049,  37334, 144257,   7827,  82890,  84853,  80517, 114452, 232094,\n",
            "          3686,  17984,  11830,  62001, 182394,   4167,      5, 203312,  10753,\n",
            "         50667,   2650,      4,  45303,   1962, 163062, 198236,  29160, 176030,\n",
            "         15453,      4,   3219, 171093,   5944,   2650,   8120,  10175,  12095,\n",
            "         52989,  21883,     15,   2650,  24183,   5638,  14861,     16,  56735,\n",
            "          3219, 171093,   5944,   2650,  12009, 145578,  10832,   2802,   2650,\n",
            "         26873,  52989,  21883,  53336,  26415,  38640,  31067,     74, 105457,\n",
            "          5966,  22050,  12095,  52989,  21883, 202342,  59386,  12095,  52989,\n",
            "         13070,   2650,   1962,  39311,   9654,  37964,  18806,      4, 196586,\n",
            "        105457,   5966,  22467,  78876,  52989,  21883,     74, 102080,   6896,\n",
            "            20,  21162,  14233,  94097,   4864,  12152,  12095,  52989,  21883,\n",
            "          1629, 210828,   1381, 198236,   2782, 191297,  10832,   2802,   2650,\n",
            "         26873,  52989,  21883,   1629,   3912,  59987,   1962, 212933,  26415,\n",
            "         20567,      5,  69535,   9696, 184936,  28258,  89933,   1039,  12095,\n",
            "         52989,  21883,   1629,     15,  10753,   2802,   6149,  11674,  16043,\n",
            "         26873,   2913,  21883, 202342, 137010,     16, 145615,     74, 164359,\n",
            "         12095,  11993, 181576,  87783,  35186,     15,  15182,  53208,     16,\n",
            "         12095,  52989,  21883,  91585,  11772,    616,  71987,  12095,  52989,\n",
            "         21883,  91585,  11772,     15,   1021,  26136,  32881,      7,     16,\n",
            "         73417,  73949, 163493,      5,     15,   4875,   5427,   3770, 136259,\n",
            "          1629,  88115,   2650, 230988, 112578,  53336,   4167, 136259, 173139,\n",
            "             6,  79464,   2798, 143825,      5,     16, 181576,  87783,  35186,\n",
            "         12095,  52989,  21883,   1629,  10021,    106, 190707,   4875, 128236,\n",
            "         52989,  21883,     15,  20549,    289,  32881,     16,    116,  14184,\n",
            "          3937, 145181,  52989,  21883,     15,  24980,     13,   1803,  32881,\n",
            "            16,   1737,    138, 116180,  17056,   3686,   4875, 128236,  52989,\n",
            "         21883,     15,  99736,    289,  32881,     16,   1737,    201,  22262,\n",
            "         95344,  12095,  52989,  21883,     15,   6652,  88354,    289,  32881,\n",
            "            16,   6001,   6343,   8850,  12095,  52989,  21883,     15,      7,\n",
            "         88322,  48899,  32881,     16,  60070,  12784,   2782,  35424,  26873,\n",
            "         52989,  21883,     15,  12421,    432,    532,  32881,     16,  71987,\n",
            "         12095,  52989,  21883,   1629,  31203,    361, 145578,  51153,  18805,\n",
            "         12095,  52989,  21883,     15,  12018,  28236,     16,    305, 177292,\n",
            "         95424,  18805,  12095,  52989,  21883,     15,  24084,   2298,     16,\n",
            "          1737,   2690,  42353,  78876,  52989,  21883,     15,  16917,  10325,\n",
            "         32881,     16,   1737,    190,   6390,  62481,  12095,  52989,  21883,\n",
            "            15,   3285,    519,  47148,  32881,      2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'start_position': tensor(27), 'end_position': tensor(27)}\n",
            "26881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YBEpGYP-kjH",
        "outputId": "d8ffa558-8377-4146-9eac-5c37806a0ff1"
      },
      "source": [
        "if config.model_name != \"\":\n",
        "    test_ds = BaseDataset(test, config.model_name, include_labels=False)\n",
        "    print(test_ds[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([     0,      6,  38033,  91262,  20546,  85149,    471,  58380,    641,\n",
            "          8062,   6004,    460,      2,      2,      6,  38033,  91262,  20546,\n",
            "         85149,     15, 206327,     12,    361, 182198,  26819,     74,      6,\n",
            "        196859,   1026,      4,  15297,     16,    967,   9261,  41162, 156793,\n",
            "         64382,  46297, 103766,   1404,   7294,   1293,    125, 222600,   5725,\n",
            "         11515,      6,  38033,  91262,  20546,  85149,    641,  22274,    361,\n",
            "        182198,  26819,    629,      6, 196859,   1026,      4,  15297,    421,\n",
            "         11645,   3813,    125,  24939,  62573,  39477,      5, 233097,   4429,\n",
            "         45951,  25594,    871,  56980,   4149,   1471,    998,  23263,    646,\n",
            "          1293,    125,  35056,  56980,   4149,   1471,    998,  20546,  85149,\n",
            "         47211,  12797,  27193,    421,   5564, 220307,   9331,    287,   3765,\n",
            "          3946,  13430, 120116,    125,      6,  38033,  91262,  20546,  85149,\n",
            "           471, 222600,   5725,  53812,   9729, 204778,    646,  17035,    871,\n",
            "         33171,    838,    646,  21191,  41162, 156793,  64382,  46297,  12189,\n",
            "          1748,   1780,  26252,   4029,    125,  82645, 209393,    209,   9512,\n",
            "           471,  78087,    646,   2093,      6,  38033,  91262,  20546,  85149,\n",
            "          1142,  31160,      5,  31598,      5,  33142, 160674,    646,  77022,\n",
            "         10067, 166922,  26252,   1896,   8785,   3813,    125,  31160,      5,\n",
            "         31598,      5,  33142, 160674,   3946,    287,  13325,   4592,   1187,\n",
            "         12189, 201742,   1293, 207411,   8771,  74163,   4846, 157426, 138314,\n",
            "           646, 191604,   4029,   5349,    460,    125,  47211,  12797,    702,\n",
            "          9512,    471,  78087,    421,  21191,  22009,   4415, 188408,  41162,\n",
            "        156793,  64382,  46297, 115739,  77666,  51476, 151576,  41657,    659,\n",
            "          9917,    125,   9512,   3576,    421,      6,  38033,  91262,  20546,\n",
            "         85149,   1142,    729,   9512,    471,  78087,    421,  70159,  85134,\n",
            "        188408,  41162, 156793,  64382,  46297, 115739,  77666,  51476, 151576,\n",
            "         41657,    659,    125,  64021,   9512,  21191,      6, 170555,   3558,\n",
            "        159967,  51476,    287,   3765, 227649,   6473,    421,  91298,    659,\n",
            "         17837,   2617,   9179,  73457,    287, 227649,   6473,  70159,  85134,\n",
            "        188408,  41162, 156793,  64382,  46297, 115739,  77666,  51476, 151576,\n",
            "           871,  13371,    998,  85134, 188408,  41162, 156793,  64382,  46297,\n",
            "        115739,  77666,  51476, 151576,    421,  41657,  76613,    471,    125,\n",
            "             6, 170555,   3558, 159967,  51476,    287,   3765,  35056,  91298,\n",
            "           659,  52170, 195730,   6927,   7231, 192872,    125,   5726,    646,\n",
            "          2021,   7231,  73451,  32534,  12797,      6,  38033,  91262,  20546,\n",
            "         85149,   1142,  73457,    287, 188408, 115474,   1471,  73254,    421,\n",
            "         41657,  76613,    471,    125,  39556,   9236, 227649,   6473,    287,\n",
            "          3765,      9, 105456,      6,  38033,  91262,  20546,  85149,   1142,\n",
            "        119253,   3282, 227649,   6473,    421,   1780,  67963,  76613,    471,\n",
            "           871,   3946,    471, 227649,   6473,    421,  13353, 203104, 160161,\n",
            "        118689,    838,    125,  54968,   1532,  59308,  26609,   8683,  13056,\n",
            "          8531, 156180,   6473,    421,   1780,      6,  38033,  91262,  20546,\n",
            "         85149,   1142,   5564, 221876,   2139,      2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'offset_mapping': [(0, 0), (0, 1), (0, 2), (2, 6), (6, 9), (9, 13), (13, 16), (16, 20), (20, 23), (23, 27), (27, 32), (32, 35), (0, 0), (0, 0), (0, 1), (0, 2), (2, 6), (6, 9), (9, 13), (13, 15), (15, 19), (19, 20), (20, 22), (22, 29), (29, 34), (34, 35), (35, 36), (36, 40), (40, 41), (41, 42), (42, 53), (53, 54), (54, 57), (57, 64), (64, 67), (67, 69), (69, 71), (71, 73), (73, 76), (76, 78), (78, 80), (80, 84), (84, 85), (87, 95), (95, 97), (97, 102), (103, 104), (104, 106), (106, 110), (110, 113), (113, 117), (117, 120), (120, 125), (125, 127), (127, 134), (134, 139), (139, 142), (142, 143), (143, 147), (147, 148), (148, 149), (149, 160), (160, 164), (164, 168), (168, 171), (171, 172), (172, 177), (177, 182), (182, 185), (185, 186), (186, 194), (194, 197), (197, 199), (199, 201), (201, 204), (204, 208), (208, 211), (211, 212), (212, 213), (213, 217), (217, 220), (220, 224), (224, 225), (225, 230), (230, 234), (234, 237), (237, 238), (238, 239), (239, 242), (242, 246), (246, 251), (251, 255), (255, 260), (260, 264), (264, 269), (269, 274), (274, 277), (277, 280), (280, 284), (284, 289), (289, 292), (292, 296), (296, 297), (297, 298), (298, 300), (300, 304), (304, 307), (307, 311), (311, 314), (314, 322), (322, 324), (324, 328), (328, 330), (330, 339), (339, 342), (342, 346), (346, 349), (349, 353), (353, 354), (354, 357), (357, 366), (366, 369), (369, 371), (371, 373), (373, 375), (375, 379), (379, 381), (381, 384), (384, 389), (389, 394), (394, 395), (397, 400), (400, 404), (405, 408), (408, 412), (412, 415), (415, 420), (420, 423), (423, 426), (426, 427), (427, 429), (429, 433), (433, 436), (436, 440), (440, 443), (443, 446), (446, 447), (447, 449), (449, 450), (450, 453), (453, 455), (455, 458), (458, 464), (464, 467), (467, 472), (472, 477), (477, 480), (480, 485), (485, 488), (488, 489), (489, 492), (492, 493), (493, 495), (495, 496), (496, 499), (499, 501), (501, 506), (506, 509), (509, 514), (514, 517), (517, 519), (519, 523), (523, 533), (533, 537), (537, 545), (545, 547), (547, 550), (550, 551), (551, 557), (557, 564), (564, 567), (567, 576), (576, 581), (581, 585), (585, 588), (588, 589), (589, 594), (594, 598), (598, 601), (601, 605), (605, 608), (608, 613), (613, 617), (617, 626), (626, 629), (629, 631), (631, 637), (637, 640), (640, 642), (642, 644), (644, 646), (646, 649), (649, 651), (651, 654), (654, 657), (657, 661), (661, 662), (662, 665), (665, 666), (666, 670), (670, 675), (675, 679), (679, 680), (680, 682), (682, 686), (686, 689), (689, 693), (693, 696), (696, 699), (699, 703), (703, 706), (706, 711), (711, 715), (715, 719), (719, 722), (722, 728), (728, 731), (731, 733), (733, 735), (735, 737), (737, 740), (740, 742), (742, 745), (745, 748), (748, 752), (752, 753), (753, 754), (754, 758), (758, 762), (762, 771), (771, 772), (772, 777), (777, 778), (778, 782), (782, 785), (785, 788), (788, 792), (792, 796), (796, 798), (798, 802), (802, 807), (807, 808), (808, 812), (812, 814), (814, 818), (818, 826), (826, 829), (829, 833), (833, 835), (835, 839), (839, 842), (842, 848), (848, 851), (851, 853), (853, 855), (855, 857), (857, 860), (860, 862), (862, 865), (865, 868), (868, 871), (871, 874), (874, 875), (875, 878), (878, 884), (884, 887), (887, 889), (889, 891), (891, 893), (893, 896), (896, 898), (898, 901), (901, 904), (904, 908), (908, 912), (912, 918), (918, 921), (921, 922), (922, 923), (923, 928), (928, 929), (929, 933), (933, 936), (936, 939), (939, 943), (943, 948), (948, 953), (953, 954), (954, 959), (959, 964), (964, 968), (968, 971), (971, 975), (975, 976), (976, 981), (981, 984), (984, 989), (989, 992), (992, 999), (999, 1003), (1003, 1007), (1007, 1008), (1008, 1010), (1010, 1014), (1014, 1017), (1017, 1021), (1021, 1024), (1024, 1032), (1032, 1035), (1035, 1041), (1041, 1045), (1045, 1046), (1046, 1058), (1058, 1062), (1062, 1066), (1066, 1072), (1072, 1075), (1075, 1076), (1076, 1079), (1079, 1085), (1085, 1089), (1089, 1091), (1091, 1094), (1094, 1098), (1098, 1099), (1099, 1102), (1102, 1103), (1103, 1105), (1105, 1109), (1109, 1112), (1112, 1116), (1116, 1119), (1119, 1125), (1125, 1127), (1127, 1131), (1131, 1133), (1133, 1137), (1137, 1140), (1140, 1146), (1146, 1152), (1152, 1155), (1155, 1158), (1158, 1163), (1163, 1166), (1166, 1170), (1170, 1172), (1172, 1176), (1176, 1181), (1181, 1189), (1189, 1197), (1197, 1201), (1201, 1202), (1202, 1203), (1203, 1206), (1206, 1211), (1211, 1214), (1214, 1216), (1216, 1218), (1218, 1220), (1220, 1221), (1221, 1225), (1225, 1227), (1227, 1231), (1231, 1234), (1234, 1235), (1235, 1237), (1237, 1241), (1241, 1244), (1244, 1248), (1248, 1251), (1251, 1256), (1256, 1264), (1264, 1266), (0, 0)], 'sequence_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], 'id': '22bff3dec', 'context': 'ज्वाला गुट्टा (जन्म: 7 सितंबर 1983; वर्धा, महाराष्ट्र) एक भारतीय बैडमिंटन खिलाडी हैं। \\n प्रारंभिक जीवन \\nज्वाला गुट्टा का जन्म 7 सितंबर 1983 को वर्धा, महाराष्ट्र में हुआ था। उनके पिता एम. क्रांति तेलुगु और मां येलन चीन से हैं। उनकी मां येलन गुट्टा पहली बार 1977 में अपने दादा जी के साथ भारत आई थीं। ज्वाला गुट्टा की प्रारंभिक पढ़ाई हैदराबाद से हुई और यहीं से उन्होंने बैडमिंटन खेलना भी शुरू किया। \\n कॅरियर \\n10 साल की उम्र से ही ज्वाला गुट्टा ने एस.एम. आरिफ से ट्रेनिंग लेना शुरू कर दिया था। एस.एम. आरिफ भारत के जाने माने खेल प्रशिक्षक हैं जिन्हें द्रोणाचार्य अवार्ड से सम्मानित किया गया है। पहली बार 13 साल की उम्र में उन्होंने मिनी नेशनल बैडमिंटन चैंपियनशिप जीती थी। साल 2000 में ज्वाला गुट्टा ने 17 साल की उम्र में जूनियर नेशनल बैडमिंटन चैंपियनशिप जीती। इसी साल उन्होंने श्रुति कुरियन के साथ डबल्स में जोड़ी बनाते हुए महिलाओं के डबल्स जूनियर नेशनल बैडमिंटन चैंपियनशिप और सीनियर नेशनल बैडमिंटन चैंपियनशिप में जीत हासिल की। श्रुति कुरियन के साथ उनकी जोड़ी काफी लंबे समय तक चली। 2002 से 2008 तक लगातार सात बार ज्वाला गुट्टा ने महिलाओं के नेशनल युगल प्रतियोगिता में जीत हासिल की।[2]\\nमहिला डबल्स के साथ-साथ ज्वाला गुट्टा ने मिश्रित डबल्स में भी सफलता हासिल की और भारत की डबल्स में सबसे बेहतरीन खिलाड़ी बनीं।[3] 2010 कॉमनवेल्थ गेम्स में भी ज्वाला गुट्टा ने अपने पार्टनर अश्विनी पोनप्पा के साथ भारत के लिए स्वर्ण पदक जीता। कॉमनवेल्थ गेम्स के बाद से एक बार फिर ज्वाला गुट्टा भारतीय बैडमिंटन में चर्चा का विषय बन गई हैं।[4][5]\\nग्लासगो में आयोजित कॉमनवेल्थ गेम्स, 2014 में ज्वाला गुट्टा ने स्वर्ण पदक हासिल किया।\\n व्यक्तिगत जीवन \\nमैदान पर बाएं हाथ से तेज-तर्रार शॉट लगाने वाली ज्वाला निजी जिंदगी में भी काफी तेज और चर्चाओं में छाई रहती हैं। ज्वाला ने 2005 में बैडमिंटन खिलाड़ी चेतन आनंद से शादी की थी, 29 जून 2011 को उन्होंने अपने पति पूर्व बैडमिंटन खिलाड़ी चेतन आनंद से तलाक लिया है। चेतन आनंद भी एक बेहतरीन भारतीय बैडमिंटन खिलाड़ी हैं।\\n फिल्मोग्राफी \\nGunde Jaari Gallanthayyinde[6] \\nफुगली (2014)\\n उपलब्धियां \\nरिकॉर्ड 13 बार नेशनल बैडमिंटन चैंपियनशिप की विजेता। \\nभारत की सबसे बेहतरीन डबल्स प्लेयर। \\nसाल 2011 में उन्हें “अर्जुन पुरस्कार” से सम्मानित किया गया। \\nराष्ट्रमंडल खेल, 2014 (ग्लासगो) में स्वर्ण पदक जीता। \\n चित्र दीर्घा \\n\\n\\nवी दीजू और ज्वाला गुट्टा\\nकेबीसी के सेट पर सुशील कुमार, ज्वाला गुट्टा, लिएंडर पेस, श्रीसंत\\nकेबीसी के सेट पर सुशील कुमार, ज्वाला गुट्टा, लिएंडर पेस, श्रीसंत\\n\\n सन्दर्भ \\n\\n बाहरी कड़ियाँ \\n\\n\\n\\n\\n\\nश्रेणी:हिन्द की बेटियाँ\\nश्रेणी:विकिपरियोजना हिन्द की बेटियाँ\\nश्रेणी:भारत के खिलाड़ी\\nश्रेणी:1983 में जन्मे लोग\\nश्रेणी:जीवित लोग\\nश्रेणी:भारतीय महिला बैडमिंटन खिलाड़ी\\nश्रेणी:राष्ट्रमंडल खेलों के पदक प्राप्तकर्ता\\nश्रेणी:महाराष्ट्र के लोग\\nश्रेणी:बैडमिंटन खिलाड़ी', 'question': 'ज्वाला गुट्टा की माँ का नाम क्या है'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4zuBuCCAv-8"
      },
      "source": [
        "# 🚗 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tJieX2AAueP",
        "outputId": "a0a99196-543c-4714-ca56-2da057b20b80"
      },
      "source": [
        "if config.model_name != \"\":\n",
        "    print(T.AutoConfig.from_pretrained(config.model_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XLMRobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"language\": \"english\",\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"name\": \"XLMRoberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZtghUknA1b8"
      },
      "source": [
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__()\n",
        "\n",
        "        self.auto_config = T.AutoConfig.from_pretrained(model_name)\n",
        "        self.auto_config.update({\n",
        "            \"hidden_dropout_prob\": config.dropout,\n",
        "            \"layer_norm_eps\": 1e-7,\n",
        "        })\n",
        "\n",
        "        self.auto_model = T.AutoModel.from_pretrained(model_name, config=self.auto_config, add_pooling_layer=False)\n",
        "        self.qa_outputs = nn.Linear(self.auto_config.hidden_size, 2)\n",
        "\n",
        "        if config.init_weights:\n",
        "            self._init_weights(self.qa_outputs)\n",
        "\n",
        "        if config.init_layers > 0:\n",
        "            self._init_layers()\n",
        "        \n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.auto_config.initializer_range)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "    def _init_layers(self):\n",
        "        # re-init pooler\n",
        "        # self.auto_model.pooler.dense.weight.data.normal_(mean=0.0, std=self.auto_model.config.initializer_range)\n",
        "        # self.auto_model.pooler.dense.bias.data.zero_()\n",
        "        # for p in self.auto_model.pooler.parameters():\n",
        "        #     p.requires_grad = True\n",
        "\n",
        "        # re-init encoder\n",
        "        layers = self.auto_model.encoder.layer[-config.init_layers:]\n",
        "        for layer in layers:\n",
        "            for module in layer.modules():\n",
        "                if isinstance(module, nn.Linear):\n",
        "                    # Slightly different from the TF version which uses truncated_normal for initialization\n",
        "                    # cf https://github.com/pytorch/pytorch/pull/5617\n",
        "                    module.weight.data.normal_(mean=0.0, std=self.auto_model.config.initializer_range)\n",
        "                    if module.bias is not None:\n",
        "                        module.bias.data.zero_()\n",
        "                elif isinstance(module, nn.Embedding):\n",
        "                    module.weight.data.normal_(mean=0.0, std=self.auto_model.config.initializer_range)\n",
        "                    if module.padding_idx is not None:\n",
        "                        module.weight.data[module.padding_idx].zero_()\n",
        "                elif isinstance(module, nn.LayerNorm):\n",
        "                    module.bias.data.zero_()\n",
        "                    module.weight.data.fill_(1.0)\n",
        "\n",
        "    def forward(\n",
        "        self, \n",
        "        input_ids, \n",
        "        attention_mask=None, \n",
        "    ):\n",
        "        outputs = self.auto_model(\n",
        "            input_ids,\n",
        "            attention_mask,\n",
        "        )\n",
        "\n",
        "        last_hidden_state = outputs[0]\n",
        "        \n",
        "        qa_logits = self.qa_outputs(last_hidden_state)\n",
        "        \n",
        "        start_logits, end_logits = qa_logits.split(1, dim=-1)\n",
        "        start_logits = start_logits.squeeze(-1)\n",
        "        end_logits = end_logits.squeeze(-1)\n",
        "    \n",
        "        return start_logits, end_logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1cZpfnGmuyI"
      },
      "source": [
        "class QAModel(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__()\n",
        "\n",
        "        self.auto_config = T.AutoConfig.from_pretrained(model_name)\n",
        "        self.auto_config.update({\n",
        "            \"hidden_dropout_prob\": config.dropout,\n",
        "            # \"layer_norm_eps\": 1e-7,\n",
        "        })\n",
        "\n",
        "        self.auto_model = T.AutoModelForQuestionAnswering.from_pretrained(model_name, config=self.auto_config)\n",
        "\n",
        "    def forward(\n",
        "        self, \n",
        "        input_ids, \n",
        "        attention_mask=None, \n",
        "    ):\n",
        "        outputs = self.auto_model(\n",
        "            input_ids,\n",
        "            attention_mask,\n",
        "        )\n",
        "\n",
        "        return outputs.start_logits, outputs.end_logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "36e4738a65474c2480db43003c0e36f6",
            "272caf9759de4a1a89b63e4e1fffa1b8",
            "4c19719da3504573a0e947d5c162a5b0",
            "bb3a405e64c84de3958e46ab593a1dcf",
            "a3b118b28c694bc3a44344ddea1e90b5",
            "6e6f2d21fad6452ab577f17fc2624c93",
            "8d189f9004384e899e229a2b4136650c",
            "4f55655a29b94410ba8b5071cdceffa5",
            "cf301d6bd6bb41b9aa62cc6638502c5c",
            "c37d4f02973b4b6e95041d68c8043f29",
            "0d345378098c4d3bbb8e20bfdf480f4c"
          ]
        },
        "id": "M92xPyOyCSQZ",
        "outputId": "34d19d5c-8a83-4d1e-8885-a4303b69bee3"
      },
      "source": [
        "if config.model_name != \"\":\n",
        "    if config.model_class == \"bare\":\n",
        "        model = BaseModel(config.model_name)\n",
        "    elif config.model_class == \"qa\":\n",
        "        model = QAModel(config.model_name)\n",
        "    print(model)\n",
        "\n",
        "    train_dataset = BaseDataset(train, config.model_name)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "    for features in train_loader:\n",
        "        output = model(features[\"input_ids\"], features[\"attention_mask\"])\n",
        "        print(output)\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36e4738a65474c2480db43003c0e36f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'qa_outputs.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BaseModel(\n",
            "  (auto_model): XLMRobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 1024)\n",
            "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (12): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (13): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (14): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (15): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (16): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (17): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (18): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (19): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (20): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (21): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (22): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (23): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",
            ")\n",
            "(tensor([[-0.3975, -0.1206, -0.5748,  ...,  0.1906, -0.2890,  0.0632],\n",
            "        [-0.3060, -0.1187,  0.0277,  ...,  0.0485,  0.0485,  0.0485],\n",
            "        [-0.3055, -0.5288, -0.3366,  ...,  0.0819,  0.0819,  0.0819],\n",
            "        [-0.2414, -0.6567, -0.0696,  ..., -0.4762, -0.1426,  0.0624]],\n",
            "       grad_fn=<SqueezeBackward1>), tensor([[ 0.3880,  0.6623,  0.7906,  ...,  0.8861,  0.6380, -0.0270],\n",
            "        [ 0.3180,  0.4705,  0.4791,  ..., -0.0856, -0.0856, -0.0856],\n",
            "        [ 0.1775,  0.7089,  0.3864,  ..., -0.0424, -0.0424, -0.0424],\n",
            "        [ 0.4582,  0.5835,  0.8310,  ...,  0.5266,  0.8035, -0.0364]],\n",
            "       grad_fn=<SqueezeBackward1>))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35wEQxmYCwUr",
        "outputId": "43fa1870-0d3e-441c-fa37-4b2ccc60faf0"
      },
      "source": [
        "if config.model_name != \"\":\n",
        "    for n, (name, tensor) in enumerate(list(model.named_parameters())):\n",
        "        print(f\"{n:>4}: {tensor.requires_grad}, {name}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   0: True, auto_model.embeddings.word_embeddings.weight\n",
            "   1: True, auto_model.embeddings.position_embeddings.weight\n",
            "   2: True, auto_model.embeddings.token_type_embeddings.weight\n",
            "   3: True, auto_model.embeddings.LayerNorm.weight\n",
            "   4: True, auto_model.embeddings.LayerNorm.bias\n",
            "   5: True, auto_model.encoder.layer.0.attention.self.query.weight\n",
            "   6: True, auto_model.encoder.layer.0.attention.self.query.bias\n",
            "   7: True, auto_model.encoder.layer.0.attention.self.key.weight\n",
            "   8: True, auto_model.encoder.layer.0.attention.self.key.bias\n",
            "   9: True, auto_model.encoder.layer.0.attention.self.value.weight\n",
            "  10: True, auto_model.encoder.layer.0.attention.self.value.bias\n",
            "  11: True, auto_model.encoder.layer.0.attention.output.dense.weight\n",
            "  12: True, auto_model.encoder.layer.0.attention.output.dense.bias\n",
            "  13: True, auto_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "  14: True, auto_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "  15: True, auto_model.encoder.layer.0.intermediate.dense.weight\n",
            "  16: True, auto_model.encoder.layer.0.intermediate.dense.bias\n",
            "  17: True, auto_model.encoder.layer.0.output.dense.weight\n",
            "  18: True, auto_model.encoder.layer.0.output.dense.bias\n",
            "  19: True, auto_model.encoder.layer.0.output.LayerNorm.weight\n",
            "  20: True, auto_model.encoder.layer.0.output.LayerNorm.bias\n",
            "  21: True, auto_model.encoder.layer.1.attention.self.query.weight\n",
            "  22: True, auto_model.encoder.layer.1.attention.self.query.bias\n",
            "  23: True, auto_model.encoder.layer.1.attention.self.key.weight\n",
            "  24: True, auto_model.encoder.layer.1.attention.self.key.bias\n",
            "  25: True, auto_model.encoder.layer.1.attention.self.value.weight\n",
            "  26: True, auto_model.encoder.layer.1.attention.self.value.bias\n",
            "  27: True, auto_model.encoder.layer.1.attention.output.dense.weight\n",
            "  28: True, auto_model.encoder.layer.1.attention.output.dense.bias\n",
            "  29: True, auto_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "  30: True, auto_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "  31: True, auto_model.encoder.layer.1.intermediate.dense.weight\n",
            "  32: True, auto_model.encoder.layer.1.intermediate.dense.bias\n",
            "  33: True, auto_model.encoder.layer.1.output.dense.weight\n",
            "  34: True, auto_model.encoder.layer.1.output.dense.bias\n",
            "  35: True, auto_model.encoder.layer.1.output.LayerNorm.weight\n",
            "  36: True, auto_model.encoder.layer.1.output.LayerNorm.bias\n",
            "  37: True, auto_model.encoder.layer.2.attention.self.query.weight\n",
            "  38: True, auto_model.encoder.layer.2.attention.self.query.bias\n",
            "  39: True, auto_model.encoder.layer.2.attention.self.key.weight\n",
            "  40: True, auto_model.encoder.layer.2.attention.self.key.bias\n",
            "  41: True, auto_model.encoder.layer.2.attention.self.value.weight\n",
            "  42: True, auto_model.encoder.layer.2.attention.self.value.bias\n",
            "  43: True, auto_model.encoder.layer.2.attention.output.dense.weight\n",
            "  44: True, auto_model.encoder.layer.2.attention.output.dense.bias\n",
            "  45: True, auto_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "  46: True, auto_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "  47: True, auto_model.encoder.layer.2.intermediate.dense.weight\n",
            "  48: True, auto_model.encoder.layer.2.intermediate.dense.bias\n",
            "  49: True, auto_model.encoder.layer.2.output.dense.weight\n",
            "  50: True, auto_model.encoder.layer.2.output.dense.bias\n",
            "  51: True, auto_model.encoder.layer.2.output.LayerNorm.weight\n",
            "  52: True, auto_model.encoder.layer.2.output.LayerNorm.bias\n",
            "  53: True, auto_model.encoder.layer.3.attention.self.query.weight\n",
            "  54: True, auto_model.encoder.layer.3.attention.self.query.bias\n",
            "  55: True, auto_model.encoder.layer.3.attention.self.key.weight\n",
            "  56: True, auto_model.encoder.layer.3.attention.self.key.bias\n",
            "  57: True, auto_model.encoder.layer.3.attention.self.value.weight\n",
            "  58: True, auto_model.encoder.layer.3.attention.self.value.bias\n",
            "  59: True, auto_model.encoder.layer.3.attention.output.dense.weight\n",
            "  60: True, auto_model.encoder.layer.3.attention.output.dense.bias\n",
            "  61: True, auto_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "  62: True, auto_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "  63: True, auto_model.encoder.layer.3.intermediate.dense.weight\n",
            "  64: True, auto_model.encoder.layer.3.intermediate.dense.bias\n",
            "  65: True, auto_model.encoder.layer.3.output.dense.weight\n",
            "  66: True, auto_model.encoder.layer.3.output.dense.bias\n",
            "  67: True, auto_model.encoder.layer.3.output.LayerNorm.weight\n",
            "  68: True, auto_model.encoder.layer.3.output.LayerNorm.bias\n",
            "  69: True, auto_model.encoder.layer.4.attention.self.query.weight\n",
            "  70: True, auto_model.encoder.layer.4.attention.self.query.bias\n",
            "  71: True, auto_model.encoder.layer.4.attention.self.key.weight\n",
            "  72: True, auto_model.encoder.layer.4.attention.self.key.bias\n",
            "  73: True, auto_model.encoder.layer.4.attention.self.value.weight\n",
            "  74: True, auto_model.encoder.layer.4.attention.self.value.bias\n",
            "  75: True, auto_model.encoder.layer.4.attention.output.dense.weight\n",
            "  76: True, auto_model.encoder.layer.4.attention.output.dense.bias\n",
            "  77: True, auto_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "  78: True, auto_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "  79: True, auto_model.encoder.layer.4.intermediate.dense.weight\n",
            "  80: True, auto_model.encoder.layer.4.intermediate.dense.bias\n",
            "  81: True, auto_model.encoder.layer.4.output.dense.weight\n",
            "  82: True, auto_model.encoder.layer.4.output.dense.bias\n",
            "  83: True, auto_model.encoder.layer.4.output.LayerNorm.weight\n",
            "  84: True, auto_model.encoder.layer.4.output.LayerNorm.bias\n",
            "  85: True, auto_model.encoder.layer.5.attention.self.query.weight\n",
            "  86: True, auto_model.encoder.layer.5.attention.self.query.bias\n",
            "  87: True, auto_model.encoder.layer.5.attention.self.key.weight\n",
            "  88: True, auto_model.encoder.layer.5.attention.self.key.bias\n",
            "  89: True, auto_model.encoder.layer.5.attention.self.value.weight\n",
            "  90: True, auto_model.encoder.layer.5.attention.self.value.bias\n",
            "  91: True, auto_model.encoder.layer.5.attention.output.dense.weight\n",
            "  92: True, auto_model.encoder.layer.5.attention.output.dense.bias\n",
            "  93: True, auto_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "  94: True, auto_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "  95: True, auto_model.encoder.layer.5.intermediate.dense.weight\n",
            "  96: True, auto_model.encoder.layer.5.intermediate.dense.bias\n",
            "  97: True, auto_model.encoder.layer.5.output.dense.weight\n",
            "  98: True, auto_model.encoder.layer.5.output.dense.bias\n",
            "  99: True, auto_model.encoder.layer.5.output.LayerNorm.weight\n",
            " 100: True, auto_model.encoder.layer.5.output.LayerNorm.bias\n",
            " 101: True, auto_model.encoder.layer.6.attention.self.query.weight\n",
            " 102: True, auto_model.encoder.layer.6.attention.self.query.bias\n",
            " 103: True, auto_model.encoder.layer.6.attention.self.key.weight\n",
            " 104: True, auto_model.encoder.layer.6.attention.self.key.bias\n",
            " 105: True, auto_model.encoder.layer.6.attention.self.value.weight\n",
            " 106: True, auto_model.encoder.layer.6.attention.self.value.bias\n",
            " 107: True, auto_model.encoder.layer.6.attention.output.dense.weight\n",
            " 108: True, auto_model.encoder.layer.6.attention.output.dense.bias\n",
            " 109: True, auto_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            " 110: True, auto_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            " 111: True, auto_model.encoder.layer.6.intermediate.dense.weight\n",
            " 112: True, auto_model.encoder.layer.6.intermediate.dense.bias\n",
            " 113: True, auto_model.encoder.layer.6.output.dense.weight\n",
            " 114: True, auto_model.encoder.layer.6.output.dense.bias\n",
            " 115: True, auto_model.encoder.layer.6.output.LayerNorm.weight\n",
            " 116: True, auto_model.encoder.layer.6.output.LayerNorm.bias\n",
            " 117: True, auto_model.encoder.layer.7.attention.self.query.weight\n",
            " 118: True, auto_model.encoder.layer.7.attention.self.query.bias\n",
            " 119: True, auto_model.encoder.layer.7.attention.self.key.weight\n",
            " 120: True, auto_model.encoder.layer.7.attention.self.key.bias\n",
            " 121: True, auto_model.encoder.layer.7.attention.self.value.weight\n",
            " 122: True, auto_model.encoder.layer.7.attention.self.value.bias\n",
            " 123: True, auto_model.encoder.layer.7.attention.output.dense.weight\n",
            " 124: True, auto_model.encoder.layer.7.attention.output.dense.bias\n",
            " 125: True, auto_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            " 126: True, auto_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            " 127: True, auto_model.encoder.layer.7.intermediate.dense.weight\n",
            " 128: True, auto_model.encoder.layer.7.intermediate.dense.bias\n",
            " 129: True, auto_model.encoder.layer.7.output.dense.weight\n",
            " 130: True, auto_model.encoder.layer.7.output.dense.bias\n",
            " 131: True, auto_model.encoder.layer.7.output.LayerNorm.weight\n",
            " 132: True, auto_model.encoder.layer.7.output.LayerNorm.bias\n",
            " 133: True, auto_model.encoder.layer.8.attention.self.query.weight\n",
            " 134: True, auto_model.encoder.layer.8.attention.self.query.bias\n",
            " 135: True, auto_model.encoder.layer.8.attention.self.key.weight\n",
            " 136: True, auto_model.encoder.layer.8.attention.self.key.bias\n",
            " 137: True, auto_model.encoder.layer.8.attention.self.value.weight\n",
            " 138: True, auto_model.encoder.layer.8.attention.self.value.bias\n",
            " 139: True, auto_model.encoder.layer.8.attention.output.dense.weight\n",
            " 140: True, auto_model.encoder.layer.8.attention.output.dense.bias\n",
            " 141: True, auto_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            " 142: True, auto_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            " 143: True, auto_model.encoder.layer.8.intermediate.dense.weight\n",
            " 144: True, auto_model.encoder.layer.8.intermediate.dense.bias\n",
            " 145: True, auto_model.encoder.layer.8.output.dense.weight\n",
            " 146: True, auto_model.encoder.layer.8.output.dense.bias\n",
            " 147: True, auto_model.encoder.layer.8.output.LayerNorm.weight\n",
            " 148: True, auto_model.encoder.layer.8.output.LayerNorm.bias\n",
            " 149: True, auto_model.encoder.layer.9.attention.self.query.weight\n",
            " 150: True, auto_model.encoder.layer.9.attention.self.query.bias\n",
            " 151: True, auto_model.encoder.layer.9.attention.self.key.weight\n",
            " 152: True, auto_model.encoder.layer.9.attention.self.key.bias\n",
            " 153: True, auto_model.encoder.layer.9.attention.self.value.weight\n",
            " 154: True, auto_model.encoder.layer.9.attention.self.value.bias\n",
            " 155: True, auto_model.encoder.layer.9.attention.output.dense.weight\n",
            " 156: True, auto_model.encoder.layer.9.attention.output.dense.bias\n",
            " 157: True, auto_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            " 158: True, auto_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            " 159: True, auto_model.encoder.layer.9.intermediate.dense.weight\n",
            " 160: True, auto_model.encoder.layer.9.intermediate.dense.bias\n",
            " 161: True, auto_model.encoder.layer.9.output.dense.weight\n",
            " 162: True, auto_model.encoder.layer.9.output.dense.bias\n",
            " 163: True, auto_model.encoder.layer.9.output.LayerNorm.weight\n",
            " 164: True, auto_model.encoder.layer.9.output.LayerNorm.bias\n",
            " 165: True, auto_model.encoder.layer.10.attention.self.query.weight\n",
            " 166: True, auto_model.encoder.layer.10.attention.self.query.bias\n",
            " 167: True, auto_model.encoder.layer.10.attention.self.key.weight\n",
            " 168: True, auto_model.encoder.layer.10.attention.self.key.bias\n",
            " 169: True, auto_model.encoder.layer.10.attention.self.value.weight\n",
            " 170: True, auto_model.encoder.layer.10.attention.self.value.bias\n",
            " 171: True, auto_model.encoder.layer.10.attention.output.dense.weight\n",
            " 172: True, auto_model.encoder.layer.10.attention.output.dense.bias\n",
            " 173: True, auto_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            " 174: True, auto_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            " 175: True, auto_model.encoder.layer.10.intermediate.dense.weight\n",
            " 176: True, auto_model.encoder.layer.10.intermediate.dense.bias\n",
            " 177: True, auto_model.encoder.layer.10.output.dense.weight\n",
            " 178: True, auto_model.encoder.layer.10.output.dense.bias\n",
            " 179: True, auto_model.encoder.layer.10.output.LayerNorm.weight\n",
            " 180: True, auto_model.encoder.layer.10.output.LayerNorm.bias\n",
            " 181: True, auto_model.encoder.layer.11.attention.self.query.weight\n",
            " 182: True, auto_model.encoder.layer.11.attention.self.query.bias\n",
            " 183: True, auto_model.encoder.layer.11.attention.self.key.weight\n",
            " 184: True, auto_model.encoder.layer.11.attention.self.key.bias\n",
            " 185: True, auto_model.encoder.layer.11.attention.self.value.weight\n",
            " 186: True, auto_model.encoder.layer.11.attention.self.value.bias\n",
            " 187: True, auto_model.encoder.layer.11.attention.output.dense.weight\n",
            " 188: True, auto_model.encoder.layer.11.attention.output.dense.bias\n",
            " 189: True, auto_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            " 190: True, auto_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            " 191: True, auto_model.encoder.layer.11.intermediate.dense.weight\n",
            " 192: True, auto_model.encoder.layer.11.intermediate.dense.bias\n",
            " 193: True, auto_model.encoder.layer.11.output.dense.weight\n",
            " 194: True, auto_model.encoder.layer.11.output.dense.bias\n",
            " 195: True, auto_model.encoder.layer.11.output.LayerNorm.weight\n",
            " 196: True, auto_model.encoder.layer.11.output.LayerNorm.bias\n",
            " 197: True, auto_model.encoder.layer.12.attention.self.query.weight\n",
            " 198: True, auto_model.encoder.layer.12.attention.self.query.bias\n",
            " 199: True, auto_model.encoder.layer.12.attention.self.key.weight\n",
            " 200: True, auto_model.encoder.layer.12.attention.self.key.bias\n",
            " 201: True, auto_model.encoder.layer.12.attention.self.value.weight\n",
            " 202: True, auto_model.encoder.layer.12.attention.self.value.bias\n",
            " 203: True, auto_model.encoder.layer.12.attention.output.dense.weight\n",
            " 204: True, auto_model.encoder.layer.12.attention.output.dense.bias\n",
            " 205: True, auto_model.encoder.layer.12.attention.output.LayerNorm.weight\n",
            " 206: True, auto_model.encoder.layer.12.attention.output.LayerNorm.bias\n",
            " 207: True, auto_model.encoder.layer.12.intermediate.dense.weight\n",
            " 208: True, auto_model.encoder.layer.12.intermediate.dense.bias\n",
            " 209: True, auto_model.encoder.layer.12.output.dense.weight\n",
            " 210: True, auto_model.encoder.layer.12.output.dense.bias\n",
            " 211: True, auto_model.encoder.layer.12.output.LayerNorm.weight\n",
            " 212: True, auto_model.encoder.layer.12.output.LayerNorm.bias\n",
            " 213: True, auto_model.encoder.layer.13.attention.self.query.weight\n",
            " 214: True, auto_model.encoder.layer.13.attention.self.query.bias\n",
            " 215: True, auto_model.encoder.layer.13.attention.self.key.weight\n",
            " 216: True, auto_model.encoder.layer.13.attention.self.key.bias\n",
            " 217: True, auto_model.encoder.layer.13.attention.self.value.weight\n",
            " 218: True, auto_model.encoder.layer.13.attention.self.value.bias\n",
            " 219: True, auto_model.encoder.layer.13.attention.output.dense.weight\n",
            " 220: True, auto_model.encoder.layer.13.attention.output.dense.bias\n",
            " 221: True, auto_model.encoder.layer.13.attention.output.LayerNorm.weight\n",
            " 222: True, auto_model.encoder.layer.13.attention.output.LayerNorm.bias\n",
            " 223: True, auto_model.encoder.layer.13.intermediate.dense.weight\n",
            " 224: True, auto_model.encoder.layer.13.intermediate.dense.bias\n",
            " 225: True, auto_model.encoder.layer.13.output.dense.weight\n",
            " 226: True, auto_model.encoder.layer.13.output.dense.bias\n",
            " 227: True, auto_model.encoder.layer.13.output.LayerNorm.weight\n",
            " 228: True, auto_model.encoder.layer.13.output.LayerNorm.bias\n",
            " 229: True, auto_model.encoder.layer.14.attention.self.query.weight\n",
            " 230: True, auto_model.encoder.layer.14.attention.self.query.bias\n",
            " 231: True, auto_model.encoder.layer.14.attention.self.key.weight\n",
            " 232: True, auto_model.encoder.layer.14.attention.self.key.bias\n",
            " 233: True, auto_model.encoder.layer.14.attention.self.value.weight\n",
            " 234: True, auto_model.encoder.layer.14.attention.self.value.bias\n",
            " 235: True, auto_model.encoder.layer.14.attention.output.dense.weight\n",
            " 236: True, auto_model.encoder.layer.14.attention.output.dense.bias\n",
            " 237: True, auto_model.encoder.layer.14.attention.output.LayerNorm.weight\n",
            " 238: True, auto_model.encoder.layer.14.attention.output.LayerNorm.bias\n",
            " 239: True, auto_model.encoder.layer.14.intermediate.dense.weight\n",
            " 240: True, auto_model.encoder.layer.14.intermediate.dense.bias\n",
            " 241: True, auto_model.encoder.layer.14.output.dense.weight\n",
            " 242: True, auto_model.encoder.layer.14.output.dense.bias\n",
            " 243: True, auto_model.encoder.layer.14.output.LayerNorm.weight\n",
            " 244: True, auto_model.encoder.layer.14.output.LayerNorm.bias\n",
            " 245: True, auto_model.encoder.layer.15.attention.self.query.weight\n",
            " 246: True, auto_model.encoder.layer.15.attention.self.query.bias\n",
            " 247: True, auto_model.encoder.layer.15.attention.self.key.weight\n",
            " 248: True, auto_model.encoder.layer.15.attention.self.key.bias\n",
            " 249: True, auto_model.encoder.layer.15.attention.self.value.weight\n",
            " 250: True, auto_model.encoder.layer.15.attention.self.value.bias\n",
            " 251: True, auto_model.encoder.layer.15.attention.output.dense.weight\n",
            " 252: True, auto_model.encoder.layer.15.attention.output.dense.bias\n",
            " 253: True, auto_model.encoder.layer.15.attention.output.LayerNorm.weight\n",
            " 254: True, auto_model.encoder.layer.15.attention.output.LayerNorm.bias\n",
            " 255: True, auto_model.encoder.layer.15.intermediate.dense.weight\n",
            " 256: True, auto_model.encoder.layer.15.intermediate.dense.bias\n",
            " 257: True, auto_model.encoder.layer.15.output.dense.weight\n",
            " 258: True, auto_model.encoder.layer.15.output.dense.bias\n",
            " 259: True, auto_model.encoder.layer.15.output.LayerNorm.weight\n",
            " 260: True, auto_model.encoder.layer.15.output.LayerNorm.bias\n",
            " 261: True, auto_model.encoder.layer.16.attention.self.query.weight\n",
            " 262: True, auto_model.encoder.layer.16.attention.self.query.bias\n",
            " 263: True, auto_model.encoder.layer.16.attention.self.key.weight\n",
            " 264: True, auto_model.encoder.layer.16.attention.self.key.bias\n",
            " 265: True, auto_model.encoder.layer.16.attention.self.value.weight\n",
            " 266: True, auto_model.encoder.layer.16.attention.self.value.bias\n",
            " 267: True, auto_model.encoder.layer.16.attention.output.dense.weight\n",
            " 268: True, auto_model.encoder.layer.16.attention.output.dense.bias\n",
            " 269: True, auto_model.encoder.layer.16.attention.output.LayerNorm.weight\n",
            " 270: True, auto_model.encoder.layer.16.attention.output.LayerNorm.bias\n",
            " 271: True, auto_model.encoder.layer.16.intermediate.dense.weight\n",
            " 272: True, auto_model.encoder.layer.16.intermediate.dense.bias\n",
            " 273: True, auto_model.encoder.layer.16.output.dense.weight\n",
            " 274: True, auto_model.encoder.layer.16.output.dense.bias\n",
            " 275: True, auto_model.encoder.layer.16.output.LayerNorm.weight\n",
            " 276: True, auto_model.encoder.layer.16.output.LayerNorm.bias\n",
            " 277: True, auto_model.encoder.layer.17.attention.self.query.weight\n",
            " 278: True, auto_model.encoder.layer.17.attention.self.query.bias\n",
            " 279: True, auto_model.encoder.layer.17.attention.self.key.weight\n",
            " 280: True, auto_model.encoder.layer.17.attention.self.key.bias\n",
            " 281: True, auto_model.encoder.layer.17.attention.self.value.weight\n",
            " 282: True, auto_model.encoder.layer.17.attention.self.value.bias\n",
            " 283: True, auto_model.encoder.layer.17.attention.output.dense.weight\n",
            " 284: True, auto_model.encoder.layer.17.attention.output.dense.bias\n",
            " 285: True, auto_model.encoder.layer.17.attention.output.LayerNorm.weight\n",
            " 286: True, auto_model.encoder.layer.17.attention.output.LayerNorm.bias\n",
            " 287: True, auto_model.encoder.layer.17.intermediate.dense.weight\n",
            " 288: True, auto_model.encoder.layer.17.intermediate.dense.bias\n",
            " 289: True, auto_model.encoder.layer.17.output.dense.weight\n",
            " 290: True, auto_model.encoder.layer.17.output.dense.bias\n",
            " 291: True, auto_model.encoder.layer.17.output.LayerNorm.weight\n",
            " 292: True, auto_model.encoder.layer.17.output.LayerNorm.bias\n",
            " 293: True, auto_model.encoder.layer.18.attention.self.query.weight\n",
            " 294: True, auto_model.encoder.layer.18.attention.self.query.bias\n",
            " 295: True, auto_model.encoder.layer.18.attention.self.key.weight\n",
            " 296: True, auto_model.encoder.layer.18.attention.self.key.bias\n",
            " 297: True, auto_model.encoder.layer.18.attention.self.value.weight\n",
            " 298: True, auto_model.encoder.layer.18.attention.self.value.bias\n",
            " 299: True, auto_model.encoder.layer.18.attention.output.dense.weight\n",
            " 300: True, auto_model.encoder.layer.18.attention.output.dense.bias\n",
            " 301: True, auto_model.encoder.layer.18.attention.output.LayerNorm.weight\n",
            " 302: True, auto_model.encoder.layer.18.attention.output.LayerNorm.bias\n",
            " 303: True, auto_model.encoder.layer.18.intermediate.dense.weight\n",
            " 304: True, auto_model.encoder.layer.18.intermediate.dense.bias\n",
            " 305: True, auto_model.encoder.layer.18.output.dense.weight\n",
            " 306: True, auto_model.encoder.layer.18.output.dense.bias\n",
            " 307: True, auto_model.encoder.layer.18.output.LayerNorm.weight\n",
            " 308: True, auto_model.encoder.layer.18.output.LayerNorm.bias\n",
            " 309: True, auto_model.encoder.layer.19.attention.self.query.weight\n",
            " 310: True, auto_model.encoder.layer.19.attention.self.query.bias\n",
            " 311: True, auto_model.encoder.layer.19.attention.self.key.weight\n",
            " 312: True, auto_model.encoder.layer.19.attention.self.key.bias\n",
            " 313: True, auto_model.encoder.layer.19.attention.self.value.weight\n",
            " 314: True, auto_model.encoder.layer.19.attention.self.value.bias\n",
            " 315: True, auto_model.encoder.layer.19.attention.output.dense.weight\n",
            " 316: True, auto_model.encoder.layer.19.attention.output.dense.bias\n",
            " 317: True, auto_model.encoder.layer.19.attention.output.LayerNorm.weight\n",
            " 318: True, auto_model.encoder.layer.19.attention.output.LayerNorm.bias\n",
            " 319: True, auto_model.encoder.layer.19.intermediate.dense.weight\n",
            " 320: True, auto_model.encoder.layer.19.intermediate.dense.bias\n",
            " 321: True, auto_model.encoder.layer.19.output.dense.weight\n",
            " 322: True, auto_model.encoder.layer.19.output.dense.bias\n",
            " 323: True, auto_model.encoder.layer.19.output.LayerNorm.weight\n",
            " 324: True, auto_model.encoder.layer.19.output.LayerNorm.bias\n",
            " 325: True, auto_model.encoder.layer.20.attention.self.query.weight\n",
            " 326: True, auto_model.encoder.layer.20.attention.self.query.bias\n",
            " 327: True, auto_model.encoder.layer.20.attention.self.key.weight\n",
            " 328: True, auto_model.encoder.layer.20.attention.self.key.bias\n",
            " 329: True, auto_model.encoder.layer.20.attention.self.value.weight\n",
            " 330: True, auto_model.encoder.layer.20.attention.self.value.bias\n",
            " 331: True, auto_model.encoder.layer.20.attention.output.dense.weight\n",
            " 332: True, auto_model.encoder.layer.20.attention.output.dense.bias\n",
            " 333: True, auto_model.encoder.layer.20.attention.output.LayerNorm.weight\n",
            " 334: True, auto_model.encoder.layer.20.attention.output.LayerNorm.bias\n",
            " 335: True, auto_model.encoder.layer.20.intermediate.dense.weight\n",
            " 336: True, auto_model.encoder.layer.20.intermediate.dense.bias\n",
            " 337: True, auto_model.encoder.layer.20.output.dense.weight\n",
            " 338: True, auto_model.encoder.layer.20.output.dense.bias\n",
            " 339: True, auto_model.encoder.layer.20.output.LayerNorm.weight\n",
            " 340: True, auto_model.encoder.layer.20.output.LayerNorm.bias\n",
            " 341: True, auto_model.encoder.layer.21.attention.self.query.weight\n",
            " 342: True, auto_model.encoder.layer.21.attention.self.query.bias\n",
            " 343: True, auto_model.encoder.layer.21.attention.self.key.weight\n",
            " 344: True, auto_model.encoder.layer.21.attention.self.key.bias\n",
            " 345: True, auto_model.encoder.layer.21.attention.self.value.weight\n",
            " 346: True, auto_model.encoder.layer.21.attention.self.value.bias\n",
            " 347: True, auto_model.encoder.layer.21.attention.output.dense.weight\n",
            " 348: True, auto_model.encoder.layer.21.attention.output.dense.bias\n",
            " 349: True, auto_model.encoder.layer.21.attention.output.LayerNorm.weight\n",
            " 350: True, auto_model.encoder.layer.21.attention.output.LayerNorm.bias\n",
            " 351: True, auto_model.encoder.layer.21.intermediate.dense.weight\n",
            " 352: True, auto_model.encoder.layer.21.intermediate.dense.bias\n",
            " 353: True, auto_model.encoder.layer.21.output.dense.weight\n",
            " 354: True, auto_model.encoder.layer.21.output.dense.bias\n",
            " 355: True, auto_model.encoder.layer.21.output.LayerNorm.weight\n",
            " 356: True, auto_model.encoder.layer.21.output.LayerNorm.bias\n",
            " 357: True, auto_model.encoder.layer.22.attention.self.query.weight\n",
            " 358: True, auto_model.encoder.layer.22.attention.self.query.bias\n",
            " 359: True, auto_model.encoder.layer.22.attention.self.key.weight\n",
            " 360: True, auto_model.encoder.layer.22.attention.self.key.bias\n",
            " 361: True, auto_model.encoder.layer.22.attention.self.value.weight\n",
            " 362: True, auto_model.encoder.layer.22.attention.self.value.bias\n",
            " 363: True, auto_model.encoder.layer.22.attention.output.dense.weight\n",
            " 364: True, auto_model.encoder.layer.22.attention.output.dense.bias\n",
            " 365: True, auto_model.encoder.layer.22.attention.output.LayerNorm.weight\n",
            " 366: True, auto_model.encoder.layer.22.attention.output.LayerNorm.bias\n",
            " 367: True, auto_model.encoder.layer.22.intermediate.dense.weight\n",
            " 368: True, auto_model.encoder.layer.22.intermediate.dense.bias\n",
            " 369: True, auto_model.encoder.layer.22.output.dense.weight\n",
            " 370: True, auto_model.encoder.layer.22.output.dense.bias\n",
            " 371: True, auto_model.encoder.layer.22.output.LayerNorm.weight\n",
            " 372: True, auto_model.encoder.layer.22.output.LayerNorm.bias\n",
            " 373: True, auto_model.encoder.layer.23.attention.self.query.weight\n",
            " 374: True, auto_model.encoder.layer.23.attention.self.query.bias\n",
            " 375: True, auto_model.encoder.layer.23.attention.self.key.weight\n",
            " 376: True, auto_model.encoder.layer.23.attention.self.key.bias\n",
            " 377: True, auto_model.encoder.layer.23.attention.self.value.weight\n",
            " 378: True, auto_model.encoder.layer.23.attention.self.value.bias\n",
            " 379: True, auto_model.encoder.layer.23.attention.output.dense.weight\n",
            " 380: True, auto_model.encoder.layer.23.attention.output.dense.bias\n",
            " 381: True, auto_model.encoder.layer.23.attention.output.LayerNorm.weight\n",
            " 382: True, auto_model.encoder.layer.23.attention.output.LayerNorm.bias\n",
            " 383: True, auto_model.encoder.layer.23.intermediate.dense.weight\n",
            " 384: True, auto_model.encoder.layer.23.intermediate.dense.bias\n",
            " 385: True, auto_model.encoder.layer.23.output.dense.weight\n",
            " 386: True, auto_model.encoder.layer.23.output.dense.bias\n",
            " 387: True, auto_model.encoder.layer.23.output.LayerNorm.weight\n",
            " 388: True, auto_model.encoder.layer.23.output.LayerNorm.bias\n",
            " 389: True, qa_outputs.weight\n",
            " 390: True, qa_outputs.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6NSxPjSDAp0"
      },
      "source": [
        "# Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_stCiHpfE4Cj"
      },
      "source": [
        "def bert_optimizer(model):\n",
        "    named_parameters = list(model.named_parameters())    \n",
        "\n",
        "    if (\n",
        "        \"base\" in config.model_name\n",
        "        or \"L-12\" in config.model_name\n",
        "    ):\n",
        "        bert_parameters = named_parameters[:197]    \n",
        "        regressor_parameters = named_parameters[197:]\n",
        "        second_block = 69\n",
        "        third_block = 133\n",
        "\n",
        "    elif (\n",
        "        \"large\" in config.model_name\n",
        "        or \"L-24\" in config.model_name\n",
        "    ):\n",
        "        bert_parameters = named_parameters[:389]    \n",
        "        regressor_parameters = named_parameters[389:]\n",
        "        second_block = 133\n",
        "        third_block = 261\n",
        "\n",
        "    elif \"rembert\" in config.model_name:\n",
        "        bert_parameters = named_parameters[:519]\n",
        "        regressor_parameters = named_parameters[519:]\n",
        "        second_block = 199\n",
        "        third_block = 359\n",
        "        \n",
        "    regressor_group = [params for (name, params) in regressor_parameters]\n",
        "\n",
        "    parameters = []\n",
        "    parameters.append({\"params\": regressor_group})\n",
        "\n",
        "    for layer_num, (name, params) in enumerate(bert_parameters):\n",
        "        weight_decay = 0.0 if \"bias\" in name else config.weight_decay\n",
        "\n",
        "        if layer_num >= third_block:\n",
        "            lr = config.max_lr\n",
        "        elif layer_num >= second_block:\n",
        "            lr = config.lr\n",
        "        else:\n",
        "            lr = config.min_lr\n",
        "\n",
        "        parameters.append({\"params\": params, \"weight_decay\": weight_decay, \"lr\": lr})\n",
        "\n",
        "    return T.AdamW(parameters, eps=1e-7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENcidivxDVIj"
      },
      "source": [
        "# Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkAGe7WFDWG4"
      },
      "source": [
        "def chaii_cross_entropy(preds, labels):\n",
        "    start_preds, end_preds = preds\n",
        "    start_labels, end_labels = labels\n",
        "    \n",
        "    start_loss = nn.CrossEntropyLoss(ignore_index=-1)(start_preds, start_labels)\n",
        "    end_loss = nn.CrossEntropyLoss(ignore_index=-1)(end_preds, end_labels)\n",
        "    total_loss = (start_loss + end_loss) / 2\n",
        "    return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJr7FSz5KvLt"
      },
      "source": [
        "# Scoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXFVz_OVKu2O"
      },
      "source": [
        "def jaccard(row): \n",
        "    str1 = row[0]\n",
        "    str2 = row[1]\n",
        "    a = set(str1.lower().split()) \n",
        "    b = set(str2.lower().split())\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfqKjGpLaMMX"
      },
      "source": [
        "def get_result(result_df, fold=config.n_fold):\n",
        "    score = result_df[\"jaccard\"].mean()\n",
        "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
        "    if fold == config.n_fold:\n",
        "        wandb.log({\"CV\": score})\n",
        "    else:\n",
        "        wandb.log({f\"CV_fold{fold}\": score})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7aZ38xCMG__"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD2wDdHMMMSc"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return \"%dm %ds\" % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrVjLs3H8DXV"
      },
      "source": [
        "def compute_grad_norm(parameters, norm_type=2.0):\n",
        "    \"\"\"Refer to torch.nn.utils.clip_grad_norm_\"\"\"\n",
        "    if isinstance(parameters, torch.Tensor):\n",
        "        parameters = [parameters]\n",
        "    parameters = [p for p in parameters if p.grad is not None]\n",
        "    norm_type = float(norm_type)\n",
        "    total_norm = 0\n",
        "    for p in parameters:\n",
        "        param_norm = p.grad.data.norm(norm_type)\n",
        "        total_norm += param_norm.item() ** norm_type\n",
        "    total_norm = total_norm ** (1. / norm_type)\n",
        "    return total_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laoX2YvHMW40"
      },
      "source": [
        "def train_fn(train_loader, model, criterion, optimizer, scheduler, scaler, fold, epoch, device):\n",
        "    losses = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    start = time.time()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for step, features in enumerate(train_loader):\n",
        "        input_ids = features[\"input_ids\"].to(device)\n",
        "        attention_mask = features[\"attention_mask\"].to(device)\n",
        "        labels_start = features[\"start_position\"].to(device)\n",
        "        labels_end = features[\"end_position\"].to(device)\n",
        "        batch_size = labels_start.size(0)\n",
        "\n",
        "        with amp.autocast(enabled=Config.amp):\n",
        "            out_start, out_end = model(input_ids, attention_mask)\n",
        "            loss = criterion((out_start, out_end), (labels_start, labels_end))\n",
        "            losses.update(loss.item(), batch_size)\n",
        "            loss = loss / config.gradient_accumulation_steps\n",
        "            \n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if (step + 1) % config.gradient_accumulation_steps == 0:\n",
        "            scaler.unscale_(optimizer)\n",
        "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "        else:\n",
        "            grad_norm = compute_grad_norm(model.parameters())\n",
        "\n",
        "        end = time.time()\n",
        "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
        "            print(\n",
        "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
        "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
        "                f\"Loss: {losses.avg:.4f} \"\n",
        "                f\"Grad: {grad_norm:.4f} \"\n",
        "                f\"LR: {scheduler.get_lr()[0]:.6f} \"\n",
        "            )\n",
        "            # wandb.log({\n",
        "            #     \"step\": (epoch) * len(train_loader) + step,\n",
        "            #     f\"loss/fold{fold}\": losses.avg,\n",
        "            #     f\"grad/fold{fold}\": grad_norm,\n",
        "            #     f\"lr/fold{fold}\": scheduler.get_lr()[0],\n",
        "            # })\n",
        "\n",
        "    return losses.avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-4GZ8PcPpLt"
      },
      "source": [
        "def valid_fn(valid_loader, model, criterion, device):\n",
        "    losses = AverageMeter()\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    preds_start = []\n",
        "    preds_end = []\n",
        "    start = time.time()\n",
        "\n",
        "    for step, features in enumerate(valid_loader):\n",
        "        input_ids = features[\"input_ids\"].to(device)\n",
        "        attention_mask = features[\"attention_mask\"].to(device)\n",
        "        labels_start = features[\"start_position\"].to(device)\n",
        "        labels_end = features[\"end_position\"].to(device)\n",
        "        batch_size = labels_start.size(0)\n",
        "\n",
        "        # compute loss\n",
        "        with torch.no_grad():\n",
        "            out_start, out_end = model(input_ids, attention_mask)\n",
        "\n",
        "        loss = criterion((out_start, out_end), (labels_start, labels_end))\n",
        "        losses.update(loss.item(), batch_size)\n",
        "\n",
        "        preds_start.append(out_start.to(\"cpu\").numpy())\n",
        "        preds_end.append(out_end.to(\"cpu\").numpy())\n",
        "        # preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
        "        # preds.append(y_preds.to(\"cpu\").numpy())\n",
        "\n",
        "        end = time.time()\n",
        "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
        "            print(\n",
        "                f\"EVAL: [{step}/{len(valid_loader)}] \"\n",
        "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
        "                f\"Loss: {losses.avg:.4f} \"\n",
        "            )\n",
        "\n",
        "    predictions_start = np.concatenate(preds_start)\n",
        "    predictions_end = np.concatenate(preds_end)\n",
        "    return losses.avg, predictions_start, predictions_end"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aS_0cqjWy5P"
      },
      "source": [
        "# Postprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn5pkRxmW0z_"
      },
      "source": [
        "def postprocess_qa_predictions(examples, features, tokenizer, raw_predictions, n_best_size=20, max_answer_length=30):\n",
        "    all_start_logits, all_end_logits = raw_predictions\n",
        "    \n",
        "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
        "    features_per_example = collections.defaultdict(list)\n",
        "    for i, feature in enumerate(features):\n",
        "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
        "\n",
        "    predictions = collections.OrderedDict()\n",
        "\n",
        "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
        "\n",
        "    for example_index, example in examples.iterrows():\n",
        "        feature_indices = features_per_example[example_index]\n",
        "\n",
        "        min_null_score = None\n",
        "        valid_answers = []\n",
        "        \n",
        "        context = example[\"context\"]\n",
        "        for feature_index in feature_indices:\n",
        "            start_logits = all_start_logits[feature_index]\n",
        "            end_logits = all_end_logits[feature_index]\n",
        "\n",
        "            sequence_ids = features[feature_index][\"sequence_ids\"]\n",
        "            context_index = 1\n",
        "\n",
        "            features[feature_index][\"offset_mapping\"] = [\n",
        "                (o if sequence_ids[k] == context_index else None)\n",
        "                for k, o in enumerate(features[feature_index][\"offset_mapping\"])\n",
        "            ]\n",
        "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
        "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
        "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
        "            if min_null_score is None or min_null_score < feature_null_score:\n",
        "                min_null_score = feature_null_score\n",
        "\n",
        "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            for start_index in start_indexes:\n",
        "                for end_index in end_indexes:\n",
        "                    if (\n",
        "                        start_index >= len(offset_mapping)\n",
        "                        or end_index >= len(offset_mapping)\n",
        "                        or offset_mapping[start_index] is None\n",
        "                        or offset_mapping[end_index] is None\n",
        "                    ):\n",
        "                        continue\n",
        "                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
        "                        continue\n",
        "\n",
        "                    start_char = offset_mapping[start_index][0]\n",
        "                    end_char = offset_mapping[end_index][1]\n",
        "                    valid_answers.append(\n",
        "                        {\n",
        "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                            \"text\": context[start_char: end_char]\n",
        "                        }\n",
        "                    )\n",
        "        \n",
        "        if len(valid_answers) > 0:\n",
        "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
        "        else:\n",
        "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
        "        \n",
        "        predictions[example[\"id\"]] = best_answer[\"text\"]\n",
        "\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUqyC9I8xyd9"
      },
      "source": [
        "# https://www.kaggle.com/nbroad/chaii-qa-torch-5-fold-with-post-processing-765\n",
        "def postpurocess_by_nbroad(preds_df):\n",
        "    bad_starts = [\".\", \",\", \"(\", \")\", \"-\", \"–\",  \",\", \";\"]\n",
        "    bad_endings = [\"...\", \"-\", \"(\", \")\", \"–\", \",\", \";\"]\n",
        "\n",
        "    tamil_ad = \"கி.பி\"\n",
        "    tamil_bc = \"கி.மு\"\n",
        "    tamil_km = \"கி.மீ\"\n",
        "    hindi_ad = \"ई\"\n",
        "    hindi_bc = \"ई.पू\"\n",
        "\n",
        "    cleaned_preds = []\n",
        "    for pred, context in preds_df[[\"prediction\", \"context\"]].to_numpy():\n",
        "        if pred == \"\":\n",
        "            cleaned_preds.append(pred)\n",
        "            continue\n",
        "        while any([pred.startswith(y) for y in bad_starts]):\n",
        "            pred = pred[1:]\n",
        "        while any([pred.endswith(y) for y in bad_endings]):\n",
        "            if pred.endswith(\"...\"):\n",
        "                pred = pred[:-3]\n",
        "            else:\n",
        "                pred = pred[:-1]\n",
        "\n",
        "        if any([pred.endswith(tamil_ad), pred.endswith(tamil_bc), pred.endswith(tamil_km), pred.endswith(hindi_ad), pred.endswith(hindi_bc)]) and pred+\".\" in context:\n",
        "            pred = pred+\".\"\n",
        "\n",
        "        cleaned_preds.append(pred)\n",
        "\n",
        "    preds_df[\"prediction\"] = cleaned_preds\n",
        "\n",
        "    return preds_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vwcRHThRbcm"
      },
      "source": [
        "# Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKmu1ZdXRdA7"
      },
      "source": [
        "def train_loop(df, fold):\n",
        "\n",
        "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
        "\n",
        "    # ====================================================\n",
        "    # Data Loader\n",
        "    # ====================================================\n",
        "    trn_idx = df[df[\"fold\"] != fold].index\n",
        "    val_idx = df[df[\"fold\"] == fold].index\n",
        "\n",
        "    train_folds = df.loc[trn_idx].reset_index(drop=True)\n",
        "    valid_folds = df.loc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    train_dataset = BaseDataset(train_folds, config.model_name)\n",
        "    valid_dataset = BaseDataset(valid_folds, config.model_name)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=4,\n",
        "        pin_memory=True,\n",
        "        drop_last=False,\n",
        "    )\n",
        "\n",
        "    # ====================================================\n",
        "    # Optimizer\n",
        "    # ====================================================\n",
        "    def get_optimizer(model):\n",
        "        if config.optimizer == \"Adam\":\n",
        "            optimizer = Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
        "        elif config.optimizer == \"AdamW\":\n",
        "            optimizer = T.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
        "        elif config.optimizer == \"BertAdamW\":\n",
        "            optimizer = bert_optimizer(model)\n",
        "        return optimizer\n",
        "\n",
        "    # ====================================================\n",
        "    # Scheduler\n",
        "    # ====================================================\n",
        "    def get_scheduler(optimizer):\n",
        "        # num_data = len(train_folds)\n",
        "        num_data = len(train_dataset)\n",
        "        num_steps = num_data // (config.batch_size * config.gradient_accumulation_steps) * config.epochs\n",
        "\n",
        "        if config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
        "            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=num_steps, T_mult=1, eta_min=config.min_lr, last_epoch=-1)\n",
        "        elif config.scheduler == \"CosineAnnealingLR\":\n",
        "            scheduler = CosineAnnealingLR(optimizer, T_max=num_steps, eta_min=config.min_lr, last_epoch=-1)\n",
        "        elif config.scheduler == \"CosineAnnealingWarmupRestarts\":\n",
        "            scheduler = CosineAnnealingWarmupRestarts(\n",
        "                optimizer, first_cycle_steps=num_steps, max_lr=config.lr, min_lr=config.min_lr, warmup_steps=(num_steps // 10)\n",
        "            )\n",
        "        elif config.scheduler == \"get_cosine_schedule_with_warmup\":\n",
        "            scheduler = T.get_cosine_schedule_with_warmup(\n",
        "                optimizer, num_training_steps=num_steps, num_warmup_steps=(num_steps // 10)\n",
        "            )\n",
        "        return scheduler\n",
        "\n",
        "    # ====================================================\n",
        "    # Model\n",
        "    # ====================================================\n",
        "    if config.model_class == \"bare\":\n",
        "        model = BaseModel(config.model_name)\n",
        "    elif config.model_class == \"qa\":\n",
        "        model = QAModel(config.model_name)\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = get_optimizer(model)\n",
        "    scaler = amp.GradScaler(enabled=Config.amp)\n",
        "    scheduler = get_scheduler(optimizer)\n",
        "\n",
        "    # ====================================================\n",
        "    # Criterion\n",
        "    # ====================================================\n",
        "    def get_criterion():\n",
        "        if config.criterion == \"CrossEntropyLoss\":\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "        elif config.criterion == \"BCEWithLogitsLoss\":\n",
        "            criterion = nn.BCEWithLogitsLoss()\n",
        "        elif config.criterion == \"MSELoss\":\n",
        "            criterion = nn.MSELoss()\n",
        "        elif config.criterion == \"ChaiiCrossEntropyLoss\":\n",
        "            criterion = chaii_cross_entropy\n",
        "        return criterion\n",
        "\n",
        "    criterion = get_criterion()\n",
        "\n",
        "    # ====================================================\n",
        "    # Loop\n",
        "    # ====================================================\n",
        "    best_score = -1\n",
        "    best_loss = np.inf\n",
        "    best_preds = None\n",
        "\n",
        "    wandb.watch(model, log_freq=Config.print_freq)\n",
        "\n",
        "    for epoch in range(config.epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # train\n",
        "        avg_loss = train_fn(train_loader, model, criterion, optimizer, scheduler, scaler, fold, epoch, device)\n",
        "\n",
        "        # eval\n",
        "        avg_val_loss, preds_start, preds_end = valid_fn(valid_loader, model, criterion, device)\n",
        "\n",
        "        # postprocess 1\n",
        "        predictions = postprocess_qa_predictions(\n",
        "            valid_folds, valid_dataset.features, valid_dataset.tokenizer, (preds_start, preds_end)\n",
        "        )\n",
        "\n",
        "        oof_df = valid_folds[[\"id\", \"context\", \"answer_text\"]]\n",
        "        oof_df[\"prediction\"] = oof_df['id'].apply(lambda r: predictions[r])\n",
        "\n",
        "        # postprocess 2\n",
        "        oof_df = postpurocess_by_nbroad(oof_df)\n",
        "\n",
        "        # scoring\n",
        "        oof_df['jaccard'] = oof_df[['answer_text', 'prediction']].apply(jaccard, axis=1)\n",
        "        score = oof_df[\"jaccard\"].mean()\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        LOGGER.info(f\"Epoch {epoch+1} - Score: {score}, Train Loss: {avg_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Time: {elapsed:.0f}s\")\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            f\"val_loss/fold{fold}\": avg_val_loss,\n",
        "            f\"score/fold{fold}\": score,\n",
        "        })\n",
        "        if avg_val_loss < best_loss:\n",
        "            best_score = score\n",
        "            best_loss = avg_val_loss\n",
        "            best_preds = predictions\n",
        "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Model. score: {best_score:.4f}, loss: {best_loss:.4f}\")\n",
        "\n",
        "            model_subdir = MODEL_DIR + f\"fold{fold}/\"\n",
        "            os.makedirs(model_subdir, exist_ok=True)\n",
        "            torch.save(model.state_dict(), f\"{model_subdir}/pytorch_model.bin\")\n",
        "            with open(f'{model_subdir}/preds.json', 'w') as f:\n",
        "                f.write(json.dumps(predictions, sort_keys=True, indent=4, ensure_ascii=False))\n",
        "            model.auto_config.save_pretrained(model_subdir)\n",
        "            train_dataset.tokenizer.save_pretrained(model_subdir)\n",
        "\n",
        "    valid_folds[\"prediction\"] = valid_folds['id'].apply(lambda r: best_preds[r])\n",
        "    valid_folds['jaccard'] = valid_folds[['answer_text', 'prediction']].apply(jaccard, axis=1)\n",
        "\n",
        "    return valid_folds, best_score, best_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znc9U4s9YPqs"
      },
      "source": [
        "# 🚀 Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIPgK02eYRCX"
      },
      "source": [
        "def main():\n",
        "    # ====================================================\n",
        "    # Training\n",
        "    # ====================================================\n",
        "    if Config.train:\n",
        "        oof_df = pd.DataFrame()\n",
        "        oof_result = []\n",
        "        for fold in range(config.n_fold):\n",
        "            seed_torch(seed + fold)\n",
        "\n",
        "            _oof_df, score, loss = train_loop(train, fold)\n",
        "            oof_df = pd.concat([oof_df, _oof_df])\n",
        "            oof_result.append([fold, score, loss])\n",
        "\n",
        "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
        "            get_result(_oof_df, fold)\n",
        "\n",
        "        # CV result\n",
        "        LOGGER.info(f\"========== CV ==========\")\n",
        "        get_result(oof_df)\n",
        "        \n",
        "        loss = statistics.mean([d[2] for d in oof_result])\n",
        "        wandb.log({\"loss\": loss})\n",
        "\n",
        "        table = wandb.Table(data=oof_result, columns = [\"fold\", \"score\", \"loss\"])\n",
        "        run.log({\"Fold Result\": table})\n",
        "        \n",
        "        # save result\n",
        "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"oof_df.csv\")\n",
        "\n",
        "        artifact = wandb.Artifact(config.model_name.replace('/', '-'), type='model')\n",
        "        artifact.add_dir(MODEL_DIR)\n",
        "        run.log_artifact(artifact)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4Q3YuoeYiLS",
        "outputId": "1d9472f0-9a85-4326-bb14-c77b5c5a5758"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "========== fold: 0 training ==========\n",
            "Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'qa_outputs.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [1][0/5982] Elapsed 0m 1s (remain 116m 50s) Loss: 6.1654 Grad: 5.6987 LR: 0.000000 \n",
            "Epoch: [1][100/5982] Elapsed 0m 58s (remain 56m 40s) Loss: 5.5192 Grad: 7.9162 LR: 0.000084 \n",
            "Epoch: [1][200/5982] Elapsed 1m 54s (remain 54m 59s) Loss: 3.8947 Grad: 6.1532 LR: 0.000167 \n",
            "Epoch: [1][300/5982] Elapsed 2m 51s (remain 53m 48s) Loss: 2.9398 Grad: 16.4977 LR: 0.000251 \n",
            "Epoch: [1][400/5982] Elapsed 3m 47s (remain 52m 45s) Loss: 2.4894 Grad: 14.4766 LR: 0.000335 \n",
            "Epoch: [1][500/5982] Elapsed 4m 43s (remain 51m 43s) Loss: 2.1770 Grad: 13.4975 LR: 0.000418 \n",
            "Epoch: [1][600/5982] Elapsed 5m 40s (remain 50m 44s) Loss: 1.9631 Grad: 15.2799 LR: 0.000502 \n",
            "Epoch: [1][700/5982] Elapsed 6m 36s (remain 49m 46s) Loss: 1.8082 Grad: 10.4813 LR: 0.000586 \n",
            "Epoch: [1][800/5982] Elapsed 7m 32s (remain 48m 48s) Loss: 1.6902 Grad: 19.0783 LR: 0.000669 \n",
            "Epoch: [1][900/5982] Elapsed 8m 29s (remain 47m 50s) Loss: 1.6073 Grad: 0.6474 LR: 0.000753 \n",
            "Epoch: [1][1000/5982] Elapsed 9m 25s (remain 46m 53s) Loss: 1.5379 Grad: 4.7147 LR: 0.000837 \n",
            "Epoch: [1][1100/5982] Elapsed 10m 21s (remain 45m 56s) Loss: 1.4692 Grad: 3.4237 LR: 0.000921 \n",
            "Epoch: [1][1200/5982] Elapsed 11m 18s (remain 44m 59s) Loss: 1.4253 Grad: 7.2599 LR: 0.001000 \n",
            "Epoch: [1][1300/5982] Elapsed 12m 14s (remain 44m 2s) Loss: 1.3936 Grad: 9.3497 LR: 0.001000 \n",
            "Epoch: [1][1400/5982] Elapsed 13m 10s (remain 43m 5s) Loss: 1.3666 Grad: 8.1562 LR: 0.000999 \n",
            "Epoch: [1][1500/5982] Elapsed 14m 7s (remain 42m 8s) Loss: 1.3488 Grad: 6.5448 LR: 0.000998 \n",
            "Epoch: [1][1600/5982] Elapsed 15m 3s (remain 41m 12s) Loss: 1.3272 Grad: 7.3746 LR: 0.000997 \n",
            "Epoch: [1][1700/5982] Elapsed 15m 59s (remain 40m 15s) Loss: 1.3069 Grad: 4.5353 LR: 0.000995 \n",
            "Epoch: [1][1800/5982] Elapsed 16m 56s (remain 39m 18s) Loss: 1.2795 Grad: 11.2796 LR: 0.000992 \n",
            "Epoch: [1][1900/5982] Elapsed 17m 52s (remain 38m 22s) Loss: 1.2560 Grad: 16.4303 LR: 0.000989 \n",
            "Epoch: [1][2000/5982] Elapsed 18m 48s (remain 37m 25s) Loss: 1.2410 Grad: 3.7691 LR: 0.000986 \n",
            "Epoch: [1][2100/5982] Elapsed 19m 45s (remain 36m 29s) Loss: 1.2271 Grad: 16.5229 LR: 0.000983 \n",
            "Epoch: [1][2200/5982] Elapsed 20m 41s (remain 35m 32s) Loss: 1.2129 Grad: 8.0821 LR: 0.000979 \n",
            "Epoch: [1][2300/5982] Elapsed 21m 37s (remain 34m 36s) Loss: 1.1979 Grad: 3.6908 LR: 0.000974 \n",
            "Epoch: [1][2400/5982] Elapsed 22m 34s (remain 33m 39s) Loss: 1.1856 Grad: 15.8734 LR: 0.000969 \n",
            "Epoch: [1][2500/5982] Elapsed 23m 30s (remain 32m 43s) Loss: 1.1733 Grad: 9.3644 LR: 0.000964 \n",
            "Epoch: [1][2600/5982] Elapsed 24m 26s (remain 31m 46s) Loss: 1.1635 Grad: 14.9225 LR: 0.000959 \n",
            "Epoch: [1][2700/5982] Elapsed 25m 23s (remain 30m 50s) Loss: 1.1509 Grad: 6.4485 LR: 0.000953 \n",
            "Epoch: [1][2800/5982] Elapsed 26m 19s (remain 29m 53s) Loss: 1.1424 Grad: 9.4130 LR: 0.000946 \n",
            "Epoch: [1][2900/5982] Elapsed 27m 15s (remain 28m 57s) Loss: 1.1332 Grad: 20.9774 LR: 0.000939 \n",
            "Epoch: [1][3000/5982] Elapsed 28m 12s (remain 28m 0s) Loss: 1.1310 Grad: 14.3072 LR: 0.000932 \n",
            "Epoch: [1][3100/5982] Elapsed 29m 8s (remain 27m 4s) Loss: 1.1257 Grad: 21.9281 LR: 0.000925 \n",
            "Epoch: [1][3200/5982] Elapsed 30m 4s (remain 26m 7s) Loss: 1.1174 Grad: 26.4564 LR: 0.000917 \n",
            "Epoch: [1][3300/5982] Elapsed 31m 0s (remain 25m 11s) Loss: 1.1084 Grad: 9.9022 LR: 0.000909 \n",
            "Epoch: [1][3400/5982] Elapsed 31m 57s (remain 24m 14s) Loss: 1.1007 Grad: 5.0010 LR: 0.000900 \n",
            "Epoch: [1][3500/5982] Elapsed 32m 53s (remain 23m 18s) Loss: 1.0944 Grad: 12.0924 LR: 0.000891 \n",
            "Epoch: [1][3600/5982] Elapsed 33m 49s (remain 22m 22s) Loss: 1.0898 Grad: 0.3261 LR: 0.000882 \n",
            "Epoch: [1][3700/5982] Elapsed 34m 46s (remain 21m 25s) Loss: 1.0812 Grad: 7.3984 LR: 0.000872 \n",
            "Epoch: [1][3800/5982] Elapsed 35m 42s (remain 20m 29s) Loss: 1.0805 Grad: 13.7303 LR: 0.000862 \n",
            "Epoch: [1][3900/5982] Elapsed 36m 38s (remain 19m 32s) Loss: 1.0745 Grad: 18.1660 LR: 0.000852 \n",
            "Epoch: [1][4000/5982] Elapsed 37m 35s (remain 18m 36s) Loss: 1.0671 Grad: 18.1087 LR: 0.000842 \n",
            "Epoch: [1][4100/5982] Elapsed 38m 31s (remain 17m 40s) Loss: 1.0630 Grad: 4.6077 LR: 0.000831 \n",
            "Epoch: [1][4200/5982] Elapsed 39m 27s (remain 16m 43s) Loss: 1.0581 Grad: 3.2615 LR: 0.000820 \n",
            "Epoch: [1][4300/5982] Elapsed 40m 24s (remain 15m 47s) Loss: 1.0519 Grad: 11.8096 LR: 0.000808 \n",
            "Epoch: [1][4400/5982] Elapsed 41m 20s (remain 14m 51s) Loss: 1.0450 Grad: 0.1446 LR: 0.000797 \n",
            "Epoch: [1][4500/5982] Elapsed 42m 16s (remain 13m 54s) Loss: 1.0404 Grad: 18.5426 LR: 0.000785 \n",
            "Epoch: [1][4600/5982] Elapsed 43m 13s (remain 12m 58s) Loss: 1.0355 Grad: 15.5552 LR: 0.000773 \n",
            "Epoch: [1][4700/5982] Elapsed 44m 9s (remain 12m 1s) Loss: 1.0308 Grad: 5.5330 LR: 0.000760 \n",
            "Epoch: [1][4800/5982] Elapsed 45m 5s (remain 11m 5s) Loss: 1.0266 Grad: 13.9819 LR: 0.000748 \n",
            "Epoch: [1][4900/5982] Elapsed 46m 2s (remain 10m 9s) Loss: 1.0205 Grad: 5.3731 LR: 0.000735 \n",
            "Epoch: [1][5000/5982] Elapsed 46m 58s (remain 9m 12s) Loss: 1.0179 Grad: 32.5559 LR: 0.000722 \n",
            "Epoch: [1][5100/5982] Elapsed 47m 54s (remain 8m 16s) Loss: 1.0137 Grad: 0.4856 LR: 0.000709 \n",
            "Epoch: [1][5200/5982] Elapsed 48m 50s (remain 7m 20s) Loss: 1.0087 Grad: 6.4295 LR: 0.000696 \n",
            "Epoch: [1][5300/5982] Elapsed 49m 47s (remain 6m 23s) Loss: 1.0031 Grad: 3.4133 LR: 0.000682 \n",
            "Epoch: [1][5400/5982] Elapsed 50m 43s (remain 5m 27s) Loss: 0.9978 Grad: 7.7791 LR: 0.000668 \n",
            "Epoch: [1][5500/5982] Elapsed 51m 39s (remain 4m 31s) Loss: 0.9937 Grad: 13.5448 LR: 0.000655 \n",
            "Epoch: [1][5600/5982] Elapsed 52m 36s (remain 3m 34s) Loss: 0.9912 Grad: 9.9860 LR: 0.000641 \n",
            "Epoch: [1][5700/5982] Elapsed 53m 32s (remain 2m 38s) Loss: 0.9866 Grad: 20.3888 LR: 0.000627 \n",
            "Epoch: [1][5800/5982] Elapsed 54m 28s (remain 1m 41s) Loss: 0.9840 Grad: 11.1494 LR: 0.000612 \n",
            "Epoch: [1][5900/5982] Elapsed 55m 25s (remain 0m 45s) Loss: 0.9798 Grad: 11.6690 LR: 0.000598 \n",
            "Epoch: [1][5981/5982] Elapsed 56m 9s (remain 0m 0s) Loss: 0.9767 Grad: 14.1682 LR: 0.000587 \n",
            "EVAL: [0/738] Elapsed 0m 0s (remain 8m 26s) Loss: 0.1019 \n",
            "EVAL: [100/738] Elapsed 0m 17s (remain 1m 52s) Loss: 0.2821 \n",
            "EVAL: [200/738] Elapsed 0m 35s (remain 1m 33s) Loss: 0.2526 \n",
            "EVAL: [300/738] Elapsed 0m 52s (remain 1m 15s) Loss: 0.2392 \n",
            "EVAL: [400/738] Elapsed 1m 9s (remain 0m 58s) Loss: 0.2471 \n",
            "EVAL: [500/738] Elapsed 1m 26s (remain 0m 40s) Loss: 0.2432 \n",
            "EVAL: [600/738] Elapsed 1m 43s (remain 0m 23s) Loss: 0.2448 \n",
            "EVAL: [700/738] Elapsed 2m 1s (remain 0m 6s) Loss: 0.2518 \n",
            "EVAL: [737/738] Elapsed 2m 7s (remain 0m 0s) Loss: 0.2530 \n",
            "Post-processing 223 example predictions split into 2952 features.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Score: 0.6474072887750018, Train Loss: 0.9767, Val Loss: 0.2530, Time: 3498s\n",
            "Epoch 1 - Save Best Model. score: 0.6474, loss: 0.2530\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [2][0/5982] Elapsed 0m 1s (remain 106m 58s) Loss: 0.4070 Grad: 4.7457 LR: 0.000587 \n",
            "Epoch: [2][100/5982] Elapsed 0m 57s (remain 55m 48s) Loss: 0.4648 Grad: 3.6557 LR: 0.000572 \n",
            "Epoch: [2][200/5982] Elapsed 1m 53s (remain 54m 35s) Loss: 0.4378 Grad: 6.2257 LR: 0.000558 \n",
            "Epoch: [2][300/5982] Elapsed 2m 50s (remain 53m 31s) Loss: 0.4594 Grad: 3.0374 LR: 0.000543 \n",
            "Epoch: [2][400/5982] Elapsed 3m 46s (remain 52m 32s) Loss: 0.4730 Grad: 0.4207 LR: 0.000529 \n",
            "Epoch: [2][500/5982] Elapsed 4m 42s (remain 51m 34s) Loss: 0.4653 Grad: 526.9499 LR: 0.000514 \n",
            "Epoch: [2][600/5982] Elapsed 5m 39s (remain 50m 37s) Loss: 0.4758 Grad: 0.5351 LR: 0.000500 \n",
            "Epoch: [2][700/5982] Elapsed 6m 35s (remain 49m 39s) Loss: 0.4742 Grad: 21.2578 LR: 0.000485 \n",
            "Epoch: [2][800/5982] Elapsed 7m 31s (remain 48m 42s) Loss: 0.4749 Grad: 7.6576 LR: 0.000470 \n",
            "Epoch: [2][900/5982] Elapsed 8m 28s (remain 47m 46s) Loss: 0.4602 Grad: 6.6209 LR: 0.000456 \n",
            "Epoch: [2][1000/5982] Elapsed 9m 24s (remain 46m 49s) Loss: 0.4524 Grad: 18.1949 LR: 0.000441 \n",
            "Epoch: [2][1100/5982] Elapsed 10m 20s (remain 45m 52s) Loss: 0.4419 Grad: 0.8456 LR: 0.000427 \n",
            "Epoch: [2][1200/5982] Elapsed 11m 17s (remain 44m 55s) Loss: 0.4381 Grad: 0.0941 LR: 0.000413 \n",
            "Epoch: [2][1300/5982] Elapsed 12m 13s (remain 43m 59s) Loss: 0.4405 Grad: 2.2170 LR: 0.000398 \n",
            "Epoch: [2][1400/5982] Elapsed 13m 9s (remain 43m 2s) Loss: 0.4394 Grad: 0.9480 LR: 0.000384 \n",
            "Epoch: [2][1500/5982] Elapsed 14m 6s (remain 42m 6s) Loss: 0.4369 Grad: 4.4621 LR: 0.000370 \n",
            "Epoch: [2][1600/5982] Elapsed 15m 2s (remain 41m 9s) Loss: 0.4369 Grad: 16.6759 LR: 0.000356 \n",
            "Epoch: [2][1700/5982] Elapsed 15m 58s (remain 40m 13s) Loss: 0.4361 Grad: 0.5670 LR: 0.000342 \n",
            "Epoch: [2][1800/5982] Elapsed 16m 55s (remain 39m 16s) Loss: 0.4320 Grad: 26.9889 LR: 0.000328 \n",
            "Epoch: [2][1900/5982] Elapsed 17m 51s (remain 38m 20s) Loss: 0.4334 Grad: 13.6284 LR: 0.000314 \n",
            "Epoch: [2][2000/5982] Elapsed 18m 47s (remain 37m 23s) Loss: 0.4362 Grad: 14.5086 LR: 0.000301 \n",
            "Epoch: [2][2100/5982] Elapsed 19m 44s (remain 36m 27s) Loss: 0.4309 Grad: 7.9116 LR: 0.000288 \n",
            "Epoch: [2][2200/5982] Elapsed 20m 40s (remain 35m 30s) Loss: 0.4332 Grad: 0.0717 LR: 0.000275 \n",
            "Epoch: [2][2300/5982] Elapsed 21m 36s (remain 34m 34s) Loss: 0.4291 Grad: 0.0316 LR: 0.000262 \n",
            "Epoch: [2][2400/5982] Elapsed 22m 32s (remain 33m 37s) Loss: 0.4281 Grad: 5.1804 LR: 0.000249 \n",
            "Epoch: [2][2500/5982] Elapsed 23m 29s (remain 32m 41s) Loss: 0.4224 Grad: 6.4689 LR: 0.000236 \n",
            "Epoch: [2][2600/5982] Elapsed 24m 25s (remain 31m 45s) Loss: 0.4252 Grad: 5.9276 LR: 0.000224 \n",
            "Epoch: [2][2700/5982] Elapsed 25m 21s (remain 30m 48s) Loss: 0.4249 Grad: 3.2047 LR: 0.000212 \n",
            "Epoch: [2][2800/5982] Elapsed 26m 20s (remain 29m 54s) Loss: 0.4240 Grad: 1.4081 LR: 0.000200 \n",
            "Epoch: [2][2900/5982] Elapsed 27m 16s (remain 28m 57s) Loss: 0.4252 Grad: 0.1295 LR: 0.000189 \n",
            "Epoch: [2][3000/5982] Elapsed 28m 12s (remain 28m 1s) Loss: 0.4249 Grad: 6.9917 LR: 0.000177 \n",
            "Epoch: [2][3100/5982] Elapsed 29m 8s (remain 27m 4s) Loss: 0.4230 Grad: 30.7707 LR: 0.000166 \n",
            "Epoch: [2][3200/5982] Elapsed 30m 5s (remain 26m 8s) Loss: 0.4202 Grad: 27.4438 LR: 0.000156 \n",
            "Epoch: [2][3300/5982] Elapsed 31m 1s (remain 25m 11s) Loss: 0.4214 Grad: 15.9744 LR: 0.000145 \n",
            "Epoch: [2][3400/5982] Elapsed 31m 57s (remain 24m 15s) Loss: 0.4187 Grad: 1.6286 LR: 0.000135 \n",
            "Epoch: [2][3500/5982] Elapsed 32m 54s (remain 23m 19s) Loss: 0.4180 Grad: 15.9751 LR: 0.000125 \n",
            "Epoch: [2][3600/5982] Elapsed 33m 50s (remain 22m 22s) Loss: 0.4186 Grad: 0.1943 LR: 0.000116 \n",
            "Epoch: [2][3700/5982] Elapsed 34m 46s (remain 21m 26s) Loss: 0.4171 Grad: 4.7343 LR: 0.000107 \n",
            "Epoch: [2][3800/5982] Elapsed 35m 43s (remain 20m 29s) Loss: 0.4159 Grad: 5.0732 LR: 0.000098 \n",
            "Epoch: [2][3900/5982] Elapsed 36m 39s (remain 19m 33s) Loss: 0.4155 Grad: 7.1060 LR: 0.000089 \n",
            "Epoch: [2][4000/5982] Elapsed 37m 35s (remain 18m 36s) Loss: 0.4163 Grad: 7.4474 LR: 0.000081 \n",
            "Epoch: [2][4100/5982] Elapsed 38m 32s (remain 17m 40s) Loss: 0.4161 Grad: 11.7154 LR: 0.000073 \n",
            "Epoch: [2][4200/5982] Elapsed 39m 28s (remain 16m 44s) Loss: 0.4153 Grad: 34.3579 LR: 0.000066 \n",
            "Epoch: [2][4300/5982] Elapsed 40m 24s (remain 15m 47s) Loss: 0.4146 Grad: 15.2167 LR: 0.000059 \n",
            "Epoch: [2][4400/5982] Elapsed 41m 21s (remain 14m 51s) Loss: 0.4139 Grad: 11.5752 LR: 0.000052 \n",
            "Epoch: [2][4500/5982] Elapsed 42m 17s (remain 13m 55s) Loss: 0.4144 Grad: 1.0518 LR: 0.000046 \n",
            "Epoch: [2][4600/5982] Elapsed 43m 14s (remain 12m 58s) Loss: 0.4127 Grad: 5.8537 LR: 0.000040 \n",
            "Epoch: [2][4700/5982] Elapsed 44m 10s (remain 12m 2s) Loss: 0.4119 Grad: 3.6317 LR: 0.000034 \n",
            "Epoch: [2][4800/5982] Elapsed 45m 6s (remain 11m 5s) Loss: 0.4118 Grad: 1.7101 LR: 0.000029 \n",
            "Epoch: [2][4900/5982] Elapsed 46m 3s (remain 10m 9s) Loss: 0.4100 Grad: 11.8327 LR: 0.000025 \n",
            "Epoch: [2][5000/5982] Elapsed 46m 59s (remain 9m 13s) Loss: 0.4106 Grad: 0.5060 LR: 0.000020 \n",
            "Epoch: [2][5100/5982] Elapsed 47m 55s (remain 8m 16s) Loss: 0.4117 Grad: 1.4591 LR: 0.000016 \n",
            "Epoch: [2][5200/5982] Elapsed 48m 52s (remain 7m 20s) Loss: 0.4101 Grad: 6.9917 LR: 0.000013 \n",
            "Epoch: [2][5300/5982] Elapsed 49m 48s (remain 6m 23s) Loss: 0.4100 Grad: 4.7095 LR: 0.000010 \n",
            "Epoch: [2][5400/5982] Elapsed 50m 45s (remain 5m 27s) Loss: 0.4089 Grad: 2.4470 LR: 0.000007 \n",
            "Epoch: [2][5500/5982] Elapsed 51m 41s (remain 4m 31s) Loss: 0.4074 Grad: 7.9172 LR: 0.000005 \n",
            "Epoch: [2][5600/5982] Elapsed 52m 37s (remain 3m 34s) Loss: 0.4060 Grad: 11.1059 LR: 0.000003 \n",
            "Epoch: [2][5700/5982] Elapsed 53m 34s (remain 2m 38s) Loss: 0.4034 Grad: 7.6433 LR: 0.000002 \n",
            "Epoch: [2][5800/5982] Elapsed 54m 30s (remain 1m 42s) Loss: 0.4034 Grad: 6.3691 LR: 0.000001 \n",
            "Epoch: [2][5900/5982] Elapsed 55m 27s (remain 0m 45s) Loss: 0.4033 Grad: 2.6650 LR: 0.000000 \n",
            "Epoch: [2][5981/5982] Elapsed 56m 13s (remain 0m 0s) Loss: 0.4035 Grad: 12.2100 LR: 0.000000 \n",
            "EVAL: [0/738] Elapsed 0m 0s (remain 8m 40s) Loss: 0.0195 \n",
            "EVAL: [100/738] Elapsed 0m 17s (remain 1m 52s) Loss: 0.2607 \n",
            "EVAL: [200/738] Elapsed 0m 35s (remain 1m 33s) Loss: 0.2658 \n",
            "EVAL: [300/738] Elapsed 0m 52s (remain 1m 15s) Loss: 0.2462 \n",
            "EVAL: [400/738] Elapsed 1m 9s (remain 0m 58s) Loss: 0.2508 \n",
            "EVAL: [500/738] Elapsed 1m 26s (remain 0m 41s) Loss: 0.2505 \n",
            "EVAL: [600/738] Elapsed 1m 43s (remain 0m 23s) Loss: 0.2586 \n",
            "EVAL: [700/738] Elapsed 2m 1s (remain 0m 6s) Loss: 0.2664 \n",
            "EVAL: [737/738] Elapsed 2m 7s (remain 0m 0s) Loss: 0.2686 \n",
            "Post-processing 223 example predictions split into 2952 features.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2 - Score: 0.6874564025909318, Train Loss: 0.4035, Val Loss: 0.2686, Time: 3502s\n",
            "========== fold: 0 result ==========\n",
            "Score: 0.63694\n",
            "========== fold: 1 training ==========\n",
            "Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'qa_outputs.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [1][0/5994] Elapsed 0m 1s (remain 108m 29s) Loss: 5.3079 Grad: 6.3694 LR: 0.000000 \n",
            "Epoch: [1][100/5994] Elapsed 0m 57s (remain 55m 53s) Loss: 4.9495 Grad: 6.8206 LR: 0.000084 \n",
            "Epoch: [1][200/5994] Elapsed 1m 53s (remain 54m 41s) Loss: 3.4561 Grad: 21.5871 LR: 0.000167 \n",
            "Epoch: [1][300/5994] Elapsed 2m 52s (remain 54m 15s) Loss: 2.6666 Grad: 13.6854 LR: 0.000251 \n",
            "Epoch: [1][400/5994] Elapsed 3m 48s (remain 53m 6s) Loss: 2.2438 Grad: 9.1164 LR: 0.000335 \n",
            "Epoch: [1][500/5994] Elapsed 4m 44s (remain 52m 2s) Loss: 1.9997 Grad: 8.4948 LR: 0.000418 \n",
            "Epoch: [1][600/5994] Elapsed 5m 41s (remain 51m 1s) Loss: 1.8104 Grad: 9.3798 LR: 0.000502 \n",
            "Epoch: [1][700/5994] Elapsed 6m 37s (remain 50m 2s) Loss: 1.6698 Grad: 5.8208 LR: 0.000586 \n",
            "Epoch: [1][800/5994] Elapsed 7m 33s (remain 49m 3s) Loss: 1.5925 Grad: 9.5117 LR: 0.000669 \n",
            "Epoch: [1][900/5994] Elapsed 8m 30s (remain 48m 5s) Loss: 1.5160 Grad: 17.3274 LR: 0.000753 \n",
            "Epoch: [1][1000/5994] Elapsed 9m 26s (remain 47m 7s) Loss: 1.4633 Grad: 18.8117 LR: 0.000837 \n",
            "Epoch: [1][1100/5994] Elapsed 10m 23s (remain 46m 9s) Loss: 1.4099 Grad: 22.8675 LR: 0.000921 \n",
            "Epoch: [1][1200/5994] Elapsed 11m 19s (remain 45m 12s) Loss: 1.3707 Grad: 7.3286 LR: 0.001000 \n",
            "Epoch: [1][1300/5994] Elapsed 12m 15s (remain 44m 14s) Loss: 1.3361 Grad: 51.2127 LR: 0.001000 \n",
            "Epoch: [1][1400/5994] Elapsed 13m 12s (remain 43m 17s) Loss: 1.3239 Grad: 20.8561 LR: 0.000999 \n",
            "Epoch: [1][1500/5994] Elapsed 14m 8s (remain 42m 20s) Loss: 1.2974 Grad: 11.6905 LR: 0.000998 \n",
            "Epoch: [1][1600/5994] Elapsed 15m 5s (remain 41m 23s) Loss: 1.2817 Grad: 12.0662 LR: 0.000997 \n",
            "Epoch: [1][1700/5994] Elapsed 16m 1s (remain 40m 26s) Loss: 1.2694 Grad: 17.4119 LR: 0.000995 \n",
            "Epoch: [1][1800/5994] Elapsed 16m 57s (remain 39m 29s) Loss: 1.2525 Grad: 2.2353 LR: 0.000992 \n",
            "Epoch: [1][1900/5994] Elapsed 17m 53s (remain 38m 32s) Loss: 1.2298 Grad: 8.7397 LR: 0.000989 \n",
            "Epoch: [1][2000/5994] Elapsed 18m 50s (remain 37m 35s) Loss: 1.2175 Grad: 11.9558 LR: 0.000986 \n",
            "Epoch: [1][2100/5994] Elapsed 19m 46s (remain 36m 38s) Loss: 1.2016 Grad: 4.2212 LR: 0.000983 \n",
            "Epoch: [1][2200/5994] Elapsed 20m 42s (remain 35m 41s) Loss: 1.1867 Grad: 24.8663 LR: 0.000979 \n",
            "Epoch: [1][2300/5994] Elapsed 21m 39s (remain 34m 45s) Loss: 1.1872 Grad: 7.9464 LR: 0.000974 \n",
            "Epoch: [1][2400/5994] Elapsed 22m 35s (remain 33m 48s) Loss: 1.1713 Grad: 1.0407 LR: 0.000970 \n",
            "Epoch: [1][2500/5994] Elapsed 23m 31s (remain 32m 51s) Loss: 1.1600 Grad: 0.7361 LR: 0.000964 \n",
            "Epoch: [1][2600/5994] Elapsed 24m 28s (remain 31m 55s) Loss: 1.1497 Grad: 11.9354 LR: 0.000959 \n",
            "Epoch: [1][2700/5994] Elapsed 25m 24s (remain 30m 58s) Loss: 1.1458 Grad: 17.0321 LR: 0.000953 \n",
            "Epoch: [1][2800/5994] Elapsed 26m 20s (remain 30m 1s) Loss: 1.1375 Grad: 3.2481 LR: 0.000946 \n",
            "Epoch: [1][2900/5994] Elapsed 27m 16s (remain 29m 5s) Loss: 1.1294 Grad: 2.0456 LR: 0.000940 \n",
            "Epoch: [1][3000/5994] Elapsed 28m 13s (remain 28m 8s) Loss: 1.1209 Grad: 23.9909 LR: 0.000932 \n",
            "Epoch: [1][3100/5994] Elapsed 29m 9s (remain 27m 12s) Loss: 1.1114 Grad: 3.5261 LR: 0.000925 \n",
            "Epoch: [1][3200/5994] Elapsed 30m 5s (remain 26m 15s) Loss: 1.1042 Grad: 3.3895 LR: 0.000917 \n",
            "Epoch: [1][3300/5994] Elapsed 31m 2s (remain 25m 19s) Loss: 1.0951 Grad: 7.9198 LR: 0.000909 \n",
            "Epoch: [1][3400/5994] Elapsed 31m 58s (remain 24m 22s) Loss: 1.0864 Grad: 19.4495 LR: 0.000900 \n",
            "Epoch: [1][3500/5994] Elapsed 32m 54s (remain 23m 26s) Loss: 1.0815 Grad: 7.5387 LR: 0.000891 \n",
            "Epoch: [1][3600/5994] Elapsed 33m 51s (remain 22m 29s) Loss: 1.0737 Grad: 21.0401 LR: 0.000882 \n",
            "Epoch: [1][3700/5994] Elapsed 34m 47s (remain 21m 33s) Loss: 1.0649 Grad: 5.0832 LR: 0.000873 \n",
            "Epoch: [1][3800/5994] Elapsed 35m 43s (remain 20m 36s) Loss: 1.0623 Grad: 2.4451 LR: 0.000863 \n",
            "Epoch: [1][3900/5994] Elapsed 36m 40s (remain 19m 40s) Loss: 1.0609 Grad: 8.0522 LR: 0.000853 \n",
            "Epoch: [1][4000/5994] Elapsed 37m 36s (remain 18m 43s) Loss: 1.0545 Grad: 11.1225 LR: 0.000842 \n",
            "Epoch: [1][4100/5994] Elapsed 38m 32s (remain 17m 47s) Loss: 1.0489 Grad: 2.1033 LR: 0.000831 \n",
            "Epoch: [1][4200/5994] Elapsed 39m 28s (remain 16m 51s) Loss: 1.0437 Grad: 5.5915 LR: 0.000820 \n",
            "Epoch: [1][4300/5994] Elapsed 40m 25s (remain 15m 54s) Loss: 1.0406 Grad: 9.8125 LR: 0.000809 \n",
            "Epoch: [1][4400/5994] Elapsed 41m 21s (remain 14m 58s) Loss: 1.0352 Grad: 9.5209 LR: 0.000797 \n",
            "Epoch: [1][4500/5994] Elapsed 42m 17s (remain 14m 1s) Loss: 1.0311 Grad: 5.7673 LR: 0.000786 \n",
            "Epoch: [1][4600/5994] Elapsed 43m 14s (remain 13m 5s) Loss: 1.0230 Grad: 13.0695 LR: 0.000774 \n",
            "Epoch: [1][4700/5994] Elapsed 44m 10s (remain 12m 9s) Loss: 1.0192 Grad: 13.4576 LR: 0.000761 \n",
            "Epoch: [1][4800/5994] Elapsed 45m 6s (remain 11m 12s) Loss: 1.0171 Grad: 5.9051 LR: 0.000749 \n",
            "Epoch: [1][4900/5994] Elapsed 46m 3s (remain 10m 16s) Loss: 1.0140 Grad: 1.3463 LR: 0.000736 \n",
            "Epoch: [1][5000/5994] Elapsed 46m 59s (remain 9m 19s) Loss: 1.0095 Grad: 3.7117 LR: 0.000723 \n",
            "Epoch: [1][5100/5994] Elapsed 47m 55s (remain 8m 23s) Loss: 1.0035 Grad: 0.0994 LR: 0.000710 \n",
            "Epoch: [1][5200/5994] Elapsed 48m 52s (remain 7m 27s) Loss: 0.9990 Grad: 0.5120 LR: 0.000697 \n",
            "Epoch: [1][5300/5994] Elapsed 49m 48s (remain 6m 30s) Loss: 0.9955 Grad: 2.4676 LR: 0.000683 \n",
            "Epoch: [1][5400/5994] Elapsed 50m 44s (remain 5m 34s) Loss: 0.9924 Grad: 17.4710 LR: 0.000670 \n",
            "Epoch: [1][5500/5994] Elapsed 51m 41s (remain 4m 37s) Loss: 0.9884 Grad: 3.1290 LR: 0.000656 \n",
            "Epoch: [1][5600/5994] Elapsed 52m 37s (remain 3m 41s) Loss: 0.9850 Grad: 5.6002 LR: 0.000642 \n",
            "Epoch: [1][5700/5994] Elapsed 53m 33s (remain 2m 45s) Loss: 0.9802 Grad: 21.0625 LR: 0.000628 \n",
            "Epoch: [1][5800/5994] Elapsed 54m 30s (remain 1m 48s) Loss: 0.9761 Grad: 13.3291 LR: 0.000614 \n",
            "Epoch: [1][5900/5994] Elapsed 55m 26s (remain 0m 52s) Loss: 0.9739 Grad: 11.1488 LR: 0.000599 \n",
            "Epoch: [1][5993/5994] Elapsed 56m 16s (remain 0m 0s) Loss: 0.9699 Grad: 30.9296 LR: 0.000587 \n",
            "EVAL: [0/726] Elapsed 0m 0s (remain 8m 39s) Loss: 1.0357 \n",
            "EVAL: [100/726] Elapsed 0m 17s (remain 1m 50s) Loss: 0.3575 \n",
            "EVAL: [200/726] Elapsed 0m 35s (remain 1m 31s) Loss: 0.3801 \n",
            "EVAL: [300/726] Elapsed 0m 52s (remain 1m 13s) Loss: 0.3414 \n",
            "EVAL: [400/726] Elapsed 1m 9s (remain 0m 56s) Loss: 0.3160 \n",
            "EVAL: [500/726] Elapsed 1m 26s (remain 0m 38s) Loss: 0.2868 \n",
            "EVAL: [600/726] Elapsed 1m 43s (remain 0m 21s) Loss: 0.2748 \n",
            "EVAL: [700/726] Elapsed 2m 0s (remain 0m 4s) Loss: 0.2707 \n",
            "EVAL: [725/726] Elapsed 2m 5s (remain 0m 0s) Loss: 0.2636 \n",
            "Post-processing 223 example predictions split into 2902 features.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Score: 0.6708842104582015, Train Loss: 0.9699, Val Loss: 0.2636, Time: 3503s\n",
            "Epoch 1 - Save Best Model. score: 0.6709, loss: 0.2636\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [2][0/5994] Elapsed 0m 1s (remain 110m 57s) Loss: 1.2546 Grad: 23.1360 LR: 0.000587 \n",
            "Epoch: [2][100/5994] Elapsed 0m 57s (remain 55m 55s) Loss: 0.4428 Grad: 7.2264 LR: 0.000572 \n",
            "Epoch: [2][200/5994] Elapsed 1m 53s (remain 54m 40s) Loss: 0.4114 Grad: 19.9477 LR: 0.000558 \n",
            "Epoch: [2][300/5994] Elapsed 2m 50s (remain 53m 38s) Loss: 0.3972 Grad: 2.3002 LR: 0.000543 \n",
            "Epoch: [2][400/5994] Elapsed 3m 46s (remain 52m 39s) Loss: 0.3920 Grad: 2.7826 LR: 0.000529 \n",
            "Epoch: [2][500/5994] Elapsed 4m 42s (remain 51m 41s) Loss: 0.4160 Grad: 11.3077 LR: 0.000514 \n",
            "Epoch: [2][600/5994] Elapsed 5m 39s (remain 50m 43s) Loss: 0.4009 Grad: 4.3244 LR: 0.000500 \n",
            "Epoch: [2][700/5994] Elapsed 6m 35s (remain 49m 46s) Loss: 0.4108 Grad: 5.2237 LR: 0.000485 \n",
            "Epoch: [2][800/5994] Elapsed 7m 31s (remain 48m 49s) Loss: 0.4117 Grad: 12.0385 LR: 0.000471 \n",
            "Epoch: [2][900/5994] Elapsed 8m 28s (remain 47m 52s) Loss: 0.4115 Grad: 0.1219 LR: 0.000456 \n",
            "Epoch: [2][1000/5994] Elapsed 9m 24s (remain 46m 56s) Loss: 0.4089 Grad: 10.6403 LR: 0.000442 \n",
            "Epoch: [2][1100/5994] Elapsed 10m 20s (remain 45m 59s) Loss: 0.4093 Grad: 7.6126 LR: 0.000427 \n",
            "Epoch: [2][1200/5994] Elapsed 11m 17s (remain 45m 2s) Loss: 0.4091 Grad: 4.7049 LR: 0.000413 \n",
            "Epoch: [2][1300/5994] Elapsed 12m 13s (remain 44m 5s) Loss: 0.4149 Grad: 0.4171 LR: 0.000398 \n",
            "Epoch: [2][1400/5994] Elapsed 13m 9s (remain 43m 9s) Loss: 0.4191 Grad: 10.8357 LR: 0.000384 \n",
            "Epoch: [2][1500/5994] Elapsed 14m 6s (remain 42m 12s) Loss: 0.4190 Grad: 35.3636 LR: 0.000370 \n",
            "Epoch: [2][1600/5994] Elapsed 15m 2s (remain 41m 16s) Loss: 0.4236 Grad: 12.9229 LR: 0.000356 \n",
            "Epoch: [2][1700/5994] Elapsed 15m 58s (remain 40m 19s) Loss: 0.4240 Grad: 8.8178 LR: 0.000342 \n",
            "Epoch: [2][1800/5994] Elapsed 16m 55s (remain 39m 23s) Loss: 0.4241 Grad: 0.2940 LR: 0.000328 \n",
            "Epoch: [2][1900/5994] Elapsed 17m 51s (remain 38m 26s) Loss: 0.4289 Grad: 3.4990 LR: 0.000315 \n",
            "Epoch: [2][2000/5994] Elapsed 18m 47s (remain 37m 30s) Loss: 0.4239 Grad: 0.2750 LR: 0.000301 \n",
            "Epoch: [2][2100/5994] Elapsed 19m 44s (remain 36m 34s) Loss: 0.4263 Grad: 15.2885 LR: 0.000288 \n",
            "Epoch: [2][2200/5994] Elapsed 20m 40s (remain 35m 37s) Loss: 0.4230 Grad: 3.4388 LR: 0.000275 \n",
            "Epoch: [2][2300/5994] Elapsed 21m 36s (remain 34m 41s) Loss: 0.4220 Grad: 9.4607 LR: 0.000262 \n",
            "Epoch: [2][2400/5994] Elapsed 22m 33s (remain 33m 44s) Loss: 0.4223 Grad: 4.7627 LR: 0.000249 \n",
            "Epoch: [2][2500/5994] Elapsed 23m 29s (remain 32m 48s) Loss: 0.4202 Grad: 2.2822 LR: 0.000237 \n",
            "Epoch: [2][2600/5994] Elapsed 24m 25s (remain 31m 52s) Loss: 0.4191 Grad: 7.1010 LR: 0.000225 \n",
            "Epoch: [2][2700/5994] Elapsed 25m 22s (remain 30m 55s) Loss: 0.4175 Grad: 2.7291 LR: 0.000213 \n",
            "Epoch: [2][2800/5994] Elapsed 26m 18s (remain 29m 59s) Loss: 0.4176 Grad: 1.9995 LR: 0.000201 \n",
            "Epoch: [2][2900/5994] Elapsed 27m 14s (remain 29m 2s) Loss: 0.4147 Grad: 17.0082 LR: 0.000189 \n",
            "Epoch: [2][3000/5994] Elapsed 28m 10s (remain 28m 6s) Loss: 0.4121 Grad: 11.7414 LR: 0.000178 \n",
            "Epoch: [2][3100/5994] Elapsed 29m 7s (remain 27m 10s) Loss: 0.4132 Grad: 6.1479 LR: 0.000167 \n",
            "Epoch: [2][3200/5994] Elapsed 30m 3s (remain 26m 13s) Loss: 0.4123 Grad: 0.2480 LR: 0.000156 \n",
            "Epoch: [2][3300/5994] Elapsed 30m 59s (remain 25m 17s) Loss: 0.4102 Grad: 1.8416 LR: 0.000146 \n",
            "Epoch: [2][3400/5994] Elapsed 31m 56s (remain 24m 21s) Loss: 0.4083 Grad: 6.0807 LR: 0.000136 \n",
            "Epoch: [2][3500/5994] Elapsed 32m 52s (remain 23m 24s) Loss: 0.4081 Grad: 3.6007 LR: 0.000126 \n",
            "Epoch: [2][3600/5994] Elapsed 33m 48s (remain 22m 28s) Loss: 0.4067 Grad: 0.5296 LR: 0.000116 \n",
            "Epoch: [2][3700/5994] Elapsed 34m 45s (remain 21m 31s) Loss: 0.4053 Grad: 0.1064 LR: 0.000107 \n",
            "Epoch: [2][3800/5994] Elapsed 35m 41s (remain 20m 35s) Loss: 0.4056 Grad: 4.0484 LR: 0.000098 \n",
            "Epoch: [2][3900/5994] Elapsed 36m 37s (remain 19m 39s) Loss: 0.4050 Grad: 29.7103 LR: 0.000090 \n",
            "Epoch: [2][4000/5994] Elapsed 37m 34s (remain 18m 42s) Loss: 0.4044 Grad: 3.3756 LR: 0.000082 \n",
            "Epoch: [2][4100/5994] Elapsed 38m 30s (remain 17m 46s) Loss: 0.4045 Grad: 0.7116 LR: 0.000074 \n",
            "Epoch: [2][4200/5994] Elapsed 39m 26s (remain 16m 50s) Loss: 0.4055 Grad: 3.2858 LR: 0.000066 \n",
            "Epoch: [2][4300/5994] Elapsed 40m 23s (remain 15m 53s) Loss: 0.4042 Grad: 6.7339 LR: 0.000059 \n",
            "Epoch: [2][4400/5994] Elapsed 41m 19s (remain 14m 57s) Loss: 0.4021 Grad: 0.8518 LR: 0.000053 \n",
            "Epoch: [2][4500/5994] Elapsed 42m 15s (remain 14m 1s) Loss: 0.4021 Grad: 5.3226 LR: 0.000046 \n",
            "Epoch: [2][4600/5994] Elapsed 43m 12s (remain 13m 4s) Loss: 0.4027 Grad: 2.3985 LR: 0.000040 \n",
            "Epoch: [2][4700/5994] Elapsed 44m 8s (remain 12m 8s) Loss: 0.4032 Grad: 0.0014 LR: 0.000035 \n",
            "Epoch: [2][4800/5994] Elapsed 45m 4s (remain 11m 12s) Loss: 0.4031 Grad: 0.1537 LR: 0.000030 \n",
            "Epoch: [2][4900/5994] Elapsed 46m 1s (remain 10m 15s) Loss: 0.4014 Grad: 4.0167 LR: 0.000025 \n",
            "Epoch: [2][5000/5994] Elapsed 46m 57s (remain 9m 19s) Loss: 0.3989 Grad: 4.8247 LR: 0.000021 \n",
            "Epoch: [2][5100/5994] Elapsed 47m 53s (remain 8m 23s) Loss: 0.3987 Grad: 4.1176 LR: 0.000017 \n",
            "Epoch: [2][5200/5994] Elapsed 48m 50s (remain 7m 26s) Loss: 0.3967 Grad: 0.0620 LR: 0.000013 \n",
            "Epoch: [2][5300/5994] Elapsed 49m 46s (remain 6m 30s) Loss: 0.3958 Grad: 4.1808 LR: 0.000010 \n",
            "Epoch: [2][5400/5994] Elapsed 50m 42s (remain 5m 34s) Loss: 0.3970 Grad: 16.0926 LR: 0.000007 \n",
            "Epoch: [2][5500/5994] Elapsed 51m 39s (remain 4m 37s) Loss: 0.3955 Grad: 1.2861 LR: 0.000005 \n",
            "Epoch: [2][5600/5994] Elapsed 52m 35s (remain 3m 41s) Loss: 0.3953 Grad: 5.5180 LR: 0.000003 \n",
            "Epoch: [2][5700/5994] Elapsed 53m 31s (remain 2m 45s) Loss: 0.3957 Grad: 15.3147 LR: 0.000002 \n",
            "Epoch: [2][5800/5994] Elapsed 54m 28s (remain 1m 48s) Loss: 0.3953 Grad: 4.1238 LR: 0.000001 \n",
            "Epoch: [2][5900/5994] Elapsed 55m 24s (remain 0m 52s) Loss: 0.3955 Grad: 11.4534 LR: 0.000000 \n",
            "Epoch: [2][5993/5994] Elapsed 56m 16s (remain 0m 0s) Loss: 0.3950 Grad: 18.8222 LR: 0.000000 \n",
            "EVAL: [0/726] Elapsed 0m 0s (remain 8m 36s) Loss: 0.6241 \n",
            "EVAL: [100/726] Elapsed 0m 17s (remain 1m 50s) Loss: 0.2839 \n",
            "EVAL: [200/726] Elapsed 0m 35s (remain 1m 31s) Loss: 0.3270 \n",
            "EVAL: [300/726] Elapsed 0m 52s (remain 1m 13s) Loss: 0.2870 \n",
            "EVAL: [400/726] Elapsed 1m 9s (remain 0m 56s) Loss: 0.2756 \n",
            "EVAL: [500/726] Elapsed 1m 26s (remain 0m 38s) Loss: 0.2516 \n",
            "EVAL: [600/726] Elapsed 1m 43s (remain 0m 21s) Loss: 0.2452 \n",
            "EVAL: [700/726] Elapsed 2m 0s (remain 0m 4s) Loss: 0.2367 \n",
            "EVAL: [725/726] Elapsed 2m 5s (remain 0m 0s) Loss: 0.2315 \n",
            "Post-processing 223 example predictions split into 2902 features.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2 - Score: 0.6966207559256886, Train Loss: 0.3950, Val Loss: 0.2315, Time: 3503s\n",
            "Epoch 2 - Save Best Model. score: 0.6966, loss: 0.2315\n",
            "========== fold: 1 result ==========\n",
            "Score: 0.68317\n",
            "========== fold: 2 training ==========\n",
            "Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'qa_outputs.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [1][0/5972] Elapsed 0m 1s (remain 106m 55s) Loss: 5.9979 Grad: 5.7336 LR: 0.000000 \n",
            "Epoch: [1][100/5972] Elapsed 0m 57s (remain 55m 35s) Loss: 5.4739 Grad: 9.9391 LR: 0.000084 \n",
            "Epoch: [1][200/5972] Elapsed 1m 53s (remain 54m 24s) Loss: 3.8280 Grad: 53.0769 LR: 0.000168 \n",
            "Epoch: [1][300/5972] Elapsed 2m 50s (remain 53m 24s) Loss: 2.9118 Grad: 8.8831 LR: 0.000252 \n",
            "Epoch: [1][400/5972] Elapsed 3m 46s (remain 52m 25s) Loss: 2.4090 Grad: 25.1558 LR: 0.000336 \n",
            "Epoch: [1][500/5972] Elapsed 4m 42s (remain 51m 27s) Loss: 2.1224 Grad: 11.7358 LR: 0.000420 \n",
            "Epoch: [1][600/5972] Elapsed 5m 39s (remain 50m 29s) Loss: 1.9260 Grad: 7.2404 LR: 0.000504 \n",
            "Epoch: [1][700/5972] Elapsed 6m 35s (remain 49m 32s) Loss: 1.7790 Grad: 4.4760 LR: 0.000588 \n",
            "Epoch: [1][800/5972] Elapsed 7m 31s (remain 48m 35s) Loss: 1.6771 Grad: 10.9745 LR: 0.000672 \n",
            "Epoch: [1][900/5972] Elapsed 8m 27s (remain 47m 38s) Loss: 1.5980 Grad: 7.6794 LR: 0.000756 \n",
            "Epoch: [1][1000/5972] Elapsed 9m 24s (remain 46m 42s) Loss: 1.5382 Grad: 18.0901 LR: 0.000840 \n",
            "Epoch: [1][1100/5972] Elapsed 10m 20s (remain 45m 45s) Loss: 1.4840 Grad: 18.8722 LR: 0.000924 \n",
            "Epoch: [1][1200/5972] Elapsed 11m 16s (remain 44m 49s) Loss: 1.4406 Grad: 4.3558 LR: 0.001000 \n",
            "Epoch: [1][1300/5972] Elapsed 12m 13s (remain 43m 52s) Loss: 1.4105 Grad: 6.2777 LR: 0.001000 \n",
            "Epoch: [1][1400/5972] Elapsed 13m 9s (remain 42m 56s) Loss: 1.3748 Grad: 12.3694 LR: 0.000999 \n",
            "Epoch: [1][1500/5972] Elapsed 14m 5s (remain 41m 59s) Loss: 1.3372 Grad: 0.7888 LR: 0.000998 \n",
            "Epoch: [1][1600/5972] Elapsed 15m 2s (remain 41m 3s) Loss: 1.3035 Grad: 5.6139 LR: 0.000996 \n",
            "Epoch: [1][1700/5972] Elapsed 15m 58s (remain 40m 6s) Loss: 1.2863 Grad: 8.7589 LR: 0.000994 \n",
            "Epoch: [1][1800/5972] Elapsed 16m 54s (remain 39m 10s) Loss: 1.2718 Grad: 1.1339 LR: 0.000992 \n",
            "Epoch: [1][1900/5972] Elapsed 17m 51s (remain 38m 13s) Loss: 1.2575 Grad: 7.9491 LR: 0.000989 \n",
            "Epoch: [1][2000/5972] Elapsed 18m 47s (remain 37m 17s) Loss: 1.2396 Grad: 10.3461 LR: 0.000986 \n",
            "Epoch: [1][2100/5972] Elapsed 19m 43s (remain 36m 21s) Loss: 1.2207 Grad: 5.8059 LR: 0.000982 \n",
            "Epoch: [1][2200/5972] Elapsed 20m 40s (remain 35m 24s) Loss: 1.2085 Grad: 16.6987 LR: 0.000978 \n",
            "Epoch: [1][2300/5972] Elapsed 21m 36s (remain 34m 28s) Loss: 1.1992 Grad: 15.1346 LR: 0.000974 \n",
            "Epoch: [1][2400/5972] Elapsed 22m 32s (remain 33m 32s) Loss: 1.1805 Grad: 4.5858 LR: 0.000969 \n",
            "Epoch: [1][2500/5972] Elapsed 23m 29s (remain 32m 35s) Loss: 1.1717 Grad: 0.6471 LR: 0.000964 \n",
            "Epoch: [1][2600/5972] Elapsed 24m 25s (remain 31m 39s) Loss: 1.1593 Grad: 19.1441 LR: 0.000958 \n",
            "Epoch: [1][2700/5972] Elapsed 25m 21s (remain 30m 43s) Loss: 1.1506 Grad: 14.5354 LR: 0.000952 \n",
            "Epoch: [1][2800/5972] Elapsed 26m 18s (remain 29m 46s) Loss: 1.1412 Grad: 11.2132 LR: 0.000946 \n",
            "Epoch: [1][2900/5972] Elapsed 27m 14s (remain 28m 50s) Loss: 1.1352 Grad: 5.7212 LR: 0.000939 \n",
            "Epoch: [1][3000/5972] Elapsed 28m 10s (remain 27m 53s) Loss: 1.1340 Grad: 10.1976 LR: 0.000932 \n",
            "Epoch: [1][3100/5972] Elapsed 29m 7s (remain 26m 57s) Loss: 1.1242 Grad: 23.5892 LR: 0.000924 \n",
            "Epoch: [1][3200/5972] Elapsed 30m 3s (remain 26m 1s) Loss: 1.1162 Grad: 31.5622 LR: 0.000916 \n",
            "Epoch: [1][3300/5972] Elapsed 30m 59s (remain 25m 4s) Loss: 1.1106 Grad: 13.0824 LR: 0.000908 \n",
            "Epoch: [1][3400/5972] Elapsed 31m 56s (remain 24m 8s) Loss: 1.1051 Grad: 9.6400 LR: 0.000899 \n",
            "Epoch: [1][3500/5972] Elapsed 32m 52s (remain 23m 12s) Loss: 1.0962 Grad: 3.1366 LR: 0.000890 \n",
            "Epoch: [1][3600/5972] Elapsed 33m 48s (remain 22m 15s) Loss: 1.0879 Grad: 9.9089 LR: 0.000881 \n",
            "Epoch: [1][3700/5972] Elapsed 34m 45s (remain 21m 19s) Loss: 1.0803 Grad: 2.1021 LR: 0.000871 \n",
            "Epoch: [1][3800/5972] Elapsed 35m 41s (remain 20m 23s) Loss: 1.0770 Grad: 6.6744 LR: 0.000861 \n",
            "Epoch: [1][3900/5972] Elapsed 36m 37s (remain 19m 26s) Loss: 1.0695 Grad: 5.5917 LR: 0.000851 \n",
            "Epoch: [1][4000/5972] Elapsed 37m 34s (remain 18m 30s) Loss: 1.0632 Grad: 12.1031 LR: 0.000841 \n",
            "Epoch: [1][4100/5972] Elapsed 38m 30s (remain 17m 34s) Loss: 1.0564 Grad: 5.2634 LR: 0.000830 \n",
            "Epoch: [1][4200/5972] Elapsed 39m 26s (remain 16m 37s) Loss: 1.0488 Grad: 1.1339 LR: 0.000819 \n",
            "Epoch: [1][4300/5972] Elapsed 40m 23s (remain 15m 41s) Loss: 1.0442 Grad: 6.5412 LR: 0.000807 \n",
            "Epoch: [1][4400/5972] Elapsed 41m 19s (remain 14m 45s) Loss: 1.0399 Grad: 7.6764 LR: 0.000796 \n",
            "Epoch: [1][4500/5972] Elapsed 42m 15s (remain 13m 48s) Loss: 1.0340 Grad: 3.7142 LR: 0.000784 \n",
            "Epoch: [1][4600/5972] Elapsed 43m 12s (remain 12m 52s) Loss: 1.0299 Grad: 5.2928 LR: 0.000772 \n",
            "Epoch: [1][4700/5972] Elapsed 44m 8s (remain 11m 56s) Loss: 1.0245 Grad: 9.6031 LR: 0.000759 \n",
            "Epoch: [1][4800/5972] Elapsed 45m 4s (remain 10m 59s) Loss: 1.0214 Grad: 3.3180 LR: 0.000747 \n",
            "Epoch: [1][4900/5972] Elapsed 46m 1s (remain 10m 3s) Loss: 1.0172 Grad: 12.2953 LR: 0.000734 \n",
            "Epoch: [1][5000/5972] Elapsed 46m 57s (remain 9m 7s) Loss: 1.0129 Grad: 1.1882 LR: 0.000721 \n",
            "Epoch: [1][5100/5972] Elapsed 47m 53s (remain 8m 10s) Loss: 1.0090 Grad: 11.8108 LR: 0.000708 \n",
            "Epoch: [1][5200/5972] Elapsed 48m 50s (remain 7m 14s) Loss: 1.0055 Grad: 10.2167 LR: 0.000694 \n",
            "Epoch: [1][5300/5972] Elapsed 49m 46s (remain 6m 18s) Loss: 1.0019 Grad: 1.7087 LR: 0.000681 \n",
            "Epoch: [1][5400/5972] Elapsed 50m 42s (remain 5m 21s) Loss: 0.9969 Grad: 12.7620 LR: 0.000667 \n",
            "Epoch: [1][5500/5972] Elapsed 51m 39s (remain 4m 25s) Loss: 0.9951 Grad: 3.8869 LR: 0.000653 \n",
            "Epoch: [1][5600/5972] Elapsed 52m 35s (remain 3m 29s) Loss: 0.9936 Grad: 6.7193 LR: 0.000639 \n",
            "Epoch: [1][5700/5972] Elapsed 53m 32s (remain 2m 32s) Loss: 0.9876 Grad: 4.9478 LR: 0.000625 \n",
            "Epoch: [1][5800/5972] Elapsed 54m 28s (remain 1m 36s) Loss: 0.9818 Grad: 5.7294 LR: 0.000611 \n",
            "Epoch: [1][5900/5972] Elapsed 55m 24s (remain 0m 40s) Loss: 0.9790 Grad: 2.9658 LR: 0.000597 \n",
            "Epoch: [1][5971/5972] Elapsed 56m 3s (remain 0m 0s) Loss: 0.9780 Grad: 7.7869 LR: 0.000587 \n",
            "EVAL: [0/748] Elapsed 0m 0s (remain 8m 44s) Loss: 0.2360 \n",
            "EVAL: [100/748] Elapsed 0m 17s (remain 1m 54s) Loss: 0.3786 \n",
            "EVAL: [200/748] Elapsed 0m 35s (remain 1m 35s) Loss: 0.3382 \n",
            "EVAL: [300/748] Elapsed 0m 52s (remain 1m 17s) Loss: 0.3320 \n",
            "EVAL: [400/748] Elapsed 1m 9s (remain 1m 0s) Loss: 0.2975 \n",
            "EVAL: [500/748] Elapsed 1m 26s (remain 0m 42s) Loss: 0.2816 \n",
            "EVAL: [600/748] Elapsed 1m 43s (remain 0m 25s) Loss: 0.2835 \n",
            "EVAL: [700/748] Elapsed 2m 0s (remain 0m 8s) Loss: 0.2771 \n",
            "EVAL: [747/748] Elapsed 2m 8s (remain 0m 0s) Loss: 0.2686 \n",
            "Post-processing 223 example predictions split into 2990 features.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Score: 0.6697406479917691, Train Loss: 0.9780, Val Loss: 0.2686, Time: 3494s\n",
            "Epoch 1 - Save Best Model. score: 0.6697, loss: 0.2686\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [2][0/5972] Elapsed 0m 1s (remain 111m 13s) Loss: 1.4541 Grad: 19.0692 LR: 0.000587 \n",
            "Epoch: [2][100/5972] Elapsed 0m 57s (remain 55m 43s) Loss: 0.5617 Grad: 10.4175 LR: 0.000572 \n",
            "Epoch: [2][200/5972] Elapsed 1m 53s (remain 54m 30s) Loss: 0.5204 Grad: 12.2167 LR: 0.000558 \n",
            "Epoch: [2][300/5972] Elapsed 2m 50s (remain 53m 27s) Loss: 0.5319 Grad: 5.8586 LR: 0.000543 \n",
            "Epoch: [2][400/5972] Elapsed 3m 46s (remain 52m 28s) Loss: 0.4930 Grad: 24.1237 LR: 0.000528 \n",
            "Epoch: [2][500/5972] Elapsed 4m 42s (remain 51m 29s) Loss: 0.4762 Grad: 0.8045 LR: 0.000514 \n",
            "Epoch: [2][600/5972] Elapsed 5m 39s (remain 50m 32s) Loss: 0.4697 Grad: 4.8774 LR: 0.000499 \n",
            "Epoch: [2][700/5972] Elapsed 6m 35s (remain 49m 34s) Loss: 0.4592 Grad: 15.9419 LR: 0.000485 \n",
            "Epoch: [2][800/5972] Elapsed 7m 32s (remain 48m 38s) Loss: 0.4401 Grad: 6.0088 LR: 0.000470 \n",
            "Epoch: [2][900/5972] Elapsed 8m 28s (remain 47m 41s) Loss: 0.4328 Grad: 0.0740 LR: 0.000455 \n",
            "Epoch: [2][1000/5972] Elapsed 9m 24s (remain 46m 44s) Loss: 0.4319 Grad: 3.2159 LR: 0.000441 \n",
            "Epoch: [2][1100/5972] Elapsed 10m 21s (remain 45m 47s) Loss: 0.4297 Grad: 16.0793 LR: 0.000426 \n",
            "Epoch: [2][1200/5972] Elapsed 11m 17s (remain 44m 51s) Loss: 0.4253 Grad: 0.9696 LR: 0.000412 \n",
            "Epoch: [2][1300/5972] Elapsed 12m 13s (remain 43m 54s) Loss: 0.4292 Grad: 43.0627 LR: 0.000398 \n",
            "Epoch: [2][1400/5972] Elapsed 13m 10s (remain 42m 57s) Loss: 0.4278 Grad: 24.3434 LR: 0.000383 \n",
            "Epoch: [2][1500/5972] Elapsed 14m 6s (remain 42m 1s) Loss: 0.4287 Grad: 2.4919 LR: 0.000369 \n",
            "Epoch: [2][1600/5972] Elapsed 15m 2s (remain 41m 4s) Loss: 0.4252 Grad: 0.0309 LR: 0.000355 \n",
            "Epoch: [2][1700/5972] Elapsed 15m 59s (remain 40m 8s) Loss: 0.4275 Grad: 13.6853 LR: 0.000341 \n",
            "Epoch: [2][1800/5972] Elapsed 16m 55s (remain 39m 11s) Loss: 0.4245 Grad: 1.6985 LR: 0.000328 \n",
            "Epoch: [2][1900/5972] Elapsed 17m 51s (remain 38m 15s) Loss: 0.4224 Grad: 3.0950 LR: 0.000314 \n",
            "Epoch: [2][2000/5972] Elapsed 18m 48s (remain 37m 18s) Loss: 0.4222 Grad: 2.3259 LR: 0.000300 \n",
            "Epoch: [2][2100/5972] Elapsed 19m 44s (remain 36m 22s) Loss: 0.4232 Grad: 0.3738 LR: 0.000287 \n",
            "Epoch: [2][2200/5972] Elapsed 20m 40s (remain 35m 26s) Loss: 0.4241 Grad: 4.7579 LR: 0.000274 \n",
            "Epoch: [2][2300/5972] Elapsed 21m 37s (remain 34m 29s) Loss: 0.4251 Grad: 1.2464 LR: 0.000261 \n",
            "Epoch: [2][2400/5972] Elapsed 22m 33s (remain 33m 33s) Loss: 0.4229 Grad: 4.1386 LR: 0.000248 \n",
            "Epoch: [2][2500/5972] Elapsed 23m 29s (remain 32m 36s) Loss: 0.4229 Grad: 1.0905 LR: 0.000236 \n",
            "Epoch: [2][2600/5972] Elapsed 24m 26s (remain 31m 40s) Loss: 0.4208 Grad: 1.1717 LR: 0.000224 \n",
            "Epoch: [2][2700/5972] Elapsed 25m 22s (remain 30m 43s) Loss: 0.4164 Grad: 6.5218 LR: 0.000211 \n",
            "Epoch: [2][2800/5972] Elapsed 26m 18s (remain 29m 47s) Loss: 0.4168 Grad: 4.4408 LR: 0.000200 \n",
            "Epoch: [2][2900/5972] Elapsed 27m 15s (remain 28m 51s) Loss: 0.4136 Grad: 0.0870 LR: 0.000188 \n",
            "Epoch: [2][3000/5972] Elapsed 28m 11s (remain 27m 54s) Loss: 0.4140 Grad: 15.0900 LR: 0.000177 \n",
            "Epoch: [2][3100/5972] Elapsed 29m 8s (remain 26m 58s) Loss: 0.4142 Grad: 3.4169 LR: 0.000166 \n",
            "Epoch: [2][3200/5972] Elapsed 30m 4s (remain 26m 1s) Loss: 0.4134 Grad: 5.6162 LR: 0.000155 \n",
            "Epoch: [2][3300/5972] Elapsed 31m 0s (remain 25m 5s) Loss: 0.4113 Grad: 0.5566 LR: 0.000145 \n",
            "Epoch: [2][3400/5972] Elapsed 31m 57s (remain 24m 9s) Loss: 0.4108 Grad: 1.5247 LR: 0.000135 \n",
            "Epoch: [2][3500/5972] Elapsed 32m 53s (remain 23m 12s) Loss: 0.4111 Grad: 9.7841 LR: 0.000125 \n",
            "Epoch: [2][3600/5972] Elapsed 33m 49s (remain 22m 16s) Loss: 0.4096 Grad: 5.3290 LR: 0.000115 \n",
            "Epoch: [2][3700/5972] Elapsed 34m 46s (remain 21m 20s) Loss: 0.4096 Grad: 7.6980 LR: 0.000106 \n",
            "Epoch: [2][3800/5972] Elapsed 35m 42s (remain 20m 23s) Loss: 0.4079 Grad: 1.0704 LR: 0.000097 \n",
            "Epoch: [2][3900/5972] Elapsed 36m 38s (remain 19m 27s) Loss: 0.4081 Grad: 21.5891 LR: 0.000089 \n",
            "Epoch: [2][4000/5972] Elapsed 37m 35s (remain 18m 30s) Loss: 0.4064 Grad: 4.7620 LR: 0.000081 \n",
            "Epoch: [2][4100/5972] Elapsed 38m 31s (remain 17m 34s) Loss: 0.4049 Grad: 10.4577 LR: 0.000073 \n",
            "Epoch: [2][4200/5972] Elapsed 39m 27s (remain 16m 38s) Loss: 0.4026 Grad: 10.9619 LR: 0.000065 \n",
            "Epoch: [2][4300/5972] Elapsed 40m 24s (remain 15m 41s) Loss: 0.4020 Grad: 10.1977 LR: 0.000058 \n",
            "Epoch: [2][4400/5972] Elapsed 41m 20s (remain 14m 45s) Loss: 0.4020 Grad: 1.4834 LR: 0.000052 \n",
            "Epoch: [2][4500/5972] Elapsed 42m 16s (remain 13m 49s) Loss: 0.4025 Grad: 4.0754 LR: 0.000045 \n",
            "Epoch: [2][4600/5972] Elapsed 43m 13s (remain 12m 52s) Loss: 0.4028 Grad: 12.1528 LR: 0.000040 \n",
            "Epoch: [2][4700/5972] Elapsed 44m 9s (remain 11m 56s) Loss: 0.4014 Grad: 25.5299 LR: 0.000034 \n",
            "Epoch: [2][4800/5972] Elapsed 45m 5s (remain 10m 59s) Loss: 0.4009 Grad: 10.5894 LR: 0.000029 \n",
            "Epoch: [2][4900/5972] Elapsed 46m 2s (remain 10m 3s) Loss: 0.3989 Grad: 10.1021 LR: 0.000024 \n",
            "Epoch: [2][5000/5972] Elapsed 46m 58s (remain 9m 7s) Loss: 0.3979 Grad: 0.2240 LR: 0.000020 \n",
            "Epoch: [2][5100/5972] Elapsed 47m 54s (remain 8m 10s) Loss: 0.3986 Grad: 0.0068 LR: 0.000016 \n",
            "Epoch: [2][5200/5972] Elapsed 48m 51s (remain 7m 14s) Loss: 0.3974 Grad: 23.7771 LR: 0.000013 \n",
            "Epoch: [2][5300/5972] Elapsed 49m 47s (remain 6m 18s) Loss: 0.3960 Grad: 13.0442 LR: 0.000010 \n",
            "Epoch: [2][5400/5972] Elapsed 50m 44s (remain 5m 21s) Loss: 0.3956 Grad: 1.7821 LR: 0.000007 \n",
            "Epoch: [2][5500/5972] Elapsed 51m 40s (remain 4m 25s) Loss: 0.3954 Grad: 3.2474 LR: 0.000005 \n",
            "Epoch: [2][5600/5972] Elapsed 52m 36s (remain 3m 29s) Loss: 0.3940 Grad: 11.3549 LR: 0.000003 \n",
            "Epoch: [2][5700/5972] Elapsed 53m 33s (remain 2m 32s) Loss: 0.3935 Grad: 2.3090 LR: 0.000002 \n",
            "Epoch: [2][5800/5972] Elapsed 54m 29s (remain 1m 36s) Loss: 0.3928 Grad: 15.0594 LR: 0.000001 \n",
            "Epoch: [2][5900/5972] Elapsed 55m 25s (remain 0m 40s) Loss: 0.3927 Grad: 2.6358 LR: 0.000000 \n",
            "Epoch: [2][5971/5972] Elapsed 56m 6s (remain 0m 0s) Loss: 0.3929 Grad: 20.6570 LR: 0.000000 \n",
            "EVAL: [0/748] Elapsed 0m 0s (remain 8m 55s) Loss: 0.3809 \n",
            "EVAL: [100/748] Elapsed 0m 17s (remain 1m 54s) Loss: 0.4088 \n",
            "EVAL: [200/748] Elapsed 0m 35s (remain 1m 35s) Loss: 0.3743 \n",
            "EVAL: [300/748] Elapsed 0m 52s (remain 1m 17s) Loss: 0.3815 \n",
            "EVAL: [400/748] Elapsed 1m 9s (remain 1m 0s) Loss: 0.3282 \n",
            "EVAL: [500/748] Elapsed 1m 26s (remain 0m 42s) Loss: 0.3123 \n",
            "EVAL: [600/748] Elapsed 1m 43s (remain 0m 25s) Loss: 0.3171 \n",
            "EVAL: [700/748] Elapsed 2m 0s (remain 0m 8s) Loss: 0.3101 \n",
            "EVAL: [747/748] Elapsed 2m 8s (remain 0m 0s) Loss: 0.2969 \n",
            "Post-processing 223 example predictions split into 2990 features.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2 - Score: 0.6563660305812773, Train Loss: 0.3929, Val Loss: 0.2969, Time: 3497s\n",
            "========== fold: 2 result ==========\n",
            "Score: 0.66526\n",
            "========== fold: 3 training ==========\n",
            "Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'qa_outputs.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [1][0/5946] Elapsed 0m 1s (remain 108m 50s) Loss: 5.8417 Grad: 5.8675 LR: 0.000000 \n",
            "Epoch: [1][100/5946] Elapsed 0m 57s (remain 55m 21s) Loss: 5.2073 Grad: 7.3905 LR: 0.000084 \n",
            "Epoch: [1][200/5946] Elapsed 1m 53s (remain 54m 8s) Loss: 3.5949 Grad: 20.8723 LR: 0.000169 \n",
            "Epoch: [1][300/5946] Elapsed 2m 49s (remain 53m 8s) Loss: 2.7992 Grad: 24.6676 LR: 0.000253 \n",
            "Epoch: [1][400/5946] Elapsed 3m 46s (remain 52m 8s) Loss: 2.3266 Grad: 10.8494 LR: 0.000338 \n",
            "Epoch: [1][500/5946] Elapsed 4m 42s (remain 51m 11s) Loss: 2.0523 Grad: 8.7037 LR: 0.000422 \n",
            "Epoch: [1][600/5946] Elapsed 5m 38s (remain 50m 14s) Loss: 1.8481 Grad: 9.4350 LR: 0.000506 \n",
            "Epoch: [1][700/5946] Elapsed 6m 35s (remain 49m 17s) Loss: 1.7097 Grad: 16.8645 LR: 0.000591 \n",
            "Epoch: [1][800/5946] Elapsed 7m 31s (remain 48m 20s) Loss: 1.6209 Grad: 13.8569 LR: 0.000675 \n",
            "Epoch: [1][900/5946] Elapsed 8m 27s (remain 47m 23s) Loss: 1.5381 Grad: 1.8848 LR: 0.000759 \n",
            "Epoch: [1][1000/5946] Elapsed 9m 24s (remain 46m 27s) Loss: 1.4831 Grad: 14.6966 LR: 0.000844 \n",
            "Epoch: [1][1100/5946] Elapsed 10m 20s (remain 45m 30s) Loss: 1.4327 Grad: 30.5720 LR: 0.000928 \n",
            "Epoch: [1][1200/5946] Elapsed 11m 16s (remain 44m 34s) Loss: 1.3829 Grad: 11.0457 LR: 0.001000 \n",
            "Epoch: [1][1300/5946] Elapsed 12m 13s (remain 43m 37s) Loss: 1.3516 Grad: 16.1343 LR: 0.001000 \n",
            "Epoch: [1][1400/5946] Elapsed 13m 9s (remain 42m 41s) Loss: 1.3159 Grad: 26.1482 LR: 0.000999 \n",
            "Epoch: [1][1500/5946] Elapsed 14m 5s (remain 41m 45s) Loss: 1.2987 Grad: 4.2811 LR: 0.000998 \n",
            "Epoch: [1][1600/5946] Elapsed 15m 2s (remain 40m 48s) Loss: 1.2837 Grad: 3.3586 LR: 0.000996 \n",
            "Epoch: [1][1700/5946] Elapsed 15m 58s (remain 39m 52s) Loss: 1.2634 Grad: 15.2185 LR: 0.000994 \n",
            "Epoch: [1][1800/5946] Elapsed 16m 54s (remain 38m 55s) Loss: 1.2537 Grad: 6.5315 LR: 0.000992 \n",
            "Epoch: [1][1900/5946] Elapsed 17m 51s (remain 37m 59s) Loss: 1.2396 Grad: 0.6976 LR: 0.000989 \n",
            "Epoch: [1][2000/5946] Elapsed 18m 47s (remain 37m 3s) Loss: 1.2310 Grad: 5.4425 LR: 0.000986 \n",
            "Epoch: [1][2100/5946] Elapsed 19m 43s (remain 36m 6s) Loss: 1.2193 Grad: 11.6153 LR: 0.000982 \n",
            "Epoch: [1][2200/5946] Elapsed 20m 40s (remain 35m 10s) Loss: 1.2053 Grad: 8.1979 LR: 0.000978 \n",
            "Epoch: [1][2300/5946] Elapsed 21m 36s (remain 34m 14s) Loss: 1.1900 Grad: 6.3409 LR: 0.000973 \n",
            "Epoch: [1][2400/5946] Elapsed 22m 33s (remain 33m 17s) Loss: 1.1759 Grad: 0.7370 LR: 0.000969 \n",
            "Epoch: [1][2500/5946] Elapsed 23m 29s (remain 32m 21s) Loss: 1.1678 Grad: 11.2443 LR: 0.000963 \n",
            "Epoch: [1][2600/5946] Elapsed 24m 25s (remain 31m 25s) Loss: 1.1560 Grad: 64.2850 LR: 0.000958 \n",
            "Epoch: [1][2700/5946] Elapsed 25m 22s (remain 30m 28s) Loss: 1.1484 Grad: 3.0219 LR: 0.000951 \n",
            "Epoch: [1][2800/5946] Elapsed 26m 18s (remain 29m 32s) Loss: 1.1354 Grad: 28.7748 LR: 0.000945 \n",
            "Epoch: [1][2900/5946] Elapsed 27m 14s (remain 28m 35s) Loss: 1.1262 Grad: 14.8674 LR: 0.000938 \n",
            "Epoch: [1][3000/5946] Elapsed 28m 11s (remain 27m 39s) Loss: 1.1154 Grad: 15.4138 LR: 0.000931 \n",
            "Epoch: [1][3100/5946] Elapsed 29m 7s (remain 26m 43s) Loss: 1.1079 Grad: 16.7706 LR: 0.000923 \n",
            "Epoch: [1][3200/5946] Elapsed 30m 3s (remain 25m 46s) Loss: 1.0999 Grad: 7.5393 LR: 0.000915 \n",
            "Epoch: [1][3300/5946] Elapsed 31m 0s (remain 24m 50s) Loss: 1.0928 Grad: 4.8008 LR: 0.000907 \n",
            "Epoch: [1][3400/5946] Elapsed 31m 56s (remain 23m 54s) Loss: 1.0877 Grad: 9.5872 LR: 0.000898 \n",
            "Epoch: [1][3500/5946] Elapsed 32m 52s (remain 22m 57s) Loss: 1.0836 Grad: 7.2743 LR: 0.000889 \n",
            "Epoch: [1][3600/5946] Elapsed 33m 49s (remain 22m 1s) Loss: 1.0776 Grad: 10.2100 LR: 0.000880 \n",
            "Epoch: [1][3700/5946] Elapsed 34m 45s (remain 21m 5s) Loss: 1.0738 Grad: 6.0283 LR: 0.000870 \n",
            "Epoch: [1][3800/5946] Elapsed 35m 41s (remain 20m 8s) Loss: 1.0727 Grad: 6.3499 LR: 0.000860 \n",
            "Epoch: [1][3900/5946] Elapsed 36m 38s (remain 19m 12s) Loss: 1.0648 Grad: 11.0893 LR: 0.000850 \n",
            "Epoch: [1][4000/5946] Elapsed 37m 34s (remain 18m 16s) Loss: 1.0628 Grad: 14.6251 LR: 0.000839 \n",
            "Epoch: [1][4100/5946] Elapsed 38m 30s (remain 17m 19s) Loss: 1.0596 Grad: 17.6123 LR: 0.000828 \n",
            "Epoch: [1][4200/5946] Elapsed 39m 27s (remain 16m 23s) Loss: 1.0576 Grad: 7.0627 LR: 0.000817 \n",
            "Epoch: [1][4300/5946] Elapsed 40m 23s (remain 15m 26s) Loss: 1.0482 Grad: 4.3124 LR: 0.000805 \n",
            "Epoch: [1][4400/5946] Elapsed 41m 19s (remain 14m 30s) Loss: 1.0412 Grad: 11.6321 LR: 0.000793 \n",
            "Epoch: [1][4500/5946] Elapsed 42m 16s (remain 13m 34s) Loss: 1.0381 Grad: 6.7861 LR: 0.000781 \n",
            "Epoch: [1][4600/5946] Elapsed 43m 12s (remain 12m 37s) Loss: 1.0355 Grad: 2.8926 LR: 0.000769 \n",
            "Epoch: [1][4700/5946] Elapsed 44m 9s (remain 11m 41s) Loss: 1.0316 Grad: 4.2520 LR: 0.000757 \n",
            "Epoch: [1][4800/5946] Elapsed 45m 5s (remain 10m 45s) Loss: 1.0280 Grad: 8.8660 LR: 0.000744 \n",
            "Epoch: [1][4900/5946] Elapsed 46m 1s (remain 9m 48s) Loss: 1.0216 Grad: 16.0256 LR: 0.000731 \n",
            "Epoch: [1][5000/5946] Elapsed 46m 58s (remain 8m 52s) Loss: 1.0177 Grad: 17.4511 LR: 0.000718 \n",
            "Epoch: [1][5100/5946] Elapsed 47m 54s (remain 7m 56s) Loss: 1.0127 Grad: 16.4941 LR: 0.000705 \n",
            "Epoch: [1][5200/5946] Elapsed 48m 50s (remain 6m 59s) Loss: 1.0104 Grad: 9.8462 LR: 0.000691 \n",
            "Epoch: [1][5300/5946] Elapsed 49m 47s (remain 6m 3s) Loss: 1.0056 Grad: 12.5849 LR: 0.000678 \n",
            "Epoch: [1][5400/5946] Elapsed 50m 43s (remain 5m 7s) Loss: 1.0003 Grad: 12.1525 LR: 0.000664 \n",
            "Epoch: [1][5500/5946] Elapsed 51m 39s (remain 4m 10s) Loss: 0.9954 Grad: 2.7108 LR: 0.000650 \n",
            "Epoch: [1][5600/5946] Elapsed 52m 36s (remain 3m 14s) Loss: 0.9927 Grad: 5.2644 LR: 0.000636 \n",
            "Epoch: [1][5700/5946] Elapsed 53m 32s (remain 2m 18s) Loss: 0.9881 Grad: 1.4628 LR: 0.000622 \n",
            "Epoch: [1][5800/5946] Elapsed 54m 28s (remain 1m 21s) Loss: 0.9842 Grad: 9.3213 LR: 0.000607 \n",
            "Epoch: [1][5900/5946] Elapsed 55m 25s (remain 0m 25s) Loss: 0.9812 Grad: 1.4670 LR: 0.000593 \n",
            "Epoch: [1][5945/5946] Elapsed 55m 49s (remain 0m 0s) Loss: 0.9791 Grad: 8.7116 LR: 0.000587 \n",
            "EVAL: [0/774] Elapsed 0m 0s (remain 9m 13s) Loss: 0.0344 \n",
            "EVAL: [100/774] Elapsed 0m 17s (remain 1m 59s) Loss: 0.2268 \n",
            "EVAL: [200/774] Elapsed 0m 35s (remain 1m 39s) Loss: 0.2486 \n",
            "EVAL: [300/774] Elapsed 0m 52s (remain 1m 22s) Loss: 0.2333 \n",
            "EVAL: [400/774] Elapsed 1m 9s (remain 1m 4s) Loss: 0.2010 \n",
            "EVAL: [500/774] Elapsed 1m 26s (remain 0m 47s) Loss: 0.1829 \n",
            "EVAL: [600/774] Elapsed 1m 43s (remain 0m 29s) Loss: 0.1883 \n",
            "EVAL: [700/774] Elapsed 2m 0s (remain 0m 12s) Loss: 0.1929 \n",
            "EVAL: [773/774] Elapsed 2m 13s (remain 0m 0s) Loss: 0.1927 \n",
            "Post-processing 223 example predictions split into 3096 features.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Score: 0.6981849241938928, Train Loss: 0.9791, Val Loss: 0.1927, Time: 3485s\n",
            "Epoch 1 - Save Best Model. score: 0.6982, loss: 0.1927\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [2][0/5946] Elapsed 0m 1s (remain 112m 43s) Loss: 0.4028 Grad: 4.9851 LR: 0.000587 \n",
            "Epoch: [2][100/5946] Elapsed 0m 57s (remain 55m 29s) Loss: 0.3826 Grad: 14.8876 LR: 0.000572 \n",
            "Epoch: [2][200/5946] Elapsed 1m 53s (remain 54m 15s) Loss: 0.4535 Grad: 1.9527 LR: 0.000557 \n",
            "Epoch: [2][300/5946] Elapsed 2m 50s (remain 53m 14s) Loss: 0.4449 Grad: 5.7473 LR: 0.000543 \n",
            "Epoch: [2][400/5946] Elapsed 3m 46s (remain 52m 15s) Loss: 0.4511 Grad: 1.3054 LR: 0.000528 \n",
            "Epoch: [2][500/5946] Elapsed 4m 43s (remain 51m 16s) Loss: 0.4539 Grad: 2.7873 LR: 0.000514 \n",
            "Epoch: [2][600/5946] Elapsed 5m 39s (remain 50m 19s) Loss: 0.4349 Grad: 19.5947 LR: 0.000499 \n",
            "Epoch: [2][700/5946] Elapsed 6m 35s (remain 49m 21s) Loss: 0.4364 Grad: 9.0203 LR: 0.000484 \n",
            "Epoch: [2][800/5946] Elapsed 7m 32s (remain 48m 24s) Loss: 0.4308 Grad: 0.3976 LR: 0.000470 \n",
            "Epoch: [2][900/5946] Elapsed 8m 28s (remain 47m 27s) Loss: 0.4310 Grad: 6.6818 LR: 0.000455 \n",
            "Epoch: [2][1000/5946] Elapsed 9m 24s (remain 46m 30s) Loss: 0.4310 Grad: 15.2134 LR: 0.000440 \n",
            "Epoch: [2][1100/5946] Elapsed 10m 21s (remain 45m 33s) Loss: 0.4316 Grad: 8.2518 LR: 0.000426 \n",
            "Epoch: [2][1200/5946] Elapsed 11m 17s (remain 44m 36s) Loss: 0.4275 Grad: 17.2084 LR: 0.000411 \n",
            "Epoch: [2][1300/5946] Elapsed 12m 13s (remain 43m 40s) Loss: 0.4292 Grad: 10.6110 LR: 0.000397 \n",
            "Epoch: [2][1400/5946] Elapsed 13m 10s (remain 42m 43s) Loss: 0.4307 Grad: 0.4571 LR: 0.000383 \n",
            "Epoch: [2][1500/5946] Elapsed 14m 6s (remain 41m 47s) Loss: 0.4269 Grad: 4.0196 LR: 0.000368 \n",
            "Epoch: [2][1600/5946] Elapsed 15m 2s (remain 40m 50s) Loss: 0.4251 Grad: 0.1081 LR: 0.000354 \n",
            "Epoch: [2][1700/5946] Elapsed 15m 59s (remain 39m 53s) Loss: 0.4263 Grad: 12.4118 LR: 0.000340 \n",
            "Epoch: [2][1800/5946] Elapsed 16m 55s (remain 38m 57s) Loss: 0.4263 Grad: 0.6304 LR: 0.000327 \n",
            "Epoch: [2][1900/5946] Elapsed 17m 51s (remain 38m 0s) Loss: 0.4270 Grad: 0.0197 LR: 0.000313 \n",
            "Epoch: [2][2000/5946] Elapsed 18m 48s (remain 37m 4s) Loss: 0.4294 Grad: 1.6458 LR: 0.000299 \n",
            "Epoch: [2][2100/5946] Elapsed 19m 44s (remain 36m 8s) Loss: 0.4271 Grad: 10.0109 LR: 0.000286 \n",
            "Epoch: [2][2200/5946] Elapsed 20m 41s (remain 35m 11s) Loss: 0.4254 Grad: 9.4467 LR: 0.000273 \n",
            "Epoch: [2][2300/5946] Elapsed 21m 37s (remain 34m 15s) Loss: 0.4208 Grad: 16.4234 LR: 0.000260 \n",
            "Epoch: [2][2400/5946] Elapsed 22m 33s (remain 33m 18s) Loss: 0.4195 Grad: 5.1259 LR: 0.000247 \n",
            "Epoch: [2][2500/5946] Elapsed 23m 30s (remain 32m 22s) Loss: 0.4165 Grad: 6.3574 LR: 0.000234 \n",
            "Epoch: [2][2600/5946] Elapsed 24m 26s (remain 31m 26s) Loss: 0.4174 Grad: 29.1750 LR: 0.000222 \n",
            "Epoch: [2][2700/5946] Elapsed 25m 22s (remain 30m 29s) Loss: 0.4163 Grad: 8.6903 LR: 0.000210 \n",
            "Epoch: [2][2800/5946] Elapsed 26m 19s (remain 29m 33s) Loss: 0.4167 Grad: 4.8961 LR: 0.000198 \n",
            "Epoch: [2][2900/5946] Elapsed 27m 15s (remain 28m 36s) Loss: 0.4141 Grad: 0.8030 LR: 0.000187 \n",
            "Epoch: [2][3000/5946] Elapsed 28m 12s (remain 27m 40s) Loss: 0.4152 Grad: 14.3804 LR: 0.000175 \n",
            "Epoch: [2][3100/5946] Elapsed 29m 8s (remain 26m 44s) Loss: 0.4137 Grad: 11.9186 LR: 0.000164 \n",
            "Epoch: [2][3200/5946] Elapsed 30m 4s (remain 25m 47s) Loss: 0.4120 Grad: 21.7962 LR: 0.000154 \n",
            "Epoch: [2][3300/5946] Elapsed 31m 1s (remain 24m 51s) Loss: 0.4104 Grad: 11.7288 LR: 0.000143 \n",
            "Epoch: [2][3400/5946] Elapsed 31m 57s (remain 23m 54s) Loss: 0.4098 Grad: 8.7604 LR: 0.000133 \n",
            "Epoch: [2][3500/5946] Elapsed 32m 53s (remain 22m 58s) Loss: 0.4103 Grad: 2.9569 LR: 0.000123 \n",
            "Epoch: [2][3600/5946] Elapsed 33m 50s (remain 22m 2s) Loss: 0.4115 Grad: 6.7172 LR: 0.000114 \n",
            "Epoch: [2][3700/5946] Elapsed 34m 46s (remain 21m 5s) Loss: 0.4126 Grad: 2.4849 LR: 0.000105 \n",
            "Epoch: [2][3800/5946] Elapsed 35m 42s (remain 20m 9s) Loss: 0.4115 Grad: 4.6929 LR: 0.000096 \n",
            "Epoch: [2][3900/5946] Elapsed 36m 39s (remain 19m 12s) Loss: 0.4114 Grad: 2.4741 LR: 0.000087 \n",
            "Epoch: [2][4000/5946] Elapsed 37m 35s (remain 18m 16s) Loss: 0.4095 Grad: 0.2672 LR: 0.000079 \n",
            "Epoch: [2][4100/5946] Elapsed 38m 31s (remain 17m 20s) Loss: 0.4087 Grad: 3.6254 LR: 0.000072 \n",
            "Epoch: [2][4200/5946] Elapsed 39m 28s (remain 16m 23s) Loss: 0.4072 Grad: 11.7547 LR: 0.000064 \n",
            "Epoch: [2][4300/5946] Elapsed 40m 24s (remain 15m 27s) Loss: 0.4058 Grad: 4.6883 LR: 0.000057 \n",
            "Epoch: [2][4400/5946] Elapsed 41m 20s (remain 14m 30s) Loss: 0.4037 Grad: 8.8673 LR: 0.000051 \n",
            "Epoch: [2][4500/5946] Elapsed 42m 17s (remain 13m 34s) Loss: 0.4035 Grad: 5.2609 LR: 0.000044 \n",
            "Epoch: [2][4600/5946] Elapsed 43m 13s (remain 12m 38s) Loss: 0.4020 Grad: 8.8899 LR: 0.000038 \n",
            "Epoch: [2][4700/5946] Elapsed 44m 9s (remain 11m 41s) Loss: 0.3998 Grad: 20.6639 LR: 0.000033 \n",
            "Epoch: [2][4800/5946] Elapsed 45m 6s (remain 10m 45s) Loss: 0.4007 Grad: 3.6984 LR: 0.000028 \n",
            "Epoch: [2][4900/5946] Elapsed 46m 2s (remain 9m 49s) Loss: 0.3989 Grad: 11.3411 LR: 0.000023 \n",
            "Epoch: [2][5000/5946] Elapsed 46m 58s (remain 8m 52s) Loss: 0.3980 Grad: 5.3735 LR: 0.000019 \n",
            "Epoch: [2][5100/5946] Elapsed 47m 55s (remain 7m 56s) Loss: 0.3971 Grad: 2.7338 LR: 0.000015 \n",
            "Epoch: [2][5200/5946] Elapsed 48m 51s (remain 6m 59s) Loss: 0.3964 Grad: 7.0807 LR: 0.000012 \n",
            "Epoch: [2][5300/5946] Elapsed 49m 47s (remain 6m 3s) Loss: 0.3953 Grad: 12.6312 LR: 0.000009 \n",
            "Epoch: [2][5400/5946] Elapsed 50m 44s (remain 5m 7s) Loss: 0.3956 Grad: 12.0000 LR: 0.000006 \n",
            "Epoch: [2][5500/5946] Elapsed 51m 40s (remain 4m 10s) Loss: 0.3977 Grad: 9.2097 LR: 0.000004 \n",
            "Epoch: [2][5600/5946] Elapsed 52m 36s (remain 3m 14s) Loss: 0.3987 Grad: 5.0300 LR: 0.000003 \n",
            "Epoch: [2][5700/5946] Elapsed 53m 33s (remain 2m 18s) Loss: 0.3977 Grad: 22.5768 LR: 0.000001 \n",
            "Epoch: [2][5800/5946] Elapsed 54m 29s (remain 1m 21s) Loss: 0.3986 Grad: 0.1047 LR: 0.000000 \n",
            "Epoch: [2][5900/5946] Elapsed 55m 25s (remain 0m 25s) Loss: 0.3975 Grad: 5.6156 LR: 0.000000 \n",
            "Epoch: [2][5945/5946] Elapsed 55m 50s (remain 0m 0s) Loss: 0.3976 Grad: 0.0384 LR: 0.000000 \n",
            "EVAL: [0/774] Elapsed 0m 0s (remain 9m 13s) Loss: 0.0086 \n",
            "EVAL: [100/774] Elapsed 0m 17s (remain 1m 59s) Loss: 0.2662 \n",
            "EVAL: [200/774] Elapsed 0m 35s (remain 1m 39s) Loss: 0.2698 \n",
            "EVAL: [300/774] Elapsed 0m 52s (remain 1m 22s) Loss: 0.2548 \n",
            "EVAL: [400/774] Elapsed 1m 9s (remain 1m 4s) Loss: 0.2152 \n",
            "EVAL: [500/774] Elapsed 1m 26s (remain 0m 47s) Loss: 0.1922 \n",
            "EVAL: [600/774] Elapsed 1m 43s (remain 0m 29s) Loss: 0.2011 \n",
            "EVAL: [700/774] Elapsed 2m 0s (remain 0m 12s) Loss: 0.2069 \n",
            "EVAL: [773/774] Elapsed 2m 13s (remain 0m 0s) Loss: 0.2035 \n",
            "Post-processing 223 example predictions split into 3096 features.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2 - Score: 0.709283578902413, Train Loss: 0.3976, Val Loss: 0.2035, Time: 3485s\n",
            "========== fold: 3 result ==========\n",
            "Score: 0.69594\n",
            "========== fold: 4 training ==========\n",
            "Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'qa_outputs.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [1][0/6020] Elapsed 0m 1s (remain 110m 19s) Loss: 6.0730 Grad: 6.6833 LR: 0.000000 \n",
            "Epoch: [1][100/6020] Elapsed 0m 57s (remain 56m 7s) Loss: 5.4087 Grad: 6.7477 LR: 0.000083 \n",
            "Epoch: [1][200/6020] Elapsed 1m 53s (remain 54m 54s) Loss: 3.7722 Grad: 10.9661 LR: 0.000167 \n",
            "Epoch: [1][300/6020] Elapsed 2m 50s (remain 53m 51s) Loss: 2.8952 Grad: 5.8612 LR: 0.000250 \n",
            "Epoch: [1][400/6020] Elapsed 3m 46s (remain 52m 51s) Loss: 2.3924 Grad: 11.4034 LR: 0.000333 \n",
            "Epoch: [1][500/6020] Elapsed 4m 42s (remain 51m 54s) Loss: 2.1003 Grad: 8.9742 LR: 0.000417 \n",
            "Epoch: [1][600/6020] Elapsed 5m 39s (remain 50m 56s) Loss: 1.9039 Grad: 15.7916 LR: 0.000500 \n",
            "Epoch: [1][700/6020] Elapsed 6m 35s (remain 49m 59s) Loss: 1.7696 Grad: 8.5565 LR: 0.000583 \n",
            "Epoch: [1][800/6020] Elapsed 7m 31s (remain 49m 2s) Loss: 1.6750 Grad: 7.8459 LR: 0.000667 \n",
            "Epoch: [1][900/6020] Elapsed 8m 27s (remain 48m 6s) Loss: 1.5862 Grad: 10.6776 LR: 0.000750 \n",
            "Epoch: [1][1000/6020] Elapsed 9m 24s (remain 47m 9s) Loss: 1.5217 Grad: 4.2317 LR: 0.000833 \n",
            "Epoch: [1][1100/6020] Elapsed 10m 20s (remain 46m 12s) Loss: 1.4661 Grad: 15.6339 LR: 0.000917 \n",
            "Epoch: [1][1200/6020] Elapsed 11m 16s (remain 45m 16s) Loss: 1.4438 Grad: 5.5425 LR: 0.001000 \n",
            "Epoch: [1][1300/6020] Elapsed 12m 13s (remain 44m 19s) Loss: 1.4029 Grad: 6.0108 LR: 0.001000 \n",
            "Epoch: [1][1400/6020] Elapsed 13m 9s (remain 43m 23s) Loss: 1.3648 Grad: 22.6990 LR: 0.000999 \n",
            "Epoch: [1][1500/6020] Elapsed 14m 5s (remain 42m 26s) Loss: 1.3422 Grad: 13.7800 LR: 0.000998 \n",
            "Epoch: [1][1600/6020] Elapsed 15m 2s (remain 41m 30s) Loss: 1.3204 Grad: 10.7019 LR: 0.000997 \n",
            "Epoch: [1][1700/6020] Elapsed 15m 58s (remain 40m 34s) Loss: 1.2957 Grad: 15.2979 LR: 0.000995 \n",
            "Epoch: [1][1800/6020] Elapsed 16m 55s (remain 39m 37s) Loss: 1.2718 Grad: 13.3004 LR: 0.000992 \n",
            "Epoch: [1][1900/6020] Elapsed 17m 51s (remain 38m 41s) Loss: 1.2500 Grad: 5.3239 LR: 0.000990 \n",
            "Epoch: [1][2000/6020] Elapsed 18m 47s (remain 37m 45s) Loss: 1.2292 Grad: 1.2662 LR: 0.000987 \n",
            "Epoch: [1][2100/6020] Elapsed 19m 44s (remain 36m 48s) Loss: 1.2180 Grad: 30.6000 LR: 0.000983 \n",
            "Epoch: [1][2200/6020] Elapsed 20m 40s (remain 35m 52s) Loss: 1.2070 Grad: 16.3968 LR: 0.000979 \n",
            "Epoch: [1][2300/6020] Elapsed 21m 36s (remain 34m 55s) Loss: 1.1884 Grad: 28.1323 LR: 0.000975 \n",
            "Epoch: [1][2400/6020] Elapsed 22m 33s (remain 33m 59s) Loss: 1.1795 Grad: 7.0758 LR: 0.000970 \n",
            "Epoch: [1][2500/6020] Elapsed 23m 29s (remain 33m 3s) Loss: 1.1721 Grad: 12.9599 LR: 0.000965 \n",
            "Epoch: [1][2600/6020] Elapsed 24m 25s (remain 32m 6s) Loss: 1.1562 Grad: 15.1601 LR: 0.000959 \n",
            "Epoch: [1][2700/6020] Elapsed 25m 22s (remain 31m 10s) Loss: 1.1448 Grad: 22.6748 LR: 0.000953 \n",
            "Epoch: [1][2800/6020] Elapsed 26m 18s (remain 30m 14s) Loss: 1.1324 Grad: 7.3386 LR: 0.000947 \n",
            "Epoch: [1][2900/6020] Elapsed 27m 14s (remain 29m 17s) Loss: 1.1252 Grad: 7.3026 LR: 0.000941 \n",
            "Epoch: [1][3000/6020] Elapsed 28m 11s (remain 28m 21s) Loss: 1.1133 Grad: 2.1613 LR: 0.000933 \n",
            "Epoch: [1][3100/6020] Elapsed 29m 7s (remain 27m 24s) Loss: 1.1040 Grad: 10.0725 LR: 0.000926 \n",
            "Epoch: [1][3200/6020] Elapsed 30m 3s (remain 26m 28s) Loss: 1.0961 Grad: 9.0568 LR: 0.000918 \n",
            "Epoch: [1][3300/6020] Elapsed 31m 0s (remain 25m 32s) Loss: 1.0929 Grad: 28.8305 LR: 0.000910 \n",
            "Epoch: [1][3400/6020] Elapsed 31m 56s (remain 24m 35s) Loss: 1.0855 Grad: 10.8650 LR: 0.000902 \n",
            "Epoch: [1][3500/6020] Elapsed 32m 52s (remain 23m 39s) Loss: 1.0769 Grad: 8.8730 LR: 0.000893 \n",
            "Epoch: [1][3600/6020] Elapsed 33m 49s (remain 22m 43s) Loss: 1.0691 Grad: 16.3855 LR: 0.000884 \n",
            "Epoch: [1][3700/6020] Elapsed 34m 45s (remain 21m 46s) Loss: 1.0625 Grad: 8.1416 LR: 0.000874 \n",
            "Epoch: [1][3800/6020] Elapsed 35m 42s (remain 20m 50s) Loss: 1.0560 Grad: 2.6767 LR: 0.000865 \n",
            "Epoch: [1][3900/6020] Elapsed 36m 38s (remain 19m 54s) Loss: 1.0479 Grad: 11.8987 LR: 0.000855 \n",
            "Epoch: [1][4000/6020] Elapsed 37m 34s (remain 18m 57s) Loss: 1.0429 Grad: 17.2245 LR: 0.000844 \n",
            "Epoch: [1][4100/6020] Elapsed 38m 31s (remain 18m 1s) Loss: 1.0418 Grad: 3.8174 LR: 0.000834 \n",
            "Epoch: [1][4200/6020] Elapsed 39m 27s (remain 17m 5s) Loss: 1.0359 Grad: 11.1876 LR: 0.000823 \n",
            "Epoch: [1][4300/6020] Elapsed 40m 23s (remain 16m 8s) Loss: 1.0337 Grad: 10.9399 LR: 0.000811 \n",
            "Epoch: [1][4400/6020] Elapsed 41m 20s (remain 15m 12s) Loss: 1.0267 Grad: 5.4089 LR: 0.000800 \n",
            "Epoch: [1][4500/6020] Elapsed 42m 16s (remain 14m 16s) Loss: 1.0223 Grad: 7.0372 LR: 0.000788 \n",
            "Epoch: [1][4600/6020] Elapsed 43m 12s (remain 13m 19s) Loss: 1.0172 Grad: 11.0841 LR: 0.000776 \n",
            "Epoch: [1][4700/6020] Elapsed 44m 9s (remain 12m 23s) Loss: 1.0138 Grad: 8.9004 LR: 0.000764 \n",
            "Epoch: [1][4800/6020] Elapsed 45m 5s (remain 11m 26s) Loss: 1.0106 Grad: 33.3823 LR: 0.000752 \n",
            "Epoch: [1][4900/6020] Elapsed 46m 1s (remain 10m 30s) Loss: 1.0096 Grad: 12.5833 LR: 0.000739 \n",
            "Epoch: [1][5000/6020] Elapsed 46m 58s (remain 9m 34s) Loss: 1.0048 Grad: 10.9995 LR: 0.000726 \n",
            "Epoch: [1][5100/6020] Elapsed 47m 54s (remain 8m 37s) Loss: 0.9995 Grad: 22.9123 LR: 0.000713 \n",
            "Epoch: [1][5200/6020] Elapsed 48m 50s (remain 7m 41s) Loss: 0.9970 Grad: 7.9899 LR: 0.000700 \n",
            "Epoch: [1][5300/6020] Elapsed 49m 47s (remain 6m 45s) Loss: 0.9920 Grad: 5.2383 LR: 0.000687 \n",
            "Epoch: [1][5400/6020] Elapsed 50m 43s (remain 5m 48s) Loss: 0.9895 Grad: 36.4547 LR: 0.000673 \n",
            "Epoch: [1][5500/6020] Elapsed 51m 40s (remain 4m 52s) Loss: 0.9850 Grad: 11.5554 LR: 0.000659 \n",
            "Epoch: [1][5600/6020] Elapsed 52m 36s (remain 3m 56s) Loss: 0.9800 Grad: 9.3146 LR: 0.000646 \n",
            "Epoch: [1][5700/6020] Elapsed 53m 32s (remain 2m 59s) Loss: 0.9750 Grad: 9.5850 LR: 0.000632 \n",
            "Epoch: [1][5800/6020] Elapsed 54m 29s (remain 2m 3s) Loss: 0.9737 Grad: 9.0759 LR: 0.000618 \n",
            "Epoch: [1][5900/6020] Elapsed 55m 25s (remain 1m 7s) Loss: 0.9725 Grad: 7.8994 LR: 0.000604 \n",
            "Epoch: [1][6000/6020] Elapsed 56m 21s (remain 0m 10s) Loss: 0.9699 Grad: 12.1792 LR: 0.000589 \n",
            "Epoch: [1][6019/6020] Elapsed 56m 32s (remain 0m 0s) Loss: 0.9693 Grad: 18.6513 LR: 0.000587 \n",
            "EVAL: [0/701] Elapsed 0m 0s (remain 8m 23s) Loss: 0.0929 \n",
            "EVAL: [100/701] Elapsed 0m 17s (remain 1m 46s) Loss: 0.2641 \n",
            "EVAL: [200/701] Elapsed 0m 35s (remain 1m 27s) Loss: 0.2441 \n",
            "EVAL: [300/701] Elapsed 0m 52s (remain 1m 9s) Loss: 0.2708 \n",
            "EVAL: [400/701] Elapsed 1m 9s (remain 0m 51s) Loss: 0.2780 \n",
            "EVAL: [500/701] Elapsed 1m 26s (remain 0m 34s) Loss: 0.2535 \n",
            "EVAL: [600/701] Elapsed 1m 43s (remain 0m 17s) Loss: 0.2466 \n",
            "EVAL: [700/701] Elapsed 2m 0s (remain 0m 0s) Loss: 0.2622 \n",
            "Post-processing 222 example predictions split into 2801 features.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Score: 0.6645288832788834, Train Loss: 0.9693, Val Loss: 0.2622, Time: 3514s\n",
            "Epoch 1 - Save Best Model. score: 0.6645, loss: 0.2622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [2][0/6020] Elapsed 0m 1s (remain 112m 4s) Loss: 0.1015 Grad: 2.2989 LR: 0.000587 \n",
            "Epoch: [2][100/6020] Elapsed 0m 57s (remain 56m 9s) Loss: 0.4173 Grad: 7.0562 LR: 0.000572 \n",
            "Epoch: [2][200/6020] Elapsed 1m 53s (remain 54m 56s) Loss: 0.4200 Grad: 11.7356 LR: 0.000558 \n",
            "Epoch: [2][300/6020] Elapsed 2m 50s (remain 53m 53s) Loss: 0.4141 Grad: 23.6415 LR: 0.000543 \n",
            "Epoch: [2][400/6020] Elapsed 3m 46s (remain 52m 54s) Loss: 0.4302 Grad: 0.4066 LR: 0.000529 \n",
            "Epoch: [2][500/6020] Elapsed 4m 42s (remain 51m 55s) Loss: 0.4316 Grad: 18.5443 LR: 0.000514 \n",
            "Epoch: [2][600/6020] Elapsed 5m 39s (remain 50m 58s) Loss: 0.4326 Grad: 13.0305 LR: 0.000500 \n",
            "Epoch: [2][700/6020] Elapsed 6m 35s (remain 50m 1s) Loss: 0.4311 Grad: 6.2438 LR: 0.000486 \n",
            "Epoch: [2][800/6020] Elapsed 7m 31s (remain 49m 4s) Loss: 0.4436 Grad: 6.7655 LR: 0.000471 \n",
            "Epoch: [2][900/6020] Elapsed 8m 28s (remain 48m 7s) Loss: 0.4539 Grad: 1.9073 LR: 0.000457 \n",
            "Epoch: [2][1000/6020] Elapsed 9m 24s (remain 47m 11s) Loss: 0.4410 Grad: 5.3699 LR: 0.000442 \n",
            "Epoch: [2][1100/6020] Elapsed 10m 21s (remain 46m 14s) Loss: 0.4351 Grad: 5.1511 LR: 0.000428 \n",
            "Epoch: [2][1200/6020] Elapsed 11m 17s (remain 45m 18s) Loss: 0.4344 Grad: 4.3312 LR: 0.000413 \n",
            "Epoch: [2][1300/6020] Elapsed 12m 13s (remain 44m 21s) Loss: 0.4367 Grad: 1.5716 LR: 0.000399 \n",
            "Epoch: [2][1400/6020] Elapsed 13m 10s (remain 43m 24s) Loss: 0.4333 Grad: 6.4339 LR: 0.000385 \n",
            "Epoch: [2][1500/6020] Elapsed 14m 6s (remain 42m 28s) Loss: 0.4303 Grad: 5.9247 LR: 0.000371 \n",
            "Epoch: [2][1600/6020] Elapsed 15m 2s (remain 41m 31s) Loss: 0.4279 Grad: 28.1038 LR: 0.000357 \n",
            "Epoch: [2][1700/6020] Elapsed 15m 59s (remain 40m 35s) Loss: 0.4274 Grad: 1.8298 LR: 0.000343 \n",
            "Epoch: [2][1800/6020] Elapsed 16m 55s (remain 39m 38s) Loss: 0.4229 Grad: 2.0218 LR: 0.000330 \n",
            "Epoch: [2][1900/6020] Elapsed 17m 51s (remain 38m 42s) Loss: 0.4252 Grad: 0.1882 LR: 0.000316 \n",
            "Epoch: [2][2000/6020] Elapsed 18m 48s (remain 37m 46s) Loss: 0.4233 Grad: 5.5769 LR: 0.000303 \n",
            "Epoch: [2][2100/6020] Elapsed 19m 44s (remain 36m 49s) Loss: 0.4242 Grad: 0.7724 LR: 0.000289 \n",
            "Epoch: [2][2200/6020] Elapsed 20m 40s (remain 35m 53s) Loss: 0.4225 Grad: 7.7810 LR: 0.000276 \n",
            "Epoch: [2][2300/6020] Elapsed 21m 37s (remain 34m 56s) Loss: 0.4231 Grad: 3.9659 LR: 0.000264 \n",
            "Epoch: [2][2400/6020] Elapsed 22m 33s (remain 34m 0s) Loss: 0.4233 Grad: 13.9829 LR: 0.000251 \n",
            "Epoch: [2][2500/6020] Elapsed 23m 29s (remain 33m 3s) Loss: 0.4224 Grad: 8.4886 LR: 0.000238 \n",
            "Epoch: [2][2600/6020] Elapsed 24m 26s (remain 32m 7s) Loss: 0.4201 Grad: 3.8497 LR: 0.000226 \n",
            "Epoch: [2][2700/6020] Elapsed 25m 22s (remain 31m 11s) Loss: 0.4179 Grad: 0.1372 LR: 0.000214 \n",
            "Epoch: [2][2800/6020] Elapsed 26m 18s (remain 30m 14s) Loss: 0.4150 Grad: 2.7880 LR: 0.000202 \n",
            "Epoch: [2][2900/6020] Elapsed 27m 15s (remain 29m 18s) Loss: 0.4122 Grad: 0.0451 LR: 0.000191 \n",
            "Epoch: [2][3000/6020] Elapsed 28m 11s (remain 28m 21s) Loss: 0.4124 Grad: 13.7335 LR: 0.000180 \n",
            "Epoch: [2][3100/6020] Elapsed 29m 8s (remain 27m 25s) Loss: 0.4138 Grad: 1.6314 LR: 0.000169 \n",
            "Epoch: [2][3200/6020] Elapsed 30m 4s (remain 26m 29s) Loss: 0.4136 Grad: 0.0972 LR: 0.000158 \n",
            "Epoch: [2][3300/6020] Elapsed 31m 0s (remain 25m 32s) Loss: 0.4143 Grad: 15.6132 LR: 0.000147 \n",
            "Epoch: [2][3400/6020] Elapsed 31m 57s (remain 24m 36s) Loss: 0.4122 Grad: 3.2537 LR: 0.000137 \n",
            "Epoch: [2][3500/6020] Elapsed 32m 53s (remain 23m 39s) Loss: 0.4098 Grad: 2.5587 LR: 0.000128 \n",
            "Epoch: [2][3600/6020] Elapsed 33m 49s (remain 22m 43s) Loss: 0.4068 Grad: 3.9780 LR: 0.000118 \n",
            "Epoch: [2][3700/6020] Elapsed 34m 46s (remain 21m 47s) Loss: 0.4068 Grad: 0.4804 LR: 0.000109 \n",
            "Epoch: [2][3800/6020] Elapsed 35m 42s (remain 20m 50s) Loss: 0.4063 Grad: 3.0325 LR: 0.000100 \n",
            "Epoch: [2][3900/6020] Elapsed 36m 38s (remain 19m 54s) Loss: 0.4058 Grad: 2.3826 LR: 0.000091 \n",
            "Epoch: [2][4000/6020] Elapsed 37m 35s (remain 18m 58s) Loss: 0.4036 Grad: 0.2921 LR: 0.000083 \n",
            "Epoch: [2][4100/6020] Elapsed 38m 31s (remain 18m 1s) Loss: 0.4018 Grad: 8.2144 LR: 0.000075 \n",
            "Epoch: [2][4200/6020] Elapsed 39m 27s (remain 17m 5s) Loss: 0.4021 Grad: 1.1332 LR: 0.000068 \n",
            "Epoch: [2][4300/6020] Elapsed 40m 24s (remain 16m 8s) Loss: 0.4015 Grad: 1.9607 LR: 0.000061 \n",
            "Epoch: [2][4400/6020] Elapsed 41m 20s (remain 15m 12s) Loss: 0.4023 Grad: 2.4519 LR: 0.000054 \n",
            "Epoch: [2][4500/6020] Elapsed 42m 16s (remain 14m 16s) Loss: 0.4014 Grad: 17.2279 LR: 0.000048 \n",
            "Epoch: [2][4600/6020] Elapsed 43m 13s (remain 13m 19s) Loss: 0.4015 Grad: 2.6525 LR: 0.000042 \n",
            "Epoch: [2][4700/6020] Elapsed 44m 9s (remain 12m 23s) Loss: 0.4030 Grad: 14.9503 LR: 0.000036 \n",
            "Epoch: [2][4800/6020] Elapsed 45m 5s (remain 11m 27s) Loss: 0.4015 Grad: 0.2337 LR: 0.000031 \n",
            "Epoch: [2][4900/6020] Elapsed 46m 2s (remain 10m 30s) Loss: 0.4024 Grad: 14.9216 LR: 0.000026 \n",
            "Epoch: [2][5000/6020] Elapsed 46m 58s (remain 9m 34s) Loss: 0.4040 Grad: 5.5944 LR: 0.000022 \n",
            "Epoch: [2][5100/6020] Elapsed 47m 55s (remain 8m 37s) Loss: 0.4033 Grad: 3.6729 LR: 0.000018 \n",
            "Epoch: [2][5200/6020] Elapsed 48m 51s (remain 7m 41s) Loss: 0.4022 Grad: 0.2766 LR: 0.000014 \n",
            "Epoch: [2][5300/6020] Elapsed 49m 47s (remain 6m 45s) Loss: 0.4013 Grad: 9.1794 LR: 0.000011 \n",
            "Epoch: [2][5400/6020] Elapsed 50m 44s (remain 5m 48s) Loss: 0.3998 Grad: 7.5935 LR: 0.000008 \n",
            "Epoch: [2][5500/6020] Elapsed 51m 40s (remain 4m 52s) Loss: 0.4004 Grad: 34.5954 LR: 0.000006 \n",
            "Epoch: [2][5600/6020] Elapsed 52m 36s (remain 3m 56s) Loss: 0.4000 Grad: 0.4672 LR: 0.000004 \n",
            "Epoch: [2][5700/6020] Elapsed 53m 33s (remain 2m 59s) Loss: 0.3990 Grad: 19.4131 LR: 0.000002 \n",
            "Epoch: [2][5800/6020] Elapsed 54m 29s (remain 2m 3s) Loss: 0.3991 Grad: 4.7234 LR: 0.000001 \n",
            "Epoch: [2][5900/6020] Elapsed 55m 25s (remain 1m 7s) Loss: 0.3988 Grad: 0.3663 LR: 0.000000 \n",
            "Epoch: [2][6000/6020] Elapsed 56m 22s (remain 0m 10s) Loss: 0.3968 Grad: 1.8749 LR: 0.000000 \n",
            "Epoch: [2][6019/6020] Elapsed 56m 32s (remain 0m 0s) Loss: 0.3974 Grad: 30.1254 LR: 0.000000 \n",
            "EVAL: [0/701] Elapsed 0m 0s (remain 8m 23s) Loss: 0.0202 \n",
            "EVAL: [100/701] Elapsed 0m 17s (remain 1m 46s) Loss: 0.2562 \n",
            "EVAL: [200/701] Elapsed 0m 35s (remain 1m 27s) Loss: 0.2324 \n",
            "EVAL: [300/701] Elapsed 0m 52s (remain 1m 9s) Loss: 0.2549 \n",
            "EVAL: [400/701] Elapsed 1m 9s (remain 0m 51s) Loss: 0.2608 \n",
            "EVAL: [500/701] Elapsed 1m 26s (remain 0m 34s) Loss: 0.2355 \n",
            "EVAL: [600/701] Elapsed 1m 43s (remain 0m 17s) Loss: 0.2270 \n",
            "EVAL: [700/701] Elapsed 2m 0s (remain 0m 0s) Loss: 0.2499 \n",
            "Post-processing 222 example predictions split into 2801 features.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - Score: 0.6976798914298914, Train Loss: 0.3974, Val Loss: 0.2499, Time: 3517s\n",
            "Epoch 2 - Save Best Model. score: 0.6977, loss: 0.2499\n",
            "========== fold: 4 result ==========\n",
            "Score: 0.69182\n",
            "========== CV ==========\n",
            "Score: 0.67461\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 137.5s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1pdUFYKYmOM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b687593c5dff40c7884d1cf4553df293"
          ]
        },
        "outputId": "c4c6b342-3447-4318-b586-e609aac14292"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 427<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b687593c5dff40c7884d1cf4553df293",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 10708.79MB of 10708.79MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, …"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210914_153302-16cifk7p/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210914_153302-16cifk7p/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>2</td></tr><tr><td>val_loss/fold0</td><td>0.26864</td></tr><tr><td>score/fold0</td><td>0.68746</td></tr><tr><td>_runtime</td><td>35843</td></tr><tr><td>_timestamp</td><td>1631669425</td></tr><tr><td>_step</td><td>17</td></tr><tr><td>CV_fold0</td><td>0.63694</td></tr><tr><td>val_loss/fold1</td><td>0.23148</td></tr><tr><td>score/fold1</td><td>0.69662</td></tr><tr><td>CV_fold1</td><td>0.68317</td></tr><tr><td>val_loss/fold2</td><td>0.29687</td></tr><tr><td>score/fold2</td><td>0.65637</td></tr><tr><td>CV_fold2</td><td>0.66526</td></tr><tr><td>val_loss/fold3</td><td>0.20349</td></tr><tr><td>score/fold3</td><td>0.70928</td></tr><tr><td>CV_fold3</td><td>0.69594</td></tr><tr><td>val_loss/fold4</td><td>0.24988</td></tr><tr><td>score/fold4</td><td>0.69768</td></tr><tr><td>CV_fold4</td><td>0.69182</td></tr><tr><td>CV</td><td>0.67461</td></tr><tr><td>loss</td><td>0.23913</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁█▁█▁█▁█▁█</td></tr><tr><td>val_loss/fold0</td><td>▁█</td></tr><tr><td>score/fold0</td><td>▁█</td></tr><tr><td>_runtime</td><td>▁▂▂▃▃▃▄▅▅▆▆▆▇█████</td></tr><tr><td>_timestamp</td><td>▁▂▂▃▃▃▄▅▅▆▆▆▇█████</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr><tr><td>CV_fold0</td><td>▁</td></tr><tr><td>val_loss/fold1</td><td>█▁</td></tr><tr><td>score/fold1</td><td>▁█</td></tr><tr><td>CV_fold1</td><td>▁</td></tr><tr><td>val_loss/fold2</td><td>▁█</td></tr><tr><td>score/fold2</td><td>█▁</td></tr><tr><td>CV_fold2</td><td>▁</td></tr><tr><td>val_loss/fold3</td><td>▁█</td></tr><tr><td>score/fold3</td><td>▁█</td></tr><tr><td>CV_fold3</td><td>▁</td></tr><tr><td>val_loss/fold4</td><td>█▁</td></tr><tr><td>score/fold4</td><td>▁█</td></tr><tr><td>CV_fold4</td><td>▁</td></tr><tr><td>CV</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 55 artifact file(s) and 2 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">youthful-valley-9</strong>: <a href=\"https://wandb.ai/imokuri/chaii/runs/16cifk7p\" target=\"_blank\">https://wandb.ai/imokuri/chaii/runs/16cifk7p</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fEjvHZUbgpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60d85c1e-fee6-40fa-90ac-d4e8de74b972"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 15 01:34:45 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    34W / 250W |  15785MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ]
}